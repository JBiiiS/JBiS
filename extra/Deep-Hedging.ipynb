{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrV5Ikm1ga36"
   },
   "source": [
    "np.empty([m,n]):m by n empty mtx\n",
    "norm.cdf(n) : -infinity ~ n cdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1zSsO02UB32"
   },
   "source": [
    "**Functional API vs Sequential API**\n",
    "\n",
    "1. Sequential API\n",
    "\n",
    "  model = Sequential()\n",
    "  '레이어가 1줄로 일렬로 연결되는 경우'\n",
    "  대개, 입력층이 1열, 흐름이 x->layer1->layer2->output\n",
    "\n",
    "\n",
    "2. Functional API\n",
    "\n",
    "  model = keras.Model(inputs = my_input, outputs = my_output)\n",
    "  multi input, multi output이나 중간에서 갈라졌다 합쳐지는 구조(branch,merge등)\n",
    "  잔차연결(skip/residual)같은 비선형 토폴로지 등\n",
    "\n",
    "\n",
    "중요한 차이는 Functional API는 INPUT이 될 TENSOR에 대한 명확한 정의가 있어야함.\n",
    "\n",
    "예컨대 Sequential API에선,\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, activation = 'Relu', name = 'output'))으로만 써도, Sequential이 자동적으로 '암묵적 input tensor를 지정해주고 연결해줘서'문제가 없지만,\n",
    "\n",
    " output = keras.Dense(1, activation = 'Relu', name = 'output')라고 쓰고,\n",
    "\n",
    "model = Model(inputs = ['hedge_cost', 'price'], outputs = output)이렇게 하면\n",
    "\n",
    "\"output이 있긴한데 저새끼가 뭐 받는건지 정확히 정의가 안되어있었는데?\"\n",
    "\n",
    "일케됨.\n",
    "\n",
    " output = keras.Dense(1, activation = 'Relu', name = 'output')(input_vec)\n",
    "\n",
    "\n",
    " 이렇게 '입력 텐서는 얘로 할게' 가 있어야만 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EVzj4t7HA-xD"
   },
   "outputs": [],
   "source": [
    "# Pytorch Update\n",
    "\n",
    "'''\n",
    "\n",
    "# 1. 기존 버전 삭제 및 호환 버전 재설치\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 --upgrade --force-reinstall\n",
    "\n",
    "# 2. 설치 후 런타임 재시작 필수! (아래 코드 실행)\n",
    "import os\n",
    "os.kill(os.getpid(), 9)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8sWt_Bb0RPYr"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sympy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sympy.__version__ != \u001b[33m\"\u001b[39m\u001b[33m1.12\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSymPy 버전 불일치 감지 (1.12 권장). 재설치를 진행합니다...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sympy'"
     ]
    }
   ],
   "source": [
    "import sympy\n",
    "if sympy.__version__ != \"1.12\":\n",
    "    print(\"SymPy 버전 불일치 감지 (1.12 권장). 재설치를 진행합니다...\")\n",
    "    !pip install \"sympy==1.12\"\n",
    "    print(\"설치 완료. 런타임을 재시작한 후 다시 실행해주세요.\")\n",
    "    # 이후 로직 중단 혹은 경고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wu4vTPiu1CXg"
   },
   "outputs": [],
   "source": [
    "!pip install arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "le9I5KPUeFXI"
   },
   "outputs": [],
   "source": [
    "#!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKaAqrqgNRa4"
   },
   "outputs": [],
   "source": [
    "pip install -U finance-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYPb4o3W4SQc"
   },
   "outputs": [],
   "source": [
    "import FinanceDataReader as fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aSYIt4PTPMxs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "from google.colab import files\n",
    "from scipy.stats import norm\n",
    "from tensorflow import keras\n",
    "\n",
    "#keras regression\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import optimizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlChsWqoRGMT"
   },
   "outputs": [],
   "source": [
    "r =0.00\n",
    "sig = 0.2\n",
    "T= 30/365 #Maturity\n",
    "\n",
    "M = 100 # 시나리오 개수\n",
    "N = 500 #시간 나누는 개수\n",
    "\n",
    "\n",
    "dt = T/N #1 day\n",
    "rdt = r*dt\n",
    "sigsdt = sig * np.sqrt(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4AaJBpwuX-7N"
   },
   "outputs": [],
   "source": [
    "S0 = 100\n",
    "\n",
    "\n",
    "S = np.empty([M,N+1]) #N+1인 이유는오늘은 t=0으로 할 거기 때문\n",
    "'''\n",
    "rng = np.random.default_rng(seed=42)\n",
    "rv = rng.normal(rdt, sigsdt, size=(M, N))\n",
    "'''\n",
    "np.random.seed(100)\n",
    "rv = np.random.normal(rdt,sigsdt,(M,N))\n",
    "# rv = GBM & risk-neutral prob 하, dlns_t인 동시에 return: ds_t/s_t\n",
    "# np.random.noraml은 (Mean, **sd**, mtx size)로 생성하고,각 element는 랜덤하게 그런 분포에서 뽑아낸 값임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZmKWP92BaM0A"
   },
   "outputs": [],
   "source": [
    "for i in range(M):\n",
    "  S[i,0] = S0\n",
    "  for j in range(N):\n",
    "    S[i,j+1] = S[i,j] * (1+rv[i,j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vds1wAtZaNOe"
   },
   "outputs": [],
   "source": [
    "for i in range(M):\n",
    "  plt.plot(S[i,:])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(pd.Series(S[:,-1]).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "epE_zEPAcCWM"
   },
   "outputs": [],
   "source": [
    "m=1\n",
    "K = 100\n",
    "\n",
    "hedge=0\n",
    "cost = 0\n",
    "\n",
    "with_hedge_pf = []\n",
    "with_hedge_pf_cum = []\n",
    "without_hedge_pf = []\n",
    "without_hedge_pf_cum = []\n",
    "call_price = []\n",
    "\n",
    "for j in range(N):\n",
    "  tow = T - j*dt\n",
    "  d1 = (np.log(S[m,j]/K) + (r+0.5*sig**2)*tow)/(sig*np.sqrt(tow))\n",
    "  d2 = d1 - sig*np.sqrt(tow)\n",
    "  delta = norm.cdf(d1)\n",
    "  cost = cost + S[m,j]*(delta - hedge)\n",
    "  call = S[m,j]*norm.cdf(d1) - K*np.exp(-r*tow)*norm.cdf(d2)\n",
    "  call_price.append(call)\n",
    "\n",
    "  #with hedge profit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  #without hedge profit\n",
    "  if j == 0:\n",
    "    without_hedge_pf.append(0)\n",
    "  else:\n",
    "    without_hedge_pf.append(call_price[j-1] - call_price[j])\n",
    "\n",
    "  without_hedge_pf_cum.append(sum(without_hedge_pf))\n",
    "\n",
    "  if str(j)[-1] ==  '9' or j == 0:\n",
    "    print(f'{m+1}번째 시나리오, {j}시점: \\n 주가: {S[m,j]:.5f},delta: {delta}, delta 변화분: {delta - hedge}, hedge cost: {cost}')\n",
    "\n",
    "\n",
    "\n",
    "  hedge = delta # hedge= delta_t-1 -> delta-hedge = Δholding\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(np.array(without_hedge_pf))\n",
    "print('-'*15)\n",
    "print(np.array(without_hedge_pf_cum))\n",
    "print('-'*15)\n",
    "print(np.array(call_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4sNtksHd5q-"
   },
   "outputs": [],
   "source": [
    "final_cost = []\n",
    "\n",
    "for i in range(M):\n",
    "  cost = 0\n",
    "  hedge = 0\n",
    "  for j in range(N):\n",
    "    tow = T - j*dt\n",
    "    d1 = (np.log(S[i,j]/K) + (r+0.5*sig**2)*tow)/(sig*np.sqrt(tow))\n",
    "    d2 = d1 - sig*np.sqrt(tow)\n",
    "    delta = norm.cdf(d1)\n",
    "    cost = cost + S[i,j]*(hedge- delta)\n",
    "    hedge = delta\n",
    "  if S[i,N] > K:\n",
    "    cost = cost + (hedge-1)*S[i,N] + K\n",
    "  else:\n",
    "    cost = cost + (hedge-0)*S[i,N]\n",
    "\n",
    "\n",
    "  final_cost.append(cost)\n",
    "\n",
    "print(pd.Series(final_cost).idxmax())\n",
    "\n",
    "plt.hist(final_cost,bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9IMFXqvQK37"
   },
   "source": [
    "# 딥 헤징 2부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X2-0QOzlqu-I"
   },
   "outputs": [],
   "source": [
    "r = 0.00\n",
    "sig = 0.2\n",
    "T = 30/365\n",
    "\n",
    "M = 20000\n",
    "N = 30\n",
    "\n",
    "dt = T/N\n",
    "rdt = r * dt\n",
    "sigsdt = sig * np.sqrt(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4oREp9svryIh"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "S0 = 100\n",
    "\n",
    "S = np.empty([M,N+1])\n",
    "S[:,0] =   S0 #np.full((1000,),S0) 둘다 똑같음\n",
    "\n",
    "rv = np.random.normal(rdt,sigsdt,(M,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PrqnU27iQx0j"
   },
   "outputs": [],
   "source": [
    "for i in range(M):\n",
    "  for j in range(N):\n",
    "    S[i,j+1] = S[i,j] * (1+rv[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CYh9vzeGQyzQ"
   },
   "outputs": [],
   "source": [
    "for i in range(M):\n",
    "  plt.plot(S[i,:])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdtGj9yAXtix"
   },
   "source": [
    "$(\\Delta_0 - 0) S_0\n",
    "+ (\\Delta_1 - \\Delta_0) S_1\n",
    "+ (\\Delta_2 - \\Delta_1) S_2\n",
    "+ \\cdots\n",
    "+ (\\Delta_{T-1} - \\Delta_{T-2}) S_{T-1}\n",
    "+ (\\Delta_T - \\Delta_{T-1}) S_T\n",
    "$\n",
    "\n",
    "지만, 만기 시점에는 다름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6wfaLHJwSHDR"
   },
   "outputs": [],
   "source": [
    "# Long 1 call with delta hedging\n",
    "\n",
    "\n",
    "S0 = 100\n",
    "K = 100\n",
    "call_list = np.empty((M,N))\n",
    "cost_list = []\n",
    "payoff_list = []\n",
    "\n",
    "for i in range(M):\n",
    "\n",
    "  hedge = 0\n",
    "  cost = 0\n",
    "\n",
    "\n",
    "\n",
    "  for j in range(N):\n",
    "    '''\n",
    "    r = 0.00\n",
    "    sig = 0.2 - j*0.004\n",
    "    T = 30/365\n",
    "\n",
    "    M = 1000\n",
    "    N = 30\n",
    "\n",
    "    dt = T/N\n",
    "    rdt = r * dt\n",
    "    sigsdt = sig * np.sqrt(dt)\n",
    "    '''\n",
    "    sig = 0.3 - j*0.004\n",
    "    tow = T - j*dt\n",
    "    d1 = (np.log(S[i,j]/K) + (r+0.5*sig**2)*tow)/(sig*np.sqrt(tow))\n",
    "    d2 = d1 - sig*np.sqrt(tow)\n",
    "    delta = norm.cdf(d1)\n",
    "\n",
    "\n",
    "\n",
    "    cost = cost + S[i,j]*(delta - hedge) # Δ_T-1 - Δ_T-2 까지\n",
    "    hedge = delta # hedge= delta_t-1 -> delta-hedge = Δholding\n",
    "\n",
    "    call = S[i,j]*norm.cdf(d1) - K*np.exp(-r*tow)*norm.cdf(d2)\n",
    "    call_list[i,j] = call\n",
    "\n",
    "  if i == M-1:\n",
    "    for k in range(M):\n",
    "      if call_list[k,0] - call_list[0,0] == 0:\n",
    "        pass\n",
    "      else:\n",
    "        print(f'{call_list[k,0]} is different to others')\n",
    "        break\n",
    "\n",
    "  payoff = -(cost - hedge * S[i,N] + np.maximum(S[i,N] - K, 0) - call_list[0,0])# 만기 시점 총 payoff\n",
    "  cost = cost - hedge * S[i,N] #만기 시점에 사놓은 주식 팔아서 생기는 이득 고려한 순수 '헷징 비용'\n",
    "  #cost = cost - hedge * S[i,N] + np.maximum(S[i,N] - K, 0) # 만기 시점 call opt 행사 유무까지 반영한 비용\n",
    "  payoff_list.append(payoff)\n",
    "  cost_list.append(cost)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHr6bhRiSjaQ"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,12))\n",
    "plt.subplot(2,1,1)\n",
    "plt.scatter(S[:,-1], cost_list, alpha =0.6)\n",
    "plt.title('Delta-Hedge Strategy Cost w/o maturity strike')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.scatter(S[:,-1], payoff_list, alpha = 0.6)\n",
    "plt.plot([S[:,-1].min(),S[:,-1].max()],[0.0,0.0], ':', color = 'red')\n",
    "plt.title('Delta-Hedge Strategy Payoff')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEqW033RgWa_"
   },
   "outputs": [],
   "source": [
    "a=[]\n",
    "for i in payoff_list:\n",
    "  if i >= 0:\n",
    "    a.append(1)\n",
    "  else:\n",
    "    a.append(0)\n",
    "a= pd.Series(a)\n",
    "a.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TM22goohlhy4"
   },
   "outputs": [],
   "source": [
    "payoff_df = pd.Series(payoff_list)\n",
    "df = pd.concat([pd.Series(S[:,-1]),payoff_df, a], axis = 1)\n",
    "df.columns = ['stock_price','payoff','over0']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "klksei11TRkq"
   },
   "outputs": [],
   "source": [
    "nd = rv.copy()\n",
    "nd = pd.DataFrame(nd)\n",
    "nd = pd.concat([nd,df['over0']], axis = 1)\n",
    "nd1 = nd.loc[nd['over0'] == 1]\n",
    "\n",
    "\n",
    "nd1 = nd.loc[nd['over0'] == 1].drop('over0', axis = 1).reset_index(drop = True)\n",
    "nd0 = nd.loc[nd['over0'] == 0].drop('over0', axis = 1).reset_index(drop = True)\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "for i in range(nd1.shape[0]):\n",
    "  plt.plot(nd1.iloc[i])\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "for i in range(nd0.shape[0]):\n",
    "  plt.plot(nd1.iloc[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9Bgkl6Ul-Fm"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "delta-hedging이 되면 나머지 Greeks에 대한 예견이 됨. 예컨대 우린 지금\n",
    "short call long stock하고 있으니, vol이 줄어들면\n",
    "(more precisely, realize vol <= implied vol)\n",
    "1 count 커짐 + 전체 payoff\n",
    "mean도 커짐.\n",
    "못믿겠으면 sig값이 시간에 따라 decreasing하게 해보거나 델타 헤징시의 sig\n",
    "를 줄여보셈\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMN0_OLbm4lR"
   },
   "outputs": [],
   "source": [
    "def bscall(S,K,T,r,sig):\n",
    "  d1 = (np.log(S/K) + (r+0.5*sig**2)*T)/(sig*np.sqrt(T))\n",
    "  d2 = d1 - sig * np.sqrt(T)\n",
    "  return S * norm.cdf(d1) - K*np.exp(-r*T) * norm.cdf(d2)\n",
    "\n",
    "def bsput(S,K,T,r,sig):\n",
    "  d1 = (np.log(S/K) + (r+0.5*sig**2)*T)/(sig*np.sqrt(T))\n",
    "  d2 = d1 - sig * np.sqrt(T)\n",
    "  return K*np.exp(-r*T) * norm.cdf(-d2) - S * norm.cdf(-d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eud1UycGt_LC"
   },
   "outputs": [],
   "source": [
    "print(bscall(S0,K,T,r,sig), bsput(S0,K,T,r,sig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3c_IiiZwFVH"
   },
   "source": [
    "$(\\Delta_0 - 0) S_0\n",
    "+ (\\Delta_1 - \\Delta_0) S_1\n",
    "+ (\\Delta_2 - \\Delta_1) S_2\n",
    "+ \\cdots\n",
    "+ (\\Delta_{T-1} - \\Delta_{T-2}) S_{T-1}\n",
    "+ (\\Delta_T - \\Delta_{T-1}) S_T\n",
    "$\n",
    "\n",
    "=\n",
    "\n",
    "\n",
    "![image.png](data:image/png;base64,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)\n",
    "$+ \\Delta_T S_T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nB90TjeVuF9o"
   },
   "outputs": [],
   "source": [
    "cost_list=[]\n",
    "payoff_list = []\n",
    "\n",
    "for i in range(M):\n",
    "  cost = 0\n",
    "  price = S[i,0]\n",
    "  for j in range(N):\n",
    "    tow = T - j*dt\n",
    "    d1 = (np.log(S[i,j]/K) + (r+0.5*sig**2)*tow)/(sig*np.sqrt(tow))\n",
    "    d2 = d1 - sig*np.sqrt(tow)\n",
    "    delta = norm.cdf(d1)\n",
    "\n",
    "    cost = cost + delta*(price - S[i,j+1])\n",
    "    price = S[i,j+1]\n",
    "\n",
    "  payoff = cost + np.maximum(S[i,N]-K,0)  - 2.2871506280449694\n",
    "  payoff_list.append(payoff)\n",
    "  cost_list.append(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MsH_uO5hxHfV"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,12))\n",
    "plt.subplot(2,1,1)\n",
    "plt.scatter(S[:,-1], cost_list, alpha =0.6)\n",
    "plt.title('Delta-Hedge Strategy Cost w/o maturity strike')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.scatter(S[:,-1], payoff_list, alpha = 0.6)\n",
    "plt.plot([S[:,-1].min(),S[:,-1].max()],[0.0,0.0], ':', color = 'red')\n",
    "plt.title('Delta-Hedge Strategy Payoff')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LT7TlNxvF1a0"
   },
   "source": [
    "#ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fl8W7MiNLYSU"
   },
   "outputs": [],
   "source": [
    "r = 0.00\n",
    "sig = 0.2\n",
    "T = 30/365\n",
    "\n",
    "M = 20000\n",
    "N = 30\n",
    "\n",
    "dt = T/N\n",
    "rdt = r * dt\n",
    "sigsdt = sig * np.sqrt(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UMfpbk9IygrP"
   },
   "outputs": [],
   "source": [
    "#minimizing hedge_cost (결국 이게 profit maximizing)\n",
    "\n",
    "my_input = []\n",
    "\n",
    "hedge_cost = keras.layers.Input(shape = (1,), name = 'hedge_cost')\n",
    "my_input.append(hedge_cost) # exactly same to my_input = my_input + [hedge_cost]\n",
    "\n",
    "price = keras.layers.Input(shape = (1,), name = 'S_0')\n",
    "my_input.append(price) # exactly same to my_input = my_input + [price]\n",
    "\n",
    "\n",
    "\n",
    "for j in range(3):\n",
    "  delta = tf.keras.layers.Dense(1, name = 'delta_'+str(j))(price)\n",
    "\n",
    "  new_price = Input(shape = (1,), name = 'S_'+str(j+1)) # S[i,j+1]\n",
    "  my_input.append(new_price)\n",
    "\n",
    "  price_inc = keras.layers.Subtract(name = 'price_inc_'+str(j))([price ,new_price]) #\n",
    "  cost = tf.keras.layers.Multiply(name = 'Multiply (Cost)_'+str(j))([delta, price_inc]) #  delta * (price - S[i,j+1])\n",
    "  hedge_cost= tf.keras.layers.Add(name = 'hedge_cost_'+str(j))([hedge_cost,cost]) # cost= cost + delta * (price - S[i,j+1]) -> hedge_cost = hedge_cost + cost\n",
    "\n",
    "  price = new_price\n",
    "\n",
    "\n",
    "\n",
    "input_vec = keras.layers.Concatenate(name = 'input')(my_input)\n",
    "\n",
    "hedge_costs = keras.layers.Dense(1, name = 'hedge_costs')(hedge_cost)\n",
    "\n",
    "output = tf.keras.layers.Dense(1, activation = 'linear', name = 'output')(input_vec)\n",
    "\n",
    "model = tf.keras.Model(inputs = my_input, outputs = output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGuoedNsIFFl"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Xt04bx2JyTr"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LoO7ip7eff27"
   },
   "outputs": [],
   "source": [
    "K=100\n",
    "\n",
    "my_input = []\n",
    "\n",
    "call = tf.keras.layers.Input(shape = (1,), name = 'call')\n",
    "my_input.append(call)\n",
    "\n",
    "hedge_cost= tf.keras.layers.Input(shape = (1,), name = 'hedge_cost')\n",
    "my_input.append(hedge_cost)\n",
    "\n",
    "price = tf.keras.layers.Input(shape = (1,), name = 'S0')\n",
    "my_input.append(price)\n",
    "\n",
    "for j in range(N):\n",
    "\n",
    "  delta = Dense(32, activation = 'tanh')(price)\n",
    "  delta = keras.layers.BatchNormalization()(delta)\n",
    "  delta = Dense(32, activation = 'relu')(delta)\n",
    "  delta = keras.layers.BatchNormalization()(delta)\n",
    "  delta = Dense(32, activation = 'tanh')(delta)\n",
    "  delta = keras.layers.BatchNormalization()(delta)\n",
    "  delta = Dense(1)(delta)\n",
    "\n",
    "  new_price = tf.keras.layers.Input(shape = (1,), name = 'S'+str(j+1))\n",
    "  #이렇게 해야 계속 for문 돌아가면서 S1,...SN까지 받음\n",
    "  my_input.append(new_price)\n",
    "\n",
    "  price_inc = tf.keras.layers.Subtract(name = 'price_inc_'+str(j))([price, new_price])\n",
    "  cost = tf.keras.layers.Multiply(name = 'Multiply_'+str(j))([delta, price_inc])\n",
    "  hedge_cost= tf.keras.layers.Add(name = 'hedge_cost_'+str(j))([hedge_cost,cost])\n",
    "  price = new_price\n",
    "\n",
    "payoff = tf.keras.layers.Lambda(lambda x : 0.5*(tf.abs(x-K) + x-K), name = 'payoff')(price)\n",
    "\n",
    "'''\n",
    "lambda는 입력 → 출력 함수 하나를 한 줄로 정의하는 문법이고,\n",
    "layers.Lambda는 그 함수를 “레이어”로 만들어 입력 텐서(price 등)에 적용하는 것이다.\n",
    "'''\n",
    "cum_cost = tf.keras.layers.Add(name = 'cum_cost')([hedge_cost, payoff])\n",
    "cum_cost = tf.keras.layers.Subtract(name = 'final_cum_cost')([cum_cost, call])\n",
    "\n",
    "model = tf.keras.Model(inputs = my_input, outputs = cum_cost)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eo49WEXpAnL9"
   },
   "outputs": [],
   "source": [
    "p = bscall(S0,K,T,r,sig) * np.ones([M,1])\n",
    "c = np.zeros([M,1])\n",
    "SS = [S[:,i].reshape(M,1) for i in range(N+1)]\n",
    "x = [p] + [c] + [SS[i] for i in range(N+1)]\n",
    "y = np.zeros([M,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DwTSvgZRGd_z"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'mse')\n",
    "model.fit(x,y, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXcbk2FcIDT9"
   },
   "outputs": [],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zdg__9PeNszX"
   },
   "outputs": [],
   "source": [
    "plt.hist(model.predict(x),bins = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLIEyW-r8-vg"
   },
   "source": [
    "# 숙제: Long Butterfly 제작 + ML으로 payoff 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxlL3lE69Fpd"
   },
   "source": [
    "## Long butterfly 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JPUn8BbDNydM"
   },
   "outputs": [],
   "source": [
    "K1 = 92.5\n",
    "K2 = 100\n",
    "K3 = 107.5\n",
    "\n",
    "S0=100\n",
    "\n",
    "ST = np.arange(50,151,1)\n",
    "\n",
    "\n",
    "#1. t=0 call price\n",
    "\n",
    "d1_1 = (np.log(S0/K1) + (r+0.5*sig**2)*T)/(sig*np.sqrt(T))\n",
    "d1_2 = (np.log(S0/K2) + (r+0.5*sig**2)*T)/(sig*np.sqrt(T))\n",
    "d1_3 = (np.log(S0/K3) + (r+0.5*sig**2)*T)/(sig*np.sqrt(T))\n",
    "\n",
    "d2_1 = d1_1 - sig*np.sqrt(T)\n",
    "d2_2 = d1_2 - sig*np.sqrt(T)\n",
    "d2_3 = d1_3 - sig*np.sqrt(T)\n",
    "\n",
    "call1 = S0 * norm.cdf(d1_1) - K1 * np.exp(-r*T) * norm.cdf(d2_1)\n",
    "call2 = S0 * norm.cdf(d1_2) - K2 * np.exp(-r*T) * norm.cdf(d2_2)\n",
    "call3 = S0 * norm.cdf(d1_3) - K3 * np.exp(-r*T) * norm.cdf(d2_3)\n",
    "\n",
    "#2. Maturyity payoff\n",
    "\n",
    "opts = -call1 + 2 * call2 -call3\n",
    "\n",
    "payoff1 = np.maximum(ST-K1,0)\n",
    "payoff2 = np.maximum(ST-K2,0)\n",
    "payoff3 = np.maximum(ST-K3,0)\n",
    "\n",
    "pf_payoff = payoff1 - 2*payoff2 + payoff3\n",
    "\n",
    "pf_profit = pf_payoff + opts\n",
    "\n",
    "print(pf_profit)\n",
    "\n",
    "'''\n",
    "cost_list=[]\n",
    "payoff_list = []\n",
    "\n",
    "for i in range(M):\n",
    "  cost = 0\n",
    "  price = S[i,0]\n",
    "  for j in range(N):\n",
    "    tow = T - j*dt\n",
    "    d1 = (np.log(S[i,j]/K) + (r+0.5*sig**2)*tow)/(sig*np.sqrt(tow))\n",
    "    d2 = d1 - sig*np.sqrt(tow)\n",
    "    delta = norm.cdf(d1)\n",
    "\n",
    "    cost = cost + delta*(price - S[i,j+1])\n",
    "    price = S[i,j+1]\n",
    "\n",
    "  payoff = cost + np.maximum(S[i,N]-K,0)  - 2.2871506280449694\n",
    "  payoff_list.append(payoff)\n",
    "  cost_list.append(cost)\n",
    "  '''\n",
    "\n",
    "print(call1,call2,call3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FD9mI7Nt5NZe"
   },
   "outputs": [],
   "source": [
    "logS = np.log(S)\n",
    "dlogS = logS[:,1:] - logS[:,:-1]      # shape (M, N) 1~30 - 0~29\n",
    "RV = np.cumsum(dlogS**2, axis=1)      # shape (M, N)\n",
    "RV = [RV[:,i].reshape((M,1)) for i in range(N)][:-1]\n",
    "RV = [np.zeros((M,1))] +[RV[i] for i in range(len(RV))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kEtAlwyZsQn1"
   },
   "outputs": [],
   "source": [
    "RV[29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vn6bN5Zk-27k"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(ST,pf_profit)\n",
    "plt.title('Long Butterfly Profit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OFjT0Jf2BDRp"
   },
   "outputs": [],
   "source": [
    "# ML -> Long Butterfly Spread\n",
    "my_input = []\n",
    "\n",
    "initial_cf = tf.keras.layers.Input(shape = (1,), name = 'initial_cf')\n",
    "my_input.append(initial_cf)\n",
    "\n",
    "hedge_cost= tf.keras.layers.Input(shape = (1,), name = 'hedge_cost')\n",
    "my_input.append(hedge_cost)\n",
    "\n",
    "tau = tf.keras.layers.Input(shape=(1,), name='tau')\n",
    "my_input.append(tau)\n",
    "\n",
    "realised_var = tf.keras.layers.Input(shape = (1,), name = 'realised_var')\n",
    "my_input.append(realised_var)\n",
    "\n",
    "price = tf.keras.layers.Input(shape = (1,), name = 'S0')\n",
    "my_input.append(price)\n",
    "\n",
    "\n",
    "\n",
    "for j in range(N):\n",
    "\n",
    "  state = tf.keras.layers.Concatenate(name = 'state_'+str(j))([price, tau, realised_var])\n",
    "\n",
    "  delta = Dense(128, activation = 'leaky_relu')(state)\n",
    "  delta = keras.layers.BatchNormalization()(delta)\n",
    "  delta = Dense(128, activation = 'leaky_relu')(delta)\n",
    "  delta = keras.layers.BatchNormalization()(delta)\n",
    "  delta = Dense(128, activation = 'leaky_relu')(delta)\n",
    "  delta = Dense(1, activation = 'sigmoid')(delta)\n",
    "\n",
    "  if not j == N-1:\n",
    "    new_tau = tf.keras.layers.Input(shape = (1,), name = 'tau'+str(j+1))\n",
    "    my_input.append(new_tau)\n",
    "    tau = new_tau\n",
    "\n",
    "    new_var = tf.keras.layers.Input(shape = (1,), name = 'var'+str(j+1))\n",
    "    my_input.append(new_var)\n",
    "    realised_var = new_var\n",
    "\n",
    "\n",
    "  new_price = tf.keras.layers.Input(shape = (1,), name = 'S'+str(j+1))\n",
    "  my_input.append(new_price)\n",
    "\n",
    "  price_inc = tf.keras.layers.Subtract(name = 'price_inc_'+str(j))([price, new_price])\n",
    "  cost = tf.keras.layers.Multiply(name = 'Multiply_'+str(j))([delta, price_inc])\n",
    "  hedge_cost= tf.keras.layers.Add(name = 'hedge_cost_'+str(j))([hedge_cost,cost])\n",
    "  price = new_price\n",
    "\n",
    "\n",
    "stock_profit = - hedge_cost\n",
    "payoff = tf.keras.layers.Lambda(lambda x :\n",
    "                                  0.5*(tf.abs(x-K1) + x-K1)\n",
    "                                  - 2* 0.5*(tf.abs(x-K2) + x-K2)\n",
    "                                  + 0.5*(tf.abs(x-K3) + x-K3),\n",
    "                                  name = 'payoff')(price)\n",
    "\n",
    "opt = tf.keras.layers.Add(name = 'opt')([initial_cf, payoff])\n",
    "goal = tf.keras.layers.Add(name = 'goal')([opt, stock_profit])\n",
    "\n",
    "\n",
    "stock_model = tf.keras.Model(inputs = my_input, outputs = stock_profit)\n",
    "model = tf.keras.Model(inputs = my_input, outputs = goal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_pJTM4OdcIe"
   },
   "outputs": [],
   "source": [
    "[i.name for i in model.inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5dbjqL84_xk"
   },
   "outputs": [],
   "source": [
    "opts_mtx = opts * np.ones([M,1])\n",
    "c = np.zeros([M,1])\n",
    "SS = [S[:,i].reshape(M,1) for i in range(N+1)]\n",
    "tau_list = [(T - j*dt) * np.ones((M,1)) for j in range(N)]\n",
    "RV = RV\n",
    "\n",
    "variables = []\n",
    "for i in range(N):\n",
    "    variables.append(tau_list[i])\n",
    "    variables.append(RV[i])\n",
    "    variables.append(SS[i])\n",
    "\n",
    "variables.append(SS[-1])\n",
    "\n",
    "\n",
    "x = [opts_mtx] + [c] + [variables[i] for i in range(len(variables))]\n",
    "y = np.zeros([M,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G4phPAyh4_xl"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'mse')\n",
    "model.fit(x,y, epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AafzRKNS_pot"
   },
   "outputs": [],
   "source": [
    "stock_pnl = stock_model.predict(x)\n",
    "plt.scatter(S[:,-1], stock_pnl, alpha=0.5)\n",
    "plt.xlabel(\"Terminal Price $S_T$\")\n",
    "plt.ylabel(\"Stock Hedging P&L\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--s_L9qIIKi6"
   },
   "outputs": [],
   "source": [
    "# 예측\n",
    "stock_pnl = stock_model.predict(x).ravel()\n",
    "# payoff 계산(넘파이로)\n",
    "ST = S[:,-1]\n",
    "payoff_vals = opts + np.maximum(ST-K1,0) - 2*np.maximum(ST-K2,0) + np.maximum(ST-K3,0)\n",
    "\n",
    "# replicated payoff (모형이 만들었다고 주장하는 것)\n",
    "replicated = stock_pnl   # initial_cf를 상수로 넣었다면 그 값\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnZVx5U-SFTV"
   },
   "outputs": [],
   "source": [
    "plt.scatter(ST, payoff_vals, alpha=0.3, label=\"true payoff\")\n",
    "plt.scatter(ST, replicated, alpha=0.3, label=\"stock_pnl\")\n",
    "plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQ5RsCddSMo-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6osYiO2SmiS"
   },
   "source": [
    "# 딥헤징 ３부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSVT6jAISrbb"
   },
   "outputs": [],
   "source": [
    "r = 0.00\n",
    "sig = 0.2\n",
    "T = 30/365\n",
    "\n",
    "M = 1000\n",
    "N = 30\n",
    "\n",
    "dt = T/N\n",
    "rdt = r * dt\n",
    "sigsdt = sig * np.sqrt(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9mK7Saf9Srbc"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "S0 = 1\n",
    "K = 1\n",
    "\n",
    "S = np.empty([M,N+1])\n",
    "S[:,0] =   S0 #np.full((1000,),S0) 둘다 똑같음\n",
    "\n",
    "rv = np.random.normal(rdt,sigsdt,(M,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XmWNTKlpSrbc"
   },
   "outputs": [],
   "source": [
    "for i in range(M):\n",
    "  for j in range(N):\n",
    "    S[i,j+1] = S[i,j] * (1+rv[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHgYlwAISrbc"
   },
   "outputs": [],
   "source": [
    "for i in range(M):\n",
    "  plt.plot(S[i,:])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D4Zet8JSSvTo"
   },
   "outputs": [],
   "source": [
    "def bscall(S,K,T,r,sig):\n",
    "  d1 = (np.log(S/K) + (r+0.5*sig**2)*T)/(sig*np.sqrt(T))\n",
    "  d2 = d1 - sig * np.sqrt(T)\n",
    "  return S * norm.cdf(d1) - K*np.exp(-r*T) * norm.cdf(d2)\n",
    "\n",
    "def bsput(S,K,T,r,sig):\n",
    "  d1 = (np.log(S/K) + (r+0.5*sig**2)*T)/(sig*np.sqrt(T))\n",
    "  d2 = d1 - sig * np.sqrt(T)\n",
    "  return K*np.exp(-r*T) * norm.cdf(-d2) - S * norm.cdf(-d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bkEGJ0OYOhI"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ahwvZC0DS5R5"
   },
   "outputs": [],
   "source": [
    "my_input = []\n",
    "\n",
    "call = tf.keras.layers.Input(shape = (1,), name = 'call')\n",
    "my_input.append(call)\n",
    "\n",
    "hedge_cost= tf.keras.layers.Input(shape = (1,), name = 'hedge_cost')\n",
    "my_input.append(hedge_cost)\n",
    "\n",
    "price = tf.keras.layers.Input(shape = (1,), name = 'S0')\n",
    "my_input.append(price)\n",
    "\n",
    "for j in range(N):\n",
    "\n",
    "  delta = Dense(32, activation = 'leaky_relu')(price)\n",
    "  delta = keras.layers.BatchNormalization()(delta)\n",
    "  delta = Dense(32, activation = 'leaky_relu')(delta)\n",
    "  delta = keras.layers.BatchNormalization()(delta)\n",
    "  delta = Dense(32, activation = 'leaky_relu')(delta)\n",
    "  delta = Dense(1, activation = 'sigmoid')(delta)\n",
    "\n",
    "  new_price = tf.keras.layers.Input(shape = (1,), name = 'S'+str(j+1))\n",
    "  #이렇게 해야 계속 for문 돌아가면서 S1,...SN까지 받음\n",
    "  my_input.append(new_price)\n",
    "\n",
    "  price_inc = tf.keras.layers.Subtract(name = 'price_inc_'+str(j))([price, new_price])\n",
    "  cost = tf.keras.layers.Multiply(name = 'Multiply_'+str(j))([delta, price_inc])\n",
    "  hedge_cost= tf.keras.layers.Add(name = 'hedge_cost_'+str(j))([hedge_cost,cost])\n",
    "  price = new_price\n",
    "\n",
    "payoff = tf.keras.layers.Lambda(lambda x : 0.5*(tf.abs(x-K) + x-K), name = 'payoff')(price)\n",
    "cum_cost = tf.keras.layers.Add(name = 'cum_cost')([hedge_cost, payoff])\n",
    "cum_cost = tf.keras.layers.Subtract(name = 'final_cum_cost')([cum_cost, call])\n",
    "stock_profit = - hedge_cost\n",
    "\n",
    "\n",
    "stock_model = tf.keras.Model(inputs = my_input, outputs = stock_profit)\n",
    "model = tf.keras.Model(inputs = my_input, outputs = cum_cost)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdTcOhhTYOhH"
   },
   "outputs": [],
   "source": [
    "p = bscall(S0,K,T,r,sig) * np.ones([M,1])\n",
    "c = np.zeros([M,1])\n",
    "SS = [S[:,i].reshape(M,1) for i in range(N+1)]\n",
    "x = [p] + [c] + [SS[i] for i in range(N+1)]\n",
    "y = np.zeros([M,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovXJHSB-YOhI"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'mse')\n",
    "hist = model.fit(x,y, batch_size= 32, epochs = 30, verbose = True, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1SguphqYOhI"
   },
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VYs2W5_Ag1Xq"
   },
   "outputs": [],
   "source": [
    "plt.hist(stock_model.predict(x),bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k4dhL_7mg9on"
   },
   "outputs": [],
   "source": [
    "plt.scatter(S[:,-1],stock_model.predict(x), alpha = 0.5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6FpSqwhhWOS"
   },
   "outputs": [],
   "source": [
    "# 예측\n",
    "stock_pnl = stock_model.predict(x).ravel()\n",
    "# payoff 계산(넘파이로)\n",
    "ST = S[:,-1]\n",
    "payoff_vals = opts + np.maximum(ST-K1,0) - 2*np.maximum(ST-K2,0) + np.maximum(ST-K3,0)\n",
    "\n",
    "# replicated payoff (모형이 만들었다고 주장하는 것)\n",
    "replicated = stock_pnl   # initial_cf를 상수로 넣었다면 그 값\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBLrg-7Oy9zZ"
   },
   "source": [
    "# Buhler - Deep Hedging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7V9cSv40ujo"
   },
   "source": [
    "## 기초 텐서 조작 및 자동 미분 (Autograd)\n",
    "\n",
    "$\\frac{\\partial C}{\\partial \\theta}$ (비용 함수에 대한 파라미터 미분)를 구하는 과정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QUND5P8zj-cO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 1. 텐서 생성 (Requires_grad=True는 TF의 Variable과 유사하게 그래디언트 추적을 의미)\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "w = torch.tensor([0.5, 0.5, 0.5], requires_grad=True)\n",
    "\n",
    "# 2. 연산 수행 (Forward)\n",
    "y = torch.dot(x, w)  # 내적\n",
    "loss = (y - 5.0) ** 2  # 간단한 MSE Loss\n",
    "\n",
    "# 3. 역전파 (Backward)\n",
    "# PyTorch는 명시적인 Tape(TF의 GradientTape) 없이 loss.backward()로 호출\n",
    "loss.backward()\n",
    "\n",
    "# 4. 그래디언트 확인\n",
    "print(f\"w의 기울기: {w.grad}\") # d(Loss)/dw\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bEhHWRs4iiN"
   },
   "source": [
    "**Note: PyTorch는 그래디언트를 누적(accumulate)하는 특성이 있어, 학습 Loop에서 optimizer.zero_grad()를 통해 매번 그래디언트를 초기화해줘야 합니다.**\n",
    "\n",
    "Batch 1\n",
    "\n",
    "loss = ...\n",
    "loss.backward()\n",
    "\n",
    "현재 w.grad: 10 (첫 번째 배치의 기울기)\n",
    "\n",
    "optimizer.step() # 파라미터 업데이트 (10만큼 반영)\n",
    "\n",
    "Batch 2 (여기서 zero_grad()를 깜빡함!)\n",
    "loss = ...\n",
    "loss.backward()\n",
    "\n",
    "\n",
    "현재 w.grad: 20 (10 + 10) -> !?!?!?\n",
    "원래는 이번 배치의 기울기인 10이어야 하는데, 이전 것이 남아서 합쳐짐\n",
    "\n",
    "optimizer.step() # 파라미터 업데이트 (20만큼 반영 -> 학습이 엉뚱하게 튐)\n",
    "\n",
    "\n",
    "Batch 1\n",
    "\n",
    "\n",
    "optimizer.zero_grad() # 쓰레기통 비우기 (w.grad = 0)\n",
    "\n",
    "loss.backward()       # w.grad = 0 + 10 = 10\n",
    "\n",
    "optimizer.step()\n",
    "\n",
    "Batch 2\n",
    "\n",
    "optimizer.zero_grad() # 쓰레기통 비우기 (w.grad = 0)\n",
    "\n",
    "loss.backward()       # w.grad = 0 + 10 = 10 (정상!)\n",
    "\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iw-s2ILk4Xh2"
   },
   "source": [
    "## Deep-Hedging LSTM 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cAIKjcDDzhGZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DeepHedgingModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim=1):\n",
    "        super(DeepHedgingModel, self).__init__()\n",
    "        '''\n",
    "        PyTorch에서 모델을 만들 때는 보통 nn.Module이라는 기본 클래스를 상속받습니다. nn.Module 안에는 신경망 모델이 동작하는 데 꼭 필요한 복잡한 기능들(파라미터 추적, GPU 이동, 레이어 등록 등)이 이미 구현되어 있습니다.\n",
    "\n",
    "        super(...).__init__()을 호출하는 이유는 \"내가 만든 모델(DeepHedgingModel)도 nn.Module이 가진 그 기능들을 그대로 초기화해서 쓰겠다\"고 선언하는 것입니다.\n",
    "\n",
    "        2. 코드의 구성 요소\n",
    "        super(): 부모 클래스(여기서는 nn.Module)를 가리킵니다.\n",
    "\n",
    "        DeepHedgingModel: 현재 본인이 정의하고 있는 클래스의 이름입니다.\n",
    "\n",
    "        self: 현재 생성된 인스턴스 자기 자신을 의미합니다.\n",
    "\n",
    "        .__init__(): 부모 클래스의 초기화 함수(생성자)를 실행하라는 뜻입니다.\n",
    "        '''\n",
    "\n",
    "        # LSTM 레이어 정의\n",
    "        # input_dim: 시장 정보의 수 (예: 주가, 변동성, 이전 델타 등)\n",
    "        # hidden_dim: 정보를 압축할 은닉 노드 수\n",
    "        # batch_first=True: 입력 데이터 형태를 (Batch, Time, Feat)로 설정\n",
    "        # Batch: 샘플 크기 Time: 말 그대로 며칠 동안의 데이터 인지 Feat: 말 그대로 column 개수\n",
    "        # ex) (1000,20,3): 1000개의 MC 경로가 있고, 20일치이며, 사용하는 데이터가 3개(주가, vol, current delta 처럼)다.\n",
    "        self.lstm = nn.LSTM(input_size=input_dim,\n",
    "                            hidden_size=hidden_dim,\n",
    "                            num_layers=3, #hidden layer 개수\n",
    "                            batch_first=True)\n",
    "\n",
    "        # 출력 레이어 (델타 산출)\n",
    "        # 0과 1 사이의 비중을 출력하기 위해 Tanh나 Sigmoid를 쓰기도 하지만,\n",
    "        # 논문에서는 제약조건에 따라 활성화 함수가 달라질 수 있음\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        # fc indicates fully connected(dense) layer, 즉 마지막 출력 layer로 바로 앞 hidden layer를 전부 받겠다.\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "        # 이건 마지막 출력층에만 가해지는 activaion funciton -> 엥 그럼 각 hidden layer는요?\n",
    "        # 그게 이미 내장되어 있음. 보통 tanh이랑 sigmoid임. -> 엥 왜요?\n",
    "        # 그게 가장 안정적이고 효과가 좋음. 흔히 수정 안하고, 혹여나 자기가 바꾸고 싶으면 아래와 같이 층을 나눠줘야함.\n",
    "\n",
    "        '''\n",
    "        # 이런 식으로 짜면 층 사이에 원하는 함수를 넣을 수 있습니다.\n",
    "        self.lstm1 = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.relu = nn.ReLU() # 층 사이에 넣고 싶은 함수\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "        # forward 함수에서\n",
    "        out, _ = self.lstm1(x)\n",
    "        out = self.relu(out) # 1층 통과 후 ReLU 적용\n",
    "        out, _ = self.lstm2(out) # 그 다음 2층 통과\n",
    "        '''\n",
    "\n",
    "    def forward(self, x, prev_hedge=None):\n",
    "        \"\"\"\n",
    "        x shape: (Batch Size, Time Steps, Features)\n",
    "        \"\"\"\n",
    "        # 1. LSTM 통과\n",
    "        # out shape: (Batch, Time, Hidden) -> 모든 시점의 은닉 상태\n",
    "        # (h_n, c_n): 마지막 시점의 상태 (여기선 사용 안 함)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "\n",
    "        # 2. 델타 계산 (모든 타임 스텝에 대해)\n",
    "        # Deep Hedging은 만기까지의 '모든 시점'에서 리밸런싱이 일어나므로\n",
    "        # 전체 시퀀스(lstm_out)를 다 사용합니다.\n",
    "        deltas = self.activation(self.fc(lstm_out))\n",
    "\n",
    "        return deltas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "142SAQQW4cdA"
   },
   "source": [
    "## MC Simulation & Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DdH_0x2dynQo"
   },
   "outputs": [],
   "source": [
    "def generate_gbm(n_paths, n_steps, t_maturity, mu, sigma, s_0, device='cpu'):\n",
    "    \"\"\"\n",
    "    n_paths: 시뮬레이션 경로 수 (Batch Size) = M\n",
    "    n_steps: 리밸런싱 횟수 (Time Steps) = N\n",
    "    t_maturity: 만기 (년 단위, ex: 30/365)\n",
    "    mu: 연간 기대 수익률 (Drift)\n",
    "    sigma: 연간 변동성 (Volatility)\n",
    "    s_0: 초기 주가\n",
    "    \"\"\"\n",
    "    dt = t_maturity / n_steps\n",
    "\n",
    "    # 1. 브라운 운동의 증분(dW) 생성 (정규분포)\n",
    "    # shape: (Batch, Steps)\n",
    "    dw = torch.randn(n_paths, n_steps, device=device) * torch.sqrt(torch.tensor(dt)) # = ε_t * root dt\n",
    "\n",
    "    # 2. 주가 경로 계산 (Vectorized)\n",
    "    # Prerequiste: Ito's y = lnS_t &  S_t follows GBM\n",
    "    # S_t = S_0 * exp( (mu - 0.5*sigma^2)*t + sigma*W_t )\n",
    "    # 누적합(cumsum)을 이용해 한 번에 계산\n",
    "\n",
    "    drift = (mu - 0.5 * sigma**2) * dt\n",
    "    diffusion = sigma * dw\n",
    "\n",
    "    # discrete log return\n",
    "    log_returns = drift + diffusion\n",
    "\n",
    "    # 로그 수익률 누적\n",
    "    log_returns_cum = torch.cumsum(drift + diffusion, dim=1)\n",
    "\n",
    "    # 초기 주가와 결합 (t=0 시점 추가)\n",
    "    ones = torch.zeros(n_paths, 1, device=device) # t=0 시점의 로그 수익률은 0\n",
    "    log_returns_cum = torch.cat((ones, log_returns_cum), dim=1)\n",
    "\n",
    "    paths = s_0 * torch.exp(log_returns_cum)\n",
    "    paths_3d = paths.unsqueeze(-1)\n",
    "\n",
    "    # Return shape: (Batch Size, Time Steps + 1, 1) -> Feature 차원 추가\n",
    "    # 우리가 넣는건 batch(경로 개수) & time(time개수) & 'feature'(주가 등의 data)의 3차원 이므로 지금 2차원으로 구성된 것에\n",
    "    # 추가 해줘야함. unqueeze(n)은 \"n번째에 차원 추가해라\" 란 의미 squeeze는 줄이는거\n",
    "    return paths_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pE-ioaqcAhkz"
   },
   "outputs": [],
   "source": [
    "#Loss Functions\n",
    "\n",
    "def entropic_loss(pnl, risk_aversion=1.0):\n",
    "    # pnl: (batch_size,)\n",
    "    x = -risk_aversion * pnl\n",
    "    # log(mean(exp(x))) = logsumexp(x) - log(N)\n",
    "    # logsumexp는 내부적으로 max 값을 빼서 계산하므로 inf가 안 뜸\n",
    "    loss = (1/risk_aversion) * (torch.logsumexp(x, dim=0) - torch.log(torch.tensor(x.size(0), device=pnl.device)))\n",
    "    return loss\n",
    "\n",
    "def cvar_loss(pnl, alpha=0.05):\n",
    "    \"\"\"\n",
    "    pnl: (Batch Size,) 형태의 텐서. 모델의 헷징 결과로 얻은 최종 손익.\n",
    "    alpha: 상위 몇 %의 악성 손실을 볼 것인가 (보통 1%, 5%)\n",
    "    \"\"\"\n",
    "    # 1. P&L을 오름차순 정렬 (손실이 큰 순서대로, 즉 값이 작은 순서대로)\n",
    "    sorted_pnl, _ = torch.sort(pnl)\n",
    "\n",
    "    # 2. 하위 alpha%에 해당하는 인덱스 계산\n",
    "    n_samples = pnl.size(0)\n",
    "    cutoff_index = int(n_samples * alpha)\n",
    "\n",
    "    # 3. 하위 alpha%의 평균 계산 (Expected Shortfall)\n",
    "    # pnl이 이익(+)일 수도 손실(-)일 수도 있음.\n",
    "    # CVaR은 보통 '손실의 크기'를 양수로 표현하므로 -를 붙여줌.\n",
    "    # 즉, -100원이면 손실이 100원이므로 Loss는 100이 되어야 함.\n",
    "    tail_loss = -torch.mean(sorted_pnl[:cutoff_index])\n",
    "\n",
    "    return tail_loss\n",
    "\n",
    "def mean_loss(pnl):\n",
    "  mse = pnl ** 2\n",
    "  return torch.mean(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_8Hr9JZpo2B7"
   },
   "outputs": [],
   "source": [
    "def bscall(S,K,T,r,sig):\n",
    "  d1 = (np.log(S/K) + (r+0.5*sig**2)*T)/(sig*np.sqrt(T))\n",
    "  d2 = d1 - sig * np.sqrt(T)\n",
    "  return S * norm.cdf(d1) - K*np.exp(-r*T) * norm.cdf(d2)\n",
    "\n",
    "def bsput(S,K,T,r,sig):\n",
    "  d1 = (np.log(S/K) + (r+0.5*sig**2)*T)/(sig*np.sqrt(T))\n",
    "  d2 = d1 - sig * np.sqrt(T)\n",
    "  return K*np.exp(-r*T) * norm.cdf(-d2) - S * norm.cdf(-d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YT1BxgjtE5l"
   },
   "source": [
    "## Deep-Hedging vs BS Delta Hedging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McrL74jH6bEy"
   },
   "source": [
    "### W/O Transaction Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RERJfnCEBfx1"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# --- 하이퍼파라미터 설정 ---\n",
    "M = 20000   # 배치 사이즈 (User Code의 주석 참고)\n",
    "N = 30     # (Time Steps)\n",
    "T = 30/365\n",
    "mean = 0.0\n",
    "sig = 0.2\n",
    "S_0 = 100.0\n",
    "K = 100.0   # ATM 옵션\n",
    "initial_cf = bscall(S_0, K, T, mean, sig)\n",
    "\n",
    "# 디바이스 설정 (GPU 권장)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- 모델 초기화 ---\n",
    "# input_dim=1 (주가 정보만 사용한다고 가정)\n",
    "# hidden_dim=32\n",
    "model = DeepHedgingModel(input_dim=1, hidden_dim=32).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# --- 학습 루프 ---\n",
    "print(\"Training Start...\")\n",
    "for epoch in range(1001): # 500 에포크\n",
    "\n",
    "    # 1. 데이터 생성 (매 에포크마다 새로운 시뮬레이션 -> 오버피팅 방지)\n",
    "    # prices shape: (Batch, Steps+1, 1)\n",
    "    prices = generate_gbm(M, N, T, mean, sig, S_0, device)\n",
    "\n",
    "    # 2. 모델 예측 (Action)\n",
    "    # prices는 t=0 ~ t=T까지 있음.\n",
    "    # 모델에는 t=0 ~ t=T-1 까지의 정보를 주고, t=0 ~ t=T-1 시점의 델타를 구함\n",
    "    inputs = prices[:, :-1, :] # 마지막 만기 시점 제외\n",
    "\n",
    "    # deltas shape: (Batch, Steps, 1)\n",
    "    # User Code의 forward에서 squeeze가 없다면 (Batch, Steps, 1)로 나옴\n",
    "    deltas = model(inputs)\n",
    "\n",
    "    # 3. P&L 계산 (Financial Logic)\n",
    "    # 옵션 Payoff (Call Option): Max(S_T - K, 0)\n",
    "    S_T = prices[:, -1, 0]\n",
    "    option_payoff = torch.relu(S_T - K)\n",
    "\n",
    "    # 4. 헷징 포트폴리오의 가치 변화\n",
    "    price_changes = prices[:, 1:, 0] - prices[:, :-1, 0] # (Batch, Steps)\n",
    "\n",
    "    # 텐서 shape 맞추기 (Batch, Steps)\n",
    "    deltas = deltas.squeeze(-1)\n",
    "\n",
    "    # [수정 전 - no transaction cost]\n",
    "\n",
    "    # 헷징 수익 = sum(델타 * 주가변동)\n",
    "    # ΣDelta_t * (S_{t+1} - S_t) -> 손해면 마이너스로 나옴\n",
    "    hedging_pnl = torch.sum(deltas * price_changes, dim=1)\n",
    "\n",
    "\n",
    "    # 최종 P&L = 옵션 매도 프리미엄(생략 가능) + 헷징 수익 - 만기 Payoff 지불\n",
    "    # 여기서는 '순수 헷징 오차'를 줄이는 것이 목표이므로 프리미엄은 제외하고\n",
    "    # Wealth = Hedging PnL - Liability 로 봅니다.\n",
    "    total_pnl = hedging_pnl - option_payoff # 얘 평균이 결국 BS Call Price로 수렴하는지 봐야함. 그게 asset pricing에서 말하는 option premium이니깐\n",
    "    final_pnl = total_pnl + initial_cf\n",
    "    # 4. Loss 계산 (CVaR)\n",
    "    loss = cvar_loss(total_pnl) # 하위 5% 상황 방어\n",
    "    loss_mse = mean_loss(total_pnl)\n",
    "    loss_entropy = entropic_loss(total_pnl)\n",
    "\n",
    "    # 5. 역전파 및 업데이트\n",
    "    optimizer.zero_grad() # [중요] 그래디언트 초기화\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch} | CVaR Loss: {loss.item():.4f} | Mean PnL: {total_pnl.mean().item():.8f} | Mean PnL - BSCALL : {final_pnl.mean().item():.8f}\")\n",
    "        #print(f\"Epoch {epoch} | MSE Loss: {loss_mse.item():.4f} | Mean PnL: {total_pnl.mean().item():.8f}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Training Finished. BSCALL PRICE : {initial_cf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f3VqQiT5C8zQ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "S_T_np = S_T.detach().cpu().numpy()\n",
    "option_payoff_np = option_payoff.detach().cpu().numpy()\n",
    "hedging_pnl_np = hedging_pnl.detach().cpu().numpy()          # shape (M,)\n",
    "final_pnl_np = final_pnl.detach().cpu().numpy()\n",
    "\n",
    "# ---- Plot 1: S_T histogram ----\n",
    "plt.figure()\n",
    "plt.hist(S_T_np, bins=50)\n",
    "plt.title(\"Histogram of $S_T$\")\n",
    "plt.xlabel(\"$S_T$\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---- Plot 2: hedging_pnl histogram ----\n",
    "plt.figure()\n",
    "plt.hist(hedging_pnl_np, bins=80)\n",
    "plt.title(\"Histogram of Hedging PnL\")\n",
    "plt.xlabel(\"hedging_pnl\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---- Plot 3: scatter S_T vs hedging_pnl ----\n",
    "plt.figure()\n",
    "plt.scatter(S_T_np, hedging_pnl_np, s=8)\n",
    "plt.scatter(S_T_np, option_payoff_np)\n",
    "plt.title(\"Scatter: $S_T$ vs Hedging PnL\")\n",
    "plt.xlabel(\"$S_T$\")\n",
    "plt.ylabel(\"hedging_pnl\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---- Plot 4: scatter S_T vs hedging_pnl ----\n",
    "plt.figure()\n",
    "plt.scatter(S_T_np, final_pnl_np, s=8, alpha = 0.4)\n",
    "plt.plot([S_T_np.min(),S_T_np.max()],[0.0,0.0], ':', color = 'red')\n",
    "plt.title(\"Scatter: $S_T$ vs Final PnL\")\n",
    "plt.xlabel(\"$S_T$\")\n",
    "plt.ylabel(\"Final PnL\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "pd.Series(final_pnl_np).describe()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6orWo8KGDTQA"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Deep-Hedging Model\n",
    "'''\n",
    "\n",
    "# 모델을 평가 모드로 전환 (Dropout, BatchNorm 비활성화)\n",
    "model.eval()\n",
    "\n",
    "#test stock data\n",
    "prices_test = generate_gbm(M, N, T, mean, sig, S_0, device)\n",
    "\n",
    "with torch.no_grad(): # 기울기 계산을 끄고 메모리 절약\n",
    "\n",
    "    # Scikit-learn의 model.predict(X) 대신 아래와 같이 사용\n",
    "    predicted_delta = model(prices_test[:, :-1, :])\n",
    "    predicted_delta = predicted_delta.squeeze(-1)\n",
    "\n",
    "    S_T_test = prices_test[:, -1, 0]\n",
    "    option_payoff_test = torch.relu(S_T_test - K)\n",
    "\n",
    "    price_changes_test = prices_test[:, 1:, 0] - prices_test[:, :-1, 0] # (Batch, Steps)\n",
    "\n",
    "\n",
    "    hedging_pnl_test = torch.sum(predicted_delta * price_changes_test, dim=1)\n",
    "\n",
    "\n",
    "    total_pnl_test = hedging_pnl_test - option_payoff_test # 얘 평균이 결국 BS Call Price로 수렴하는지 봐야함. 그게 asset pricing에서 말하는 option premium이니깐\n",
    "    final_pnl_test = total_pnl_test + initial_cf\n",
    "\n",
    "    # 4. Loss 계산 (CVaR)\n",
    "    loss = cvar_loss(total_pnl_test) # 하위 5% 상황 방어\n",
    "    loss_mse = mean_loss(total_pnl_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ptJpmKA6KcY-"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import Normal\n",
    "\n",
    "# 1. Black-Scholes Delta 계산 함수 (Vectorized)\n",
    "def calculate_bs_delta(S, time_remaining, K, r, sigma):\n",
    "    \"\"\"\n",
    "    S: 현재 주가 (Tensor)\n",
    "    time_remaining: 잔여 만기 (Tensor)\n",
    "    K: 행사가\n",
    "    r: 무위험 이자율\n",
    "    sigma: 변동성\n",
    "    \"\"\"\n",
    "    # 만기 시점(time_remaining=0) 근처에서의 0으로 나누기 에러 방지용 epsilon\n",
    "    epsilon = 1e-8\n",
    "\n",
    "    d1 = (torch.log(S / K) + (r + 0.5 * sigma ** 2) * time_remaining) / (sigma * torch.sqrt(time_remaining) + epsilon)\n",
    "\n",
    "    normal = Normal(0, 1)\n",
    "    delta = normal.cdf(d1)\n",
    "\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CsgDGzwBx1q5"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 2. BS Hedging Simulation\n",
    "# ---------------------------------------------------------\n",
    "# prices_test shape: (Batch, Steps+1, 1)\n",
    "# 우리가 헷징 포지션을 잡아야 하는 건 t=0 부터 t=T-1 까지입니다.\n",
    "\n",
    "with torch.no_grad():\n",
    "    # (1) 입력 데이터 준비\n",
    "    # 시뮬레이션에 사용된 주가 (마지막 만기 시점 제외)\n",
    "    S_t = prices_test[:, :-1, 0] # shape: (Batch, Steps)\n",
    "\n",
    "    # (2) 잔여 만기(Time to Maturity) 텐서 생성\n",
    "    # t=0일 때 잔여만기 T, t=1일 때 T-dt, ...\n",
    "    # shape를 (Batch, Steps)로 맞춰줍니다.\n",
    "    batch_size, steps = S_t.shape\n",
    "    dt = T / steps\n",
    "\n",
    "    # [T, T-dt, T-2dt, ... , dt] 형태로 시간 생성\n",
    "    times = torch.linspace(T, dt, steps, device=device)\n",
    "    time_remaining_matrix = times.unsqueeze(0).expand(batch_size, steps) # (Batch, Steps)\n",
    "\n",
    "    # (3) BS Delta 계산\n",
    "    # r=0 (가정), sigma=sig\n",
    "    bs_deltas = calculate_bs_delta(S_t, time_remaining_matrix, K, 0.0, sig)\n",
    "\n",
    "    # (4) BS P&L 계산 (Deep Hedging과 동일한 로직)\n",
    "    # 주가 변동분\n",
    "    price_changes_test = prices_test[:, 1:, 0] - prices_test[:, :-1, 0]\n",
    "\n",
    "    # 헷징 포트폴리오 수익\n",
    "    bs_hedging_pnl = torch.sum(bs_deltas * price_changes_test, dim=1)\n",
    "\n",
    "    # 옵션 Payoff (만기 시점)\n",
    "    S_T_test = prices_test[:, -1, 0]\n",
    "    option_payoff_test = torch.relu(S_T_test - K)\n",
    "\n",
    "    # 최종 P&L (Initial Premium + Hedging PnL - Payoff)\n",
    "    # initial_cf는 BS Call Price라고 하셨으므로, 이론상 이 값의 평균은 0에 수렴해야 함\n",
    "    bs_total_pnl = bs_hedging_pnl - option_payoff_test\n",
    "    bs_final_pnl = initial_cf + bs_total_pnl\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. 결과 비교 및 출력\n",
    "# ---------------------------------------------------------\n",
    "print(f\"--- Comparison (Test Paths: {M}) ---\")\n",
    "print(f\"[Deep Hedging] Mean PnL: {final_pnl_test.mean().item():.4f} | Std: {final_pnl_test.std().item():.4f} | CVaR(5%) w/o inital cf: {loss.item():.4f}\")\n",
    "print(f\"[BS Delta]     Mean PnL: {bs_final_pnl.mean().item():.4f} | Std: {bs_final_pnl.std().item():.4f} | CVaR(5%) w/o inital cf: {cvar_loss(bs_total_pnl).item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-LGHxPzJySst"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# 딥러닝 PnL 분포\n",
    "plt.hist(final_pnl_test.cpu().numpy(), bins=75, alpha=0.5, label='Deep Hedging', density=True, color='blue')\n",
    "# BS PnL 분포\n",
    "plt.hist(bs_final_pnl.cpu().numpy(), bins=75, alpha=0.5, label='BS Hedging', density=True, color='red')\n",
    "\n",
    "plt.axvline(x=0, color='k', linestyle='--')\n",
    "plt.title('PnL Distribution Comparison')\n",
    "plt.xlabel('Profit & Loss')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxNA-SVV6SOb"
   },
   "source": [
    "### WITH Transaction Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6Z2bahH17R7"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# --- 하이퍼파라미터 설정 ---\n",
    "M = 20000   # 배치 사이즈 (User Code의 주석 참고)\n",
    "N = 30     # (Time Steps)\n",
    "T = 30/365\n",
    "mean = 0.0\n",
    "sig = 0.2\n",
    "S_0 = 100.0\n",
    "K = 100.0   # ATM 옵션\n",
    "number_opt = 10000.0\n",
    "initial_cf = bscall(S_0, K, T, mean, sig)\n",
    "\n",
    "# 디바이스 설정 (GPU 권장)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- 모델 초기화 ---\n",
    "# input_dim=1 (주가 정보만 사용한다고 가정)\n",
    "# hidden_dim=32\n",
    "model = DeepHedgingModel(input_dim=1, hidden_dim=32).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# --- 학습 루프 ---\n",
    "print(\"Training Start...\")\n",
    "for epoch in range(1001): # 500 에포크\n",
    "\n",
    "    # 1. 데이터 생성 (매 에포크마다 새로운 시뮬레이션 -> 오버피팅 방지)\n",
    "    # prices shape: (Batch, Steps+1, 1)\n",
    "    prices = generate_gbm(M, N, T, mean, sig, S_0, device)\n",
    "\n",
    "    # 2. 모델 예측 (Action)\n",
    "    # prices는 t=0 ~ t=T까지 있음.\n",
    "    # 모델에는 t=0 ~ t=T-1 까지의 정보를 주고, t=0 ~ t=T-1 시점의 델타를 구함\n",
    "    inputs = prices[:, :-1, :] # 마지막 만기 시점 제외\n",
    "\n",
    "    # deltas shape: (Batch, Steps, 1)\n",
    "    # User Code의 forward에서 squeeze가 없다면 (Batch, Steps, 1)로 나옴\n",
    "    deltas = model(inputs)\n",
    "\n",
    "    # 3. P&L 계산 (Financial Logic)\n",
    "    # 옵션 Payoff (Call Option): Max(S_T - K, 0)\n",
    "    S_T = prices[:, -1, 0]\n",
    "    option_payoff = torch.relu(S_T - K)\n",
    "\n",
    "    # 4. 헷징 포트폴리오의 가치 변화\n",
    "    price_changes = prices[:, 1:, 0] - prices[:, :-1, 0] # (Batch, Steps)\n",
    "\n",
    "    # 텐서 shape 맞추기 (Batch, Steps)\n",
    "    deltas = deltas.squeeze(-1)\n",
    "\n",
    "\n",
    "\n",
    "    # [수정 후: transaction cost 존재]\n",
    "    COST_BPS = 0.1\n",
    "\n",
    "    # 1. 델타 변화량 계산 (거래량)\n",
    "    # 첫 시점(t=0)의 델타 변화량은 |delta_0 - 0| = |delta_0|\n",
    "    # 그 이후는 |delta_t - delta_{t-1}|\n",
    "    # prev_deltas: [0, delta_0, delta_1, ..., delta_{T-2}]\n",
    "    prev_deltas = torch.cat([torch.zeros(deltas.size(0), 1).to(device), deltas[:, :-1]], dim=1)\n",
    "    delta_changes = torch.abs(deltas - prev_deltas) # (Batch, Steps)\n",
    "\n",
    "    # 2. 거래 비용 계산: 거래량 * 주가 * 비용율\n",
    "    # 주가는 해당 시점의 가격 사용 (prices[:, :-1, 0])\n",
    "    transaction_costs = torch.sum(delta_changes * prices[:, :-1, 0] * (COST_BPS / 100), dim=1)\n",
    "\n",
    "    # 3. 순수익 계산 (비용 차감)\n",
    "    hedging_pnl = torch.sum(deltas * price_changes, dim=1) - transaction_costs\n",
    "\n",
    "\n",
    "    # 최종 P&L = 옵션 매도 프리미엄(생략 가능) + 헷징 수익 - 만기 Payoff 지불\n",
    "    # 여기서는 '순수 헷징 오차'를 줄이는 것이 목표이므로 프리미엄은 제외하고\n",
    "    # Wealth = Hedging PnL - Liability 로 봅니다.\n",
    "    total_pnl = number_opt * (hedging_pnl - option_payoff) # 얘 평균이 결국 BS Call Price로 수렴하는지 봐야함. 그게 asset pricing에서 말하는 option premium이니깐\n",
    "    final_pnl = total_pnl + number_opt * (initial_cf)\n",
    "    # 4. Loss 계산 (CVaR)\n",
    "    loss = cvar_loss(total_pnl) # 하위 5% 상황 방어\n",
    "    loss_mse = mean_loss(total_pnl)\n",
    "\n",
    "\n",
    "    # 5. 역전파 및 업데이트\n",
    "    optimizer.zero_grad() # [중요] 그래디언트 초기화\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch} | CVaR Loss: {loss.item():.4f} | Mean PnL: {total_pnl.mean().item():.8f} | Final PnL : {final_pnl.mean().item():.8f}\")\n",
    "        #print(f\"Epoch {epoch} | MSE Loss: {loss_mse.item():.4f} | Mean PnL: {total_pnl.mean().item():.8f}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Training Finished.     BSCALL PRICE : {initial_cf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3YSPPuhI7YCz"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "S_T_np = S_T.detach().cpu().numpy()\n",
    "option_payoff_np = option_payoff.detach().cpu().numpy()\n",
    "hedging_pnl_np = hedging_pnl.detach().cpu().numpy()          # shape (M,)\n",
    "final_pnl_np = final_pnl.detach().cpu().numpy()\n",
    "\n",
    "# ---- Plot 1: S_T histogram ----\n",
    "plt.figure()\n",
    "plt.hist(S_T_np, bins=50)\n",
    "plt.title(\"Histogram of $S_T$\")\n",
    "plt.xlabel(\"$S_T$\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---- Plot 2: hedging_pnl histogram ----\n",
    "plt.figure()\n",
    "plt.hist(hedging_pnl_np, bins=80)\n",
    "plt.title(\"Histogram of Hedging PnL\")\n",
    "plt.xlabel(\"hedging_pnl\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---- Plot 3: scatter S_T vs hedging_pnl ----\n",
    "plt.figure()\n",
    "plt.scatter(S_T_np, hedging_pnl_np, s=8)\n",
    "plt.scatter(S_T_np, option_payoff_np)\n",
    "plt.title(\"Scatter: $S_T$ vs Hedging PnL\")\n",
    "plt.xlabel(\"$S_T$\")\n",
    "plt.ylabel(\"hedging_pnl\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---- Plot 4: scatter S_T vs hedging_pnl ----\n",
    "plt.figure()\n",
    "plt.scatter(S_T_np, final_pnl_np, s=8, alpha = 0.4)\n",
    "plt.plot([S_T_np.min(),S_T_np.max()],[0.0,0.0], ':', color = 'red')\n",
    "plt.title(\"Scatter: $S_T$ vs Final PnL\")\n",
    "plt.xlabel(\"$S_T$\")\n",
    "plt.ylabel(\"Final PnL\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "pd.Series(final_pnl_np).describe()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5jl_wAPI7YCz"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Deep-Hedging Model\n",
    "'''\n",
    "\n",
    "# 모델을 평가 모드로 전환 (Dropout, BatchNorm 비활성화)\n",
    "model.eval()\n",
    "\n",
    "#test stock data\n",
    "prices_test = generate_gbm(M, N, T, mean, sig, S_0, device)\n",
    "\n",
    "with torch.no_grad(): # 기울기 계산을 끄고 메모리 절약\n",
    "\n",
    "    # Scikit-learn의 model.predict(X) 대신 아래와 같이 사용\n",
    "    predicted_delta = model(prices_test[:, :-1, :])\n",
    "    predicted_delta = predicted_delta.squeeze(-1)\n",
    "\n",
    "    S_T_test = prices_test[:, -1, 0]\n",
    "    option_payoff_test = torch.relu(S_T_test - K)\n",
    "\n",
    "    price_changes_test = prices_test[:, 1:, 0] - prices_test[:, :-1, 0] # (Batch, Steps)\n",
    "\n",
    "    prev_deltas_test = torch.cat([torch.zeros(predicted_delta.size(0), 1).to(device), predicted_delta[:, :-1]], dim=1)\n",
    "    delta_changes_test = torch.abs(predicted_delta - prev_deltas_test) # (Batch, Steps)\n",
    "\n",
    "    transaction_costs_test = torch.sum(delta_changes_test * prices_test[:, :-1, 0] * (COST_BPS / 100), dim=1)\n",
    "\n",
    "    hedging_pnl_test = torch.sum(predicted_delta * price_changes_test, dim=1) - transaction_costs_test\n",
    "\n",
    "    total_pnl_test = number_opt * (hedging_pnl_test - option_payoff_test) # 얘 평균이 결국 BS Call Price로 수렴하는지 봐야함. 그게 asset pricing에서 말하는 option premium이니깐\n",
    "    final_pnl_test = total_pnl_test + number_opt * (initial_cf)\n",
    "\n",
    "    # 4. Loss 계산 (CVaR)\n",
    "    loss_test = cvar_loss(total_pnl_test) # 하위 5% 상황 방어\n",
    "    loss_mse_test = mean_loss(total_pnl_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNpnHSuX7YCz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import Normal\n",
    "\n",
    "# 1. Black-Scholes Delta 계산 함수 (Vectorized)\n",
    "def calculate_bs_delta(S, time_remaining, K, r, sigma):\n",
    "    \"\"\"\n",
    "    S: 현재 주가 (Tensor)\n",
    "    time_remaining: 잔여 만기 (Tensor)\n",
    "    K: 행사가\n",
    "    r: 무위험 이자율\n",
    "    sigma: 변동성\n",
    "    \"\"\"\n",
    "    # 만기 시점(time_remaining=0) 근처에서의 0으로 나누기 에러 방지용 epsilon\n",
    "    epsilon = 1e-8\n",
    "\n",
    "    d1 = (torch.log(S / K) + (r + 0.5 * sigma ** 2) * time_remaining) / (sigma * torch.sqrt(time_remaining) + epsilon)\n",
    "\n",
    "    normal = Normal(0, 1)\n",
    "    delta = normal.cdf(d1)\n",
    "\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mbHmP2VR7YCz"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 2. BS Hedging Simulation\n",
    "# ---------------------------------------------------------\n",
    "# prices_test shape: (Batch, Steps+1, 1)\n",
    "# 우리가 헷징 포지션을 잡아야 하는 건 t=0 부터 t=T-1 까지입니다.\n",
    "\n",
    "with torch.no_grad():\n",
    "    # (1) 입력 데이터 준비\n",
    "    # 시뮬레이션에 사용된 주가 (마지막 만기 시점 제외)\n",
    "    S_t = prices_test[:, :-1, 0] # shape: (Batch, Steps)\n",
    "\n",
    "    # (2) 잔여 만기(Time to Maturity) 텐서 생성\n",
    "    # t=0일 때 잔여만기 T, t=1일 때 T-dt, ...\n",
    "    # shape를 (Batch, Steps)로 맞춰줍니다.\n",
    "    batch_size, steps = S_t.shape\n",
    "    dt = T / steps\n",
    "\n",
    "    # [T, T-dt, T-2dt, ... , dt] 형태로 시간 생성\n",
    "    times = torch.linspace(T, dt, steps, device=device)\n",
    "    time_remaining_matrix = times.unsqueeze(0).expand(batch_size, steps) # (Batch, Steps)\n",
    "\n",
    "    # (3) BS Delta 계산\n",
    "    # r=0 (가정), sigma=sig\n",
    "    bs_deltas = calculate_bs_delta(S_t, time_remaining_matrix, K, 0.0, sig)\n",
    "\n",
    "    bs_prev_deltas = torch.cat([torch.zeros(bs_deltas.size(0), 1).to(device), bs_deltas[:, :-1]], dim=1)\n",
    "    bs_delta_changes = torch.abs(bs_deltas - bs_prev_deltas) # (Batch, Steps)\n",
    "\n",
    "    bs_transaction_costs = torch.sum(bs_delta_changes * prices_test[:, :-1, 0] * (COST_BPS / 100), dim=1)\n",
    "\n",
    "    # (4) BS P&L 계산 (Deep Hedging과 동일한 로직)\n",
    "    # 주가 변동분\n",
    "    price_changes_test = prices_test[:, 1:, 0] - prices_test[:, :-1, 0]\n",
    "\n",
    "    # 헷징 포트폴리오 수익\n",
    "    bs_hedging_pnl = torch.sum(bs_deltas * price_changes_test, dim=1) - bs_transaction_costs\n",
    "\n",
    "    # 옵션 Payoff (만기 시점)\n",
    "    S_T_test = prices_test[:, -1, 0]\n",
    "    option_payoff_test = torch.relu(S_T_test - K)\n",
    "\n",
    "    # 최종 P&L (Initial Premium + Hedging PnL - Payoff)\n",
    "    # initial_cf는 BS Call Price라고 하셨으므로, 이론상 이 값의 평균은 0에 수렴해야 함\n",
    "    bs_total_pnl = number_opt * (bs_hedging_pnl - option_payoff_test)\n",
    "    bs_final_pnl = number_opt * (initial_cf) + bs_total_pnl\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. 결과 비교 및 출력\n",
    "# ---------------------------------------------------------\n",
    "print(f\"--- Comparison (Test Paths: {M}) ---\")\n",
    "print(f\"[Deep Hedging] Mean PnL: {final_pnl_test.mean().item():.4f} | Std: {final_pnl_test.std().item():.4f} | CVaR(5%) w/o inital cf: {loss.item():.4f}\")\n",
    "print(f\"[BS Delta]     Mean PnL: {bs_final_pnl.mean().item():.4f} | Std: {bs_final_pnl.std().item():.4f} | CVaR(5%) w/o inital cf: {cvar_loss(bs_total_pnl).item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mlB-h9j67YCz"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "# 딥러닝 PnL 분포\n",
    "plt.hist(final_pnl_test.cpu().numpy(), bins=75, alpha=0.5, label='Deep Hedging', density=True, color='blue')\n",
    "# BS PnL 분포\n",
    "plt.hist(bs_final_pnl.cpu().numpy(), bins=75, alpha=0.5, label='BS Hedging', density=True, color='red')\n",
    "\n",
    "plt.axvline(x=0, color='k', linestyle='--')\n",
    "plt.title('PnL Distribution Comparison with transaction cost')\n",
    "plt.xlabel('Profit & Loss')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRSE9U3T-Hv0"
   },
   "source": [
    "## Putting Previous Delta & Tow Into the Model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_l9iyGDp9z1k"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DeepHedgingModelWithState(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim=1):\n",
    "        super(DeepHedgingModelWithState, self).__init__()\n",
    "\n",
    "        # input_dim: 시장 데이터 개수 (예: Log Return 1개)\n",
    "        # 실제 입력 차원 = 시장 데이터 + 이전 델타(1개) + tow(1개)\n",
    "        self.input_dim = input_dim\n",
    "        self.total_input_dim = input_dim + 2\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # LSTMCell: 시퀀스 전체가 아니라 한 스텝(t)만 계산\n",
    "        self.lstm_cell = nn.LSTMCell(self.total_input_dim, hidden_dim)\n",
    "\n",
    "        #hidden_layer output 정규화\n",
    "        self.layer_normalization = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        # 출력 레이어\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        # 숏 포지션 허용 시 Tanh, 롱 온리면 Sigmoid\n",
    "        # 여기서는 -1 ~ 1 사이로 가정 (Tanh)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, initial_delta=None, T=None):\n",
    "        \"\"\"\n",
    "        x: (Batch, Steps, input_dim) -> 예: 주가 로그 수익률 등\n",
    "        initial_delta: t=0 시점 이전에 보유한 포지션 (없으면 0)\n",
    "        \"\"\"\n",
    "        batch_size, steps, _ = x.size()\n",
    "\n",
    "        # 1. 초기 은닉 상태 (h_0, c_0) 초기화\n",
    "        h_t = torch.zeros(batch_size, self.hidden_dim, device=x.device)\n",
    "        c_t = torch.zeros(batch_size, self.hidden_dim, device=x.device)\n",
    "\n",
    "        # 2. 초기 델타, 만기 설정 (delta: t=0 이전에 아무것도 없었으면 0.0)\n",
    "        if initial_delta is None:\n",
    "            prev_delta = torch.zeros(batch_size, 1, device=x.device)\n",
    "        else:\n",
    "            prev_delta = initial_delta\n",
    "\n",
    "        deltas = []\n",
    "\n",
    "        # 3. Time Step Loop (수동으로 돌리기)\n",
    "        for t in range(steps):\n",
    "            # (1) 현재 시점의 시장 데이터 가져오기: (Batch, input_dim)\n",
    "            market_input = x[:, t, :]\n",
    "\n",
    "            if T is None:\n",
    "              print('T is not assigned. Try Again.')\n",
    "              break\n",
    "\n",
    "            else:\n",
    "              pass\n",
    "\n",
    "            dt = torch.ones(batch_size, 1, device=x.device) * (T/steps)\n",
    "            tow = dt * (T - t)\n",
    "\n",
    "            # (2) 입력 결합: [시장 데이터, 이전 델타] -> (Batch, input_dim + 1)\n",
    "            # dim=1은 feature 차원\n",
    "            lstm_input = torch.cat([market_input, prev_delta, tow], dim=1)\n",
    "\n",
    "            # (3) LSTM Cell 연산\n",
    "            h_t, c_t = self.lstm_cell(lstm_input, (h_t, c_t))\n",
    "            h_t_norm = self.layer_normalization(h_t) #정규화\n",
    "\n",
    "            # (4) 현재 델타 계산\n",
    "            delta_t = self.activation(self.fc(h_t_norm))\n",
    "\n",
    "            # (5) 결과 저장 및 업데이트\n",
    "            deltas.append(delta_t)\n",
    "            prev_delta = delta_t # 방금 구한 델타가 다음 스텝의 입력이 됨\n",
    "\n",
    "        # 리스트에 담긴 델타들을 텐서로 합침 -> (Batch, Steps, 1)\n",
    "        deltas = torch.stack(deltas, dim=1)\n",
    "\n",
    "        return deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "55HT1hrgAsYx"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# --- 하이퍼파라미터 설정 ---\n",
    "M = 20000   # 배치 사이즈 (User Code의 주석 참고)\n",
    "N = 30     # (Time Steps)\n",
    "T = 30/365\n",
    "mean = 0.0\n",
    "sig = 0.2\n",
    "S_0 = 100.0\n",
    "K = 100.0   # ATM 옵션\n",
    "number_opt = 10000.0\n",
    "initial_cf = bscall(S_0, K, T, mean, sig)\n",
    "\n",
    "BATCH_SIZE = 256 # 논문 설정대로 미니 배치 크기 지정\n",
    "\n",
    "# 디바이스 설정 (GPU 권장)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- 모델 초기화 ---\n",
    "# input_dim=1 (주가 정보만 사용한다고 가정)\n",
    "# hidden_dim=32\n",
    "model = DeepHedgingModelWithState(input_dim=1, hidden_dim=32).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005) #deep hedging 논문은 0.005엿음. / batc_size= 256\n",
    "\n",
    "\n",
    "# --- 학습 루프 ---\n",
    "print(\"Training Start...\")\n",
    "for epoch in range(501):\n",
    "\n",
    "    # 1. 데이터 생성 (매 에포크마다 새로운 시뮬레이션 -> 오버피팅 방지)\n",
    "    # prices shape: (Batch, Steps+1, 1)\n",
    "    prices = generate_gbm(M, N, T, mean, sig, S_0, device)\n",
    "    S_T = prices[:, -1, 0]\n",
    "\n",
    "    # 1-1. moneyness로 input 받아서, scale 무관하게 만들기(로그수익률은 아무리 봐도 현재 위치가 반영 안되는게 좀)\n",
    "    inputs = prices/K\n",
    "    inputs = inputs[:, :-1, :] # 마지막 만기 시점 제외\n",
    "\n",
    "    # 2. 미니 배치 루프\n",
    "\n",
    "    # 루프 시작 전 변수 초기화\n",
    "    epoch_loss = 0.0\n",
    "    epoch_loss_mse = 0.0\n",
    "    epoch_loss_entropy = 0.0\n",
    "    epoch_final_pnl = 0.0\n",
    "    num_iters = 0\n",
    "\n",
    "    for i in range(0, M, BATCH_SIZE):\n",
    "\n",
    "        if (i + BATCH_SIZE) + BATCH_SIZE > M:\n",
    "\n",
    "            batch_inputs = inputs[i:,:,:]\n",
    "            batch_prices = prices[i:,:,:]\n",
    "            option_payoff = torch.relu(S_T - K)[i:]\n",
    "            is_last_batch = True\n",
    "\n",
    "        else:\n",
    "\n",
    "            batch_inputs = inputs[i : i + BATCH_SIZE,:,:]\n",
    "            batch_prices = prices[i : i + BATCH_SIZE,:,:]\n",
    "            option_payoff = torch.relu(S_T - K)[i : i + BATCH_SIZE]\n",
    "            is_last_batch = False\n",
    "\n",
    "        # 2. 모델 예측 (Action)\n",
    "        # prices는 t=0 ~ t=T까지 있음.\n",
    "        # 모델에는 t=0 ~ t=T-1 까지의 정보를 주고, t=0 ~ t=T-1 시점의 델타를 구함\n",
    "\n",
    "        # deltas shape: (Batch, Steps, 1)\n",
    "        # User Code의 forward에서 squeeze가 없다면 (Batch, Steps, 1)로 나옴\n",
    "        deltas = model(batch_inputs, T = T)\n",
    "\n",
    "        # 3. P&L 계산 (Financial Logic)\n",
    "        # 옵션 Payoff (Call Option): Max(S_T - K, 0)\n",
    "\n",
    "\n",
    "        # 4. 헷징 포트폴리오의 가치 변화\n",
    "        price_changes = batch_prices[:, 1:, 0] - batch_prices[:, :-1, 0] # (Batch, Steps)\n",
    "\n",
    "        # 텐서 shape 맞추기 (Batch, Steps)\n",
    "        deltas = deltas.squeeze(-1)\n",
    "\n",
    "        # 수정 후: transaction cost 존재\n",
    "        COST_BPS = 50\n",
    "\n",
    "        # 1. 델타 변화량 계산 (거래량)\n",
    "        # 첫 시점(t=0)의 델타 변화량은 |delta_0 - 0| = |delta_0|\n",
    "        # 그 이후는 |delta_t - delta_{t-1}|\n",
    "        # prev_deltas: [0, delta_0, delta_1, ..., delta_{T-2}]\n",
    "        prev_deltas = torch.cat([torch.zeros(deltas.size(0), 1).to(device), deltas[:, :-1]], dim=1)\n",
    "        delta_changes = torch.abs(deltas - prev_deltas) # (Batch, Steps)\n",
    "\n",
    "        # 2. 거래 비용 계산: 거래량 * 주가 * 비용율\n",
    "        # 주가는 해당 시점의 가격 사용 (prices[:, :-1, 0])\n",
    "        transaction_costs = torch.sum(delta_changes * batch_prices[:, :-1, 0] * (COST_BPS / 10000), dim=1)\n",
    "\n",
    "        # 3. 순수익 계산 (비용 차감)\n",
    "        hedging_pnl = torch.sum(deltas * price_changes, dim=1) - transaction_costs\n",
    "\n",
    "\n",
    "        # 최종 P&L = 옵션 매도 프리미엄(생략 가능) + 헷징 수익 - 만기 Payoff 지불\n",
    "        # 여기서는 '순수 헷징 오차'를 줄이는 것이 목표이므로 프리미엄은 제외하고\n",
    "        # Wealth = Hedging PnL - Liability 로 봅니다.\n",
    "        total_pnl = hedging_pnl - option_payoff # 얘 평균이 결국 BS Call Price로 수렴하는지 봐야함. 그게 asset pricing에서 말하는 option premium이니깐\n",
    "        final_pnl = number_opt * (total_pnl + initial_cf)\n",
    "\n",
    "        # 4. Loss 계산 (CVaR)\n",
    "        loss = cvar_loss(total_pnl) # 하위 5% 상황 방어\n",
    "        loss_mse = mean_loss(total_pnl)\n",
    "        loss_entropy = entropic_loss(total_pnl)\n",
    "\n",
    "        # 5. 역전파 및 업데이트\n",
    "        optimizer.zero_grad()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        loss_entropy.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 6. 기록 누적\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_loss_mse += loss_mse.item()\n",
    "        epoch_loss_entropy += loss_entropy.item()\n",
    "        epoch_final_pnl += final_pnl.mean().item()\n",
    "        num_iters += 1\n",
    "\n",
    "        # 마지막 배치를 처리했으면, 더 이상 루프를 돌 필요 없이 종료\n",
    "        if is_last_batch:\n",
    "            break\n",
    "\n",
    "    if epoch  % 10 == 0:\n",
    "       avg_loss = epoch_loss / num_iters\n",
    "       avg_mse = epoch_loss_mse / num_iters\n",
    "       avg_entropy = epoch_loss_entropy / num_iters\n",
    "       avg_pnl = epoch_final_pnl / num_iters\n",
    "\n",
    "       print(f\"Epoch {epoch} | CVaR Loss: {avg_loss:.4f} | MSE Loss: {avg_mse:.4f} | Entropic Loss: {avg_entropy:.4f} | Mean Final PnL: {avg_pnl:.4f}\")\n",
    "print(f\"Training Finished. FAIR PRICE : {avg_entropy:.7f} | BSCALL PRICE : {initial_cf:.7f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E_fpH9-gk-e0"
   },
   "outputs": [],
   "source": [
    "# 모델을 평가 모드로 전환 (Dropout, BatchNorm 비활성화)\n",
    "model.eval()\n",
    "\n",
    "#generating test stock data\n",
    "prices_test = generate_gbm(M, N, T, mean, sig, S_0, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQH_0DukHXdf"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Deep-Hedging Model\n",
    "'''\n",
    "with torch.no_grad(): # 기울기 계산을 끄고 메모리 절약\n",
    "\n",
    "    # Scikit-learn의 model.predict(X) 대신 아래와 같이 사용\n",
    "    predicted_delta = model((prices_test/K)[:,:-1,:], T = T)\n",
    "    predicted_delta = predicted_delta.squeeze(-1)\n",
    "\n",
    "    S_T_test = prices_test[:, -1, 0]\n",
    "    option_payoff_test = torch.relu(S_T_test - K)\n",
    "\n",
    "    price_changes_test = prices_test[:, 1:, 0] - prices_test[:, :-1, 0] # (Batch, Steps)\n",
    "\n",
    "    prev_deltas_test = torch.cat([torch.zeros(predicted_delta.size(0), 1).to(device), predicted_delta[:, :-1]], dim=1)\n",
    "    delta_changes_test = torch.abs(predicted_delta - prev_deltas_test) # (Batch, Steps)\n",
    "\n",
    "    transaction_costs_test = torch.sum(delta_changes_test * prices_test[:, :-1, 0] * (COST_BPS / 10000), dim=1)\n",
    "\n",
    "    hedging_pnl_test = torch.sum(predicted_delta * price_changes_test, dim=1) - transaction_costs_test\n",
    "\n",
    "    total_pnl_test = hedging_pnl_test - option_payoff_test\n",
    "    final_pnl_test = (total_pnl_test + initial_cf) # * number_opt\n",
    "\n",
    "    # 4. Loss 계산\n",
    "    loss_test = cvar_loss(total_pnl_test) # 하위 5% 상황 방어\n",
    "    loss_mse_test = mean_loss(total_pnl_test)\n",
    "    loss_entropy_test = entropic_loss(total_pnl_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5MFWcTLHXdf"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import Normal\n",
    "\n",
    "# 1. Black-Scholes Delta 계산 함수 (Vectorized)\n",
    "def calculate_bs_delta(S, time_remaining, K, r, sigma):\n",
    "    \"\"\"\n",
    "    S: 현재 주가 (Tensor)\n",
    "    time_remaining: 잔여 만기 (Tensor)\n",
    "    K: 행사가\n",
    "    r: 무위험 이자율\n",
    "    sigma: 변동성\n",
    "    \"\"\"\n",
    "    # 만기 시점(time_remaining=0) 근처에서의 0으로 나누기 에러 방지용 epsilon\n",
    "    epsilon = 1e-8\n",
    "\n",
    "    d1 = (torch.log(S / K) + (r + 0.5 * sigma ** 2) * time_remaining) / (sigma * torch.sqrt(time_remaining) + epsilon)\n",
    "\n",
    "    normal = Normal(0, 1)\n",
    "    delta = normal.cdf(d1)\n",
    "\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIr0wLddHXdf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 2. BS Hedging Simulation\n",
    "# ---------------------------------------------------------\n",
    "# prices_test shape: (Batch, Steps+1, 1)\n",
    "# 우리가 헷징 포지션을 잡아야 하는 건 t=0 부터 t=T-1 까지입니다.\n",
    "\n",
    "with torch.no_grad():\n",
    "    # (1) 입력 데이터 준비\n",
    "    # 시뮬레이션에 사용된 주가 (마지막 만기 시점 제외)\n",
    "    S_t = prices_test[:, :-1, 0] # shape: (Batch, Steps)\n",
    "\n",
    "    # (2) 잔여 만기(Time to Maturity) 텐서 생성\n",
    "    # t=0일 때 잔여만기 T, t=1일 때 T-dt, ...\n",
    "    # shape를 (Batch, Steps)로 맞춰줍니다.\n",
    "    batch_size, steps = S_t.shape\n",
    "    dt = T / steps\n",
    "\n",
    "    # [T, T-dt, T-2dt, ... , dt] 형태로 시간 생성\n",
    "    times = torch.linspace(T, dt, steps, device=device)\n",
    "    time_remaining_matrix = times.unsqueeze(0).expand(batch_size, steps) # (Batch, Steps)\n",
    "\n",
    "    # (3) BS Delta 계산\n",
    "    # r=0 (가정), sigma=sig\n",
    "    bs_deltas = calculate_bs_delta(S_t, time_remaining_matrix, K, 0.0, sig)\n",
    "\n",
    "    bs_prev_deltas = torch.cat([torch.zeros(bs_deltas.size(0), 1).to(device), bs_deltas[:, :-1]], dim=1)\n",
    "    bs_delta_changes = torch.abs(bs_deltas - bs_prev_deltas) # (Batch, Steps)\n",
    "\n",
    "    bs_transaction_costs = torch.sum(bs_delta_changes * prices_test[:, :-1, 0] * (COST_BPS / 10000), dim=1)\n",
    "\n",
    "    # (4) BS P&L 계산 (Deep Hedging과 동일한 로직)\n",
    "    # 주가 변동분\n",
    "    price_changes_test = prices_test[:, 1:, 0] - prices_test[:, :-1, 0]\n",
    "\n",
    "    # 헷징 포트폴리오 수익\n",
    "    bs_hedging_pnl = torch.sum(bs_deltas * price_changes_test, dim=1) - bs_transaction_costs\n",
    "\n",
    "    # 옵션 Payoff (만기 시점)\n",
    "    S_T_test = prices_test[:, -1, 0]\n",
    "    option_payoff_test = torch.relu(S_T_test - K)\n",
    "\n",
    "    # 최종 P&L (Initial Premium + Hedging PnL - Payoff)\n",
    "    # initial_cf는 BS Call Price라고 하셨으므로, 이론상 이 값의 평균은 0에 수렴해야 함\n",
    "    bs_total_pnl = bs_hedging_pnl - option_payoff_test\n",
    "    bs_final_pnl = (initial_cf + bs_total_pnl) #* number_opt\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. 결과 비교 및 출력\n",
    "# ---------------------------------------------------------\n",
    "print(f\"--- Comparison (Test Paths: {M}) ---\")\n",
    "print(f\"[Deep Hedging] Mean PnL: {final_pnl_test.mean().item():.4f} | Std: {final_pnl_test.std().item():.4f} | CVaR(5%) w/o inital cf: {cvar_loss(final_pnl_test).item():.4f}\")\n",
    "print(f\"[BS Delta]     Mean PnL: {bs_final_pnl.mean().item():.4f} | Std: {bs_final_pnl.std().item():.4f} | CVaR(5%) w/o inital cf: {cvar_loss(bs_final_pnl).item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xev2X4R3dvlu"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "S_T_np = S_T_test.detach().cpu().numpy()\n",
    "option_payoff_np = option_payoff_test.detach().cpu().numpy()\n",
    "hedging_pnl_np = hedging_pnl_test.detach().cpu().numpy()\n",
    "final_pnl_np = final_pnl_test.detach().cpu().numpy()\n",
    "\n",
    "# ---- Plot 1: S_T histogram ----\n",
    "plt.figure()\n",
    "plt.hist(S_T_np, bins=50)\n",
    "plt.title(\"Histogram of $S_T$\")\n",
    "plt.xlabel(\"$S_T$\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---- Plot 2: hedging_pnl histogram ----\n",
    "plt.figure()\n",
    "plt.hist(hedging_pnl_np, bins=80)\n",
    "plt.title(\"Histogram of Hedging PnL\")\n",
    "plt.xlabel(\"hedging_pnl\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---- Plot 3: scatter S_T vs hedging_pnl ----\n",
    "plt.figure()\n",
    "plt.scatter(S_T_np, hedging_pnl_np, s=8)\n",
    "plt.scatter(S_T_np, option_payoff_np)\n",
    "plt.title(\"Scatter: $S_T$ vs Hedging PnL\")\n",
    "plt.xlabel(\"$S_T$\")\n",
    "plt.ylabel(\"hedging_pnl\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---- Plot 4: scatter S_T vs hedging_pnl ----\n",
    "plt.figure()\n",
    "plt.scatter(S_T_np, final_pnl_np, s=8, alpha = 0.4)\n",
    "plt.plot([S_T_np.min(),S_T_np.max()],[0.0,0.0], ':', color = 'red')\n",
    "plt.title(\"Scatter: $S_T$ vs Final PnL\")\n",
    "plt.xlabel(\"$S_T$\")\n",
    "plt.ylabel(\"Final PnL\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "pd.Series(final_pnl_np).describe()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S61iiRkoHXdf"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "# 딥러닝 PnL 분포\n",
    "plt.hist(final_pnl_test.cpu().numpy(), bins=75, alpha=0.5, label='Deep Hedging', density=True, color='blue')\n",
    "# BS PnL 분포\n",
    "plt.hist(bs_final_pnl.cpu().numpy(), bins=75, alpha=0.5, label='BS Hedging', density=True, color='red')\n",
    "\n",
    "plt.axvline(x=0, color='k', linestyle='--')\n",
    "plt.title('PnL Distribution Comparison with transaction cost')\n",
    "plt.xlabel('Profit & Loss')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehOnuQFR4Y3A"
   },
   "outputs": [],
   "source": [
    "#The difference btw Deep & BS Delta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# 시각화 스타일 설정\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "def analyze_model_behavior(model, prices_test, K, T, device, n_samples=3):\n",
    "    \"\"\"\n",
    "    1. 개별 경로(Path) 시각화: 주가 움직임에 따라 Deep Delta와 BS Delta가 어떻게 다른지 확인\n",
    "    2. 전체 통계 분석: Moneyness 및 Realized Volatility에 따른 델타 차이 분석\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # -------------------------------\n",
    "    # 1. 데이터 준비 및 추론\n",
    "    # -------------------------------\n",
    "    with torch.no_grad():\n",
    "        # (1) Deep Hedging Delta 계산\n",
    "        # Input: (Batch, Steps, 1) -> Moneyness로 변환된 값\n",
    "        inputs = (prices_test / K)[:, :-1, :]\n",
    "        predicted_delta = model(inputs, T=T).squeeze(-1) # Shape: (Batch, Steps)\n",
    "\n",
    "        # (2) Black-Scholes Delta 계산 (비교군)\n",
    "        S_t = prices_test[:, :-1, 0] # Shape: (Batch, Steps)\n",
    "        batch_size, steps = S_t.shape\n",
    "        dt = T / steps\n",
    "        times = torch.linspace(T, dt, steps, device=device)\n",
    "        time_remaining = times.unsqueeze(0).expand(batch_size, steps)\n",
    "\n",
    "        # BS Delta 계산 함수 (이전 코드의 함수 활용)\n",
    "        bs_deltas = calculate_bs_delta(S_t, time_remaining, K, 0.0, sig)\n",
    "\n",
    "    # Numpy 변환\n",
    "    S_t_np = S_t.cpu().numpy()\n",
    "    deep_deltas_np = predicted_delta.cpu().numpy()\n",
    "    bs_deltas_np = bs_deltas.cpu().numpy()\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2. n개의 개별 Sample Path 시각화\n",
    "    # -------------------------------\n",
    "    # 랜덤하게 n개 샘플 추출\n",
    "    indices = np.random.choice(range(batch_size), n_samples, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(n_samples, 1, figsize=(12, 4 * n_samples))\n",
    "    if n_samples == 1: axes = [axes]\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        ax1 = axes[i]\n",
    "\n",
    "        # 왼쪽 축: 주가 (Stock Price)\n",
    "        color = 'tab:gray'\n",
    "        ax1.set_xlabel('Time Steps')\n",
    "        ax1.set_ylabel('Stock Price ($S_t$)', color=color)\n",
    "        ax1.plot(S_t_np[idx], color=color, linestyle='--', alpha=0.6, label='Stock Price')\n",
    "        ax1.tick_params(axis='y', labelcolor=color)\n",
    "        ax1.axhline(y=K, color='black', linestyle=':', alpha=0.3) # 행사가\n",
    "\n",
    "        # 오른쪽 축: 델타 (Delta)\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.set_ylabel('Delta', color='tab:blue')\n",
    "        ax2.plot(deep_deltas_np[idx], label='Deep Delta', color='blue', linewidth=2)\n",
    "        ax2.plot(bs_deltas_np[idx], label='BS Delta', color='red', linestyle='--', linewidth=2, alpha=0.7)\n",
    "        ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "        ax2.set_ylim(-0.1, 1.1) # Call Option Delta Range\n",
    "\n",
    "        # Title & Legend\n",
    "        plt.title(f\"Sample Path #{idx}: Price vs Delta Movement\")\n",
    "\n",
    "        # 범례 합치기 (꼼수)\n",
    "        lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "        lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "        ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3. 심층 분석: Moneyness & Volatility vs Delta\n",
    "    # -------------------------------\n",
    "    print(\"\\n--- Deep Analysis: Moneyness & Volatility ---\")\n",
    "\n",
    "    # 데이터 Flattening (모든 배치의 모든 타임스텝을 하나의 점으로 취급)\n",
    "    # 분석을 위해 데이터프레임으로 변환\n",
    "    flat_S = S_t_np.flatten()\n",
    "    flat_Deep = deep_deltas_np.flatten()\n",
    "    flat_BS = bs_deltas_np.flatten()\n",
    "    flat_Time = time_remaining.cpu().numpy().flatten()\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'Stock': flat_S,\n",
    "        'Moneyness': flat_S / K,\n",
    "        'Deep_Delta': flat_Deep,\n",
    "        'BS_Delta': flat_BS,\n",
    "        'Time_Remaining': flat_Time,\n",
    "        'Delta_Diff': flat_Deep - flat_BS\n",
    "    })\n",
    "\n",
    "    # (1) Moneyness vs Delta (The \"Smile\" Curve)\n",
    "    # 만기가 얼마 안 남았을 때(T < 0.02)의 데이터만 골라서 봅니다 (델타 변화가 가장 극심한 구간)\n",
    "    short_maturity_df = df[df['Time_Remaining'] < (T * 0.2)]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(short_maturity_df['Stock'], short_maturity_df['BS_Delta'],\n",
    "                s=1, color='red', alpha=0.3, label='BS Delta (Theoretical)')\n",
    "    plt.scatter(short_maturity_df['Stock'], short_maturity_df['Deep_Delta'],\n",
    "                s=1, color='blue', alpha=0.3, label='Deep Delta (Learned)')\n",
    "\n",
    "    plt.title(f\"Delta vs Stock Price (Near Maturity: T < {T*0.2:.3f})\")\n",
    "    plt.xlabel(\"Stock Price ($S_t$)\")\n",
    "    plt.ylabel(\"Delta\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # (2) Realized Volatility vs Hedge Difference (Path-wise Analysis)\n",
    "    # 각 패스별로 \"실현 변동성\"과 \"BS와의 평균 괴리율\"을 계산\n",
    "\n",
    "    # Log Return 계산\n",
    "    log_returns = np.log(S_t_np[:, 1:] / S_t_np[:, :-1])\n",
    "    realized_vol = np.std(log_returns, axis=1) * np.sqrt(252/dt) # 연환산 변동성 (근사치)\n",
    "\n",
    "    # 딥헤징이 BS와 얼마나 다르게 행동했는가? (Mean Absolute Difference)\n",
    "    # axis=1 (시간축)에 대해 평균\n",
    "    delta_diff_mae = np.mean(np.abs(deep_deltas_np - bs_deltas_np), axis=1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(realized_vol, delta_diff_mae, alpha=0.5, s=10)\n",
    "\n",
    "    # 추세선\n",
    "    z = np.polyfit(realized_vol, delta_diff_mae, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(realized_vol, p(realized_vol), \"r--\", alpha=0.8)\n",
    "\n",
    "    plt.title(\"Realized Volatility vs Deviation from BS Delta\")\n",
    "    plt.xlabel(\"Realized Volatility of Path (Annualized)\")\n",
    "    plt.ylabel(\"MAE (Deep Delta - BS Delta)\")\n",
    "    plt.show()\n",
    "\n",
    "    return df\n",
    "\n",
    "# --- 실행 ---\n",
    "# 위에서 정의한 함수를 호출하세요. (변수들은 기존 Context에 있는 것 사용)\n",
    "# n_samples=3 : 3개의 경로를 뽑아서 보여줌\n",
    "df_analysis = analyze_model_behavior(model, prices_test, K, T, device, n_samples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIzVv7VOr88x"
   },
   "source": [
    "# Deep Hedging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIQtDmERPtdL"
   },
   "source": [
    "## Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBu_BW5YnnN5"
   },
   "source": [
    "### Mkt Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdGmyywIop1O"
   },
   "source": [
    "#### GJR-GARCH & HESTON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TIytLwyphUa"
   },
   "outputs": [],
   "source": [
    "from arch import arch_model\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from scipy.stats import linregress\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def garch_heston_analysis(price_series):\n",
    "    \"\"\"\n",
    "    Output: Heston Simulator에 넣을 파라미터 딕셔너리\n",
    "    \"\"\"\n",
    "    print(f\"--- 1. Data Processing (N={len(price_series)}) ---\")\n",
    "\n",
    "    # 1. Log Returns 계산\n",
    "    S = np.array(price_series)\n",
    "    # 0이나 음수가 있으면 에러나므로 예외처리\n",
    "    if np.any(S <= 0):\n",
    "        raise ValueError(\"주가 데이터에 0 또는 음수가 포함되어 있습니다.\")\n",
    "\n",
    "    log_returns_percent = 100 * np.diff(np.log(S)) # arch 모델은 % 단위(x100)를 선호함 (수렴 잘됨)\n",
    "    log_returns = np.diff(np.log(S))       # 실제 계산용 (x1 안 함)\n",
    "\n",
    "    # 2. ADF Test (단위근 검정)\n",
    "    print(\"\\n--- 2. Stationarity Check (ADF Test) ---\")\n",
    "    result = adfuller(log_returns)\n",
    "    print(f\"ADF Statistic: {result[0]:.4f}\")\n",
    "    print(f\"p-value: {result[1]:.4e}\")\n",
    "    if result[1] < 0.05:\n",
    "        print(\">> Result: Stationary (I(0)).\")\n",
    "    else:\n",
    "        print(\">> Warning: Non-Stationary (I(1)). 차분 필요.\")\n",
    "        return\n",
    "\n",
    "    # 3. GARCH(p,q) Modeling\n",
    "    p=1\n",
    "    q=1\n",
    "    print(f\"\\n--- 3. Fitting GARCH({p},{q}) ---\")\n",
    "    # vol='Garch', p, q, dist='Normal' or 't' (Fat tail 반영하려면 't' 추천)\n",
    "    garch = arch_model(log_returns_percent, vol='GARCH', p=p, q=q, o=1, dist='skewt')\n",
    "    res = garch.fit(disp='off')\n",
    "    print(res.summary())\n",
    "    #print(res.params, res.resid, res.forecast(horizon=n), res.plot())\n",
    "\n",
    "    # 조건부 변동성(sigma_t) 추출 -> % 단위였으므로 다시 100으로 나눠줌\n",
    "    conditional_vol = res.conditional_volatility / 100.0\n",
    "\n",
    "    # Heston의 v_t (분산) = sigma_t^2\n",
    "    vt_series = conditional_vol ** 2\n",
    "\n",
    "    # 4. Heston Parameter Calibration (Daily -> Annualized)\n",
    "    print(\"\\n--- 4. Calibrating Heston Parameters ---\")\n",
    "\n",
    "    dt = 1/252 # Daily assumption\n",
    "\n",
    "    # (1) Mu (Drift)\n",
    "    # 연환산 수익률 평균\n",
    "    mu_est = np.mean(log_returns) / dt\n",
    "    mu_garch = res.params['mu']/100 / dt\n",
    "    mu_simple = np.mean(np.diff(S)/S[:-1]) / dt\n",
    "    print(f'\\nmu_est : {mu_est} | mu_garch : {mu_garch} | mu_simple : {mu_simple}\\n')\n",
    "\n",
    "    # (2) Kappa, Theta, Xi (Regression)\n",
    "    # 회귀식: (v_{t+1} - v_t)/sqrt(v_t) = a * (1/sqrt(v_t)) + b * sqrt(v_t) + error\n",
    "    # a = kappa * theta * dt\n",
    "    # b = -kappa * dt\n",
    "\n",
    "    # 1. 아예 처음부터 연율화 시켜버림\n",
    "    vt_series_annual = vt_series / dt\n",
    "\n",
    "    # 2. Regression 준비\n",
    "    v = vt_series_annual[:-1]\n",
    "    v_next = vt_series_annual[1:]\n",
    "\n",
    "    Y = (v_next - v) / np.sqrt(v)\n",
    "    X1 = 1.0 / np.sqrt(v)\n",
    "    X2 = np.sqrt(v)\n",
    "    X_design = np.column_stack((X1, X2))\n",
    "\n",
    "    # 3. OLS 실행\n",
    "    model = sm.OLS(Y, X_design) # 상수항 없음\n",
    "    results = model.fit()\n",
    "    print(results.summary())\n",
    "    beta1, beta2 = results.params\n",
    "\n",
    "    # 4. 파라미터 추출 (이제 Scaling 고민할 필요 없음)\n",
    "    # beta2 = -kappa * dt  =>  kappa = -beta2 / dt\n",
    "    kappa_est = -beta2 / dt\n",
    "\n",
    "    # beta1 = kappa * Theta * dt  =>  Theta = beta1 / (kappa * dt)\n",
    "    theta_est = beta1 / (kappa_est * dt) # 이미 연율화된 Theta가 나옴\n",
    "\n",
    "    # 5. Xi (Vol of Vol) 추출\n",
    "    # 잔차의 분산 = Xi^2 * dt\n",
    "    residuals = results.resid\n",
    "    std_resid = np.std(residuals)\n",
    "    xi_est = std_resid / np.sqrt(dt)\n",
    "\n",
    "    # 6. rho(Corr) 추출\n",
    "    dwts = (log_returns - mu_est * dt) / np.sqrt(vt_series_annual)\n",
    "    dwtv = (np.diff(vt_series_annual) - kappa_est *(theta_est -  vt_series_annual[:-1])*dt) / (xi_est * np.sqrt(vt_series_annual[:-1]))\n",
    "    min_len = min(len(dwts), len(dwtv))\n",
    "    rho_est = np.corrcoef(dwts[:min_len], dwtv[:min_len])[0, 1]\n",
    "\n",
    "    # 6. 결과\n",
    "    final_params = {\n",
    "        \"kappa\": kappa_est,\n",
    "        \"theta\": theta_est,\n",
    "        \"xi\": xi_est,\n",
    "        \"rho\": rho_est,\n",
    "        \"v0\": vt_series_annual[-1],\n",
    "        \"mu_garch\": mu_garch,\n",
    "        \"mu_simple\": mu_simple\n",
    "    }\n",
    "    return final_params, vt_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ug2Hv5jcP8QT"
   },
   "source": [
    "### Stock Movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LpY30hYRmbB"
   },
   "source": [
    "#### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RKu1T1YVnyI3"
   },
   "outputs": [],
   "source": [
    "def generate_gbm(n_paths, n_steps, t_maturity, mu, sigma, s_0, device='cpu'):\n",
    "    \"\"\"\n",
    "    n_paths: 시뮬레이션 경로 수 (Batch Size) = M\n",
    "    n_steps: 리밸런싱 횟수 (Time Steps) = N\n",
    "    t_maturity: 만기 (년 단위, ex: 30/365)\n",
    "    mu: 연간 기대 수익률 (Drift)\n",
    "    sigma: 연간 변동성 (Volatility)\n",
    "    s_0: 초기 주가\n",
    "    \"\"\"\n",
    "    dt = t_maturity / n_steps\n",
    "\n",
    "    # 1. 브라운 운동의 증분(dW) 생성 (정규분포)\n",
    "    # shape: (Batch, Steps)\n",
    "    dw = torch.randn(n_paths, n_steps, device=device) * torch.sqrt(torch.tensor(dt)) # = ε_t * root dt\n",
    "\n",
    "    # 2. 주가 경로 계산 (Vectorized)\n",
    "    # Prerequiste: Ito's y = lnS_t &  S_t follows GBM\n",
    "    # S_t = S_0 * exp( (mu - 0.5*sigma^2)*t + sigma*W_t )\n",
    "    # 누적합(cumsum)을 이용해 한 번에 계산\n",
    "\n",
    "    drift = (mu - 0.5 * sigma**2) * dt\n",
    "    diffusion = sigma * dw\n",
    "\n",
    "    # discrete log return\n",
    "    log_returns = drift + diffusion\n",
    "\n",
    "    # 로그 수익률 누적\n",
    "    log_returns_cum = torch.cumsum(drift + diffusion, dim=1)\n",
    "\n",
    "    # 초기 주가와 결합 (t=0 시점 추가)\n",
    "    ones = torch.zeros(n_paths, 1, device=device) # t=0 시점의 로그 수익률은 0\n",
    "    log_returns_cum = torch.cat((ones, log_returns_cum), dim=1)\n",
    "\n",
    "    paths = s_0 * torch.exp(log_returns_cum)\n",
    "    paths_3d = paths.unsqueeze(-1)\n",
    "\n",
    "    # Return shape: (Batch Size, Time Steps + 1, 1) -> Feature 차원 추가\n",
    "    # 우리가 넣는건 batch(경로 개수) & time(time개수) & 'feature'(주가 등의 data)의 3차원 이므로 지금 2차원으로 구성된 것에\n",
    "    # 추가 해줘야함. unqueeze(n)은 \"n번째에 차원 추가해라\" 란 의미 squeeze는 줄이는거\n",
    "    return paths_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82WfjUErRqp-"
   },
   "source": [
    "#### HESTON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HA-jgu5URtQU"
   },
   "outputs": [],
   "source": [
    "def generate_heston(n_paths, n_steps, t_maturity, mu,\n",
    "                    kappa, theta, xi, rho, v_0, s_0, device='cpu'):\n",
    "    \"\"\"\n",
    "    Heston Model Simulator (Euler-Maruyama Scheme)\n",
    "\n",
    "    Returns:\n",
    "        S_paths (Tensor): (Batch, Steps+1, 1) -> 주가 경로\n",
    "        v_paths (Tensor): (Batch, Steps+1, 1) -> 분산(Variance) 경로\n",
    "    \"\"\"\n",
    "    dt = t_maturity / n_steps\n",
    "    sqrt_dt = torch.sqrt(torch.tensor(dt))\n",
    "\n",
    "    # 1. 상관관계가 있는 난수 생성 (Correlated Brownian Motions)\n",
    "    # Z1: 주가용 난수, Z2: 변동성용 독립 난수\n",
    "    Z1 = torch.randn(n_paths, n_steps, device=device)\n",
    "    Z2 = torch.randn(n_paths, n_steps, device=device)\n",
    "\n",
    "    # dW_S와 dW_v 구성 (Cholesky Decomposition)\n",
    "    # dW_v = rho * dW_S + sqrt(1 - rho^2) * dW_independent\n",
    "    dW_S = Z1 * sqrt_dt\n",
    "    dW_v = (rho * Z1 + torch.sqrt(1 - rho**2) * Z2) * sqrt_dt\n",
    "\n",
    "    # 2. 경로 저장을 위한 텐서 초기화\n",
    "    # (Batch, Steps + 1) -> 초기값 포함\n",
    "    S = torch.zeros(n_paths, n_steps + 1, device=device)\n",
    "    v = torch.zeros(n_paths, n_steps + 1, device=device)\n",
    "\n",
    "    S[:, 0] = s_0\n",
    "    v[:, 0] = v_0\n",
    "\n",
    "    # 3. Time-Stepping (Euler Method)\n",
    "    # Heston은 v_t가 변하므로 for loop 필수 (Vectorized over Batch)\n",
    "    for t in range(n_steps):\n",
    "        # 현재 시점의 값\n",
    "        S_t = S[:, t]\n",
    "        v_t = v[:, t]\n",
    "\n",
    "        # (중요) 분산이 음수가 되는 것을 방지 (Full Truncation Scheme)\n",
    "        # v_t가 음수면 0으로 간주하고 계산\n",
    "        v_t_pos = torch.relu(v_t)\n",
    "\n",
    "        # 분산(Variance) 프로세스 업데이트: dv_t\n",
    "        # dv = kappa * (theta - v) * dt + xi * sqrt(v) * dW_v\n",
    "        dv = kappa * (theta - v_t_pos) * dt + xi * torch.sqrt(v_t_pos) * dW_v[:, t]\n",
    "        v[:, t+1] = v_t + dv\n",
    "\n",
    "        # 주가(Price) 프로세스 업데이트: dS_t (Log Price로 계산하면 더 안정적)\n",
    "        # d(lnS) = (mu - 0.5*v)dt + sqrt(v)dW_S\n",
    "        drift_S = (mu - 0.5 * v_t_pos) * dt\n",
    "        diffusion_S = torch.sqrt(v_t_pos) * dW_S[:, t]\n",
    "\n",
    "        # S_{t+1} = S_t * exp( drift + diffusion )\n",
    "        S[:, t+1] = S_t * torch.exp(drift_S + diffusion_S)\n",
    "\n",
    "    # 4. 차원 맞추기 (Batch, Steps+1, 1) -> Feature 차원 추가\n",
    "    S_paths = S.unsqueeze(-1)\n",
    "    v_paths = v.unsqueeze(-1)\n",
    "\n",
    "    return S_paths, v_paths\n",
    "\n",
    "def generate_var_swap_prices_heston(T, dt, S_paths, v_paths, kappa, theta, r, device): #S,V paths should be dim=2\n",
    "    \"\"\"\n",
    "    Heston 모델 하에서 Variance Swap의 Fair Value Path를 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        T (float): 만기 (연 단위)\n",
    "        dt (float): Time step size\n",
    "        v_paths (torch.Tensor): 시뮬레이션된 분산 경로들 (Batch, Steps+1)\n",
    "        kappa, theta (torch.Tensor): Heston 파라미터\n",
    "        r (float): 무위험 이자율 (Risk-free rate)\n",
    "\n",
    "    Returns:\n",
    "        K_var (torch.Tensor): Fair Strike (scalar or batch scalar)\n",
    "        var_swap_prices (torch.Tensor): 각 시점의 Variance Swap 가격 (Batch, Steps+1, 1)\n",
    "    \"\"\"\n",
    "    batch_size, steps_plus_1 = v_paths.shape\n",
    "\n",
    "    # 1. Time Grid 생성 (남은 만기 계산용)\n",
    "    # t = 0, dt, 2dt, ... , T\n",
    "    times = torch.linspace(0, T, steps_plus_1).to(device)\n",
    "    tau = T - times # (Steps+1,) : 잔존 만기 [T, T-dt, ..., 0]\n",
    "\n",
    "    # Broadcasting을 위해 차원 맞추기\n",
    "    # tau: (1, Steps+1)\n",
    "    tau = tau.unsqueeze(0)\n",
    "\n",
    "    # 2. Fair Strike (K_var) 계산 (t=0 시점 기준)\n",
    "    # K_var = theta + (v_0 - theta) * (1 - e^(-kappa*T)) / (kappa*T)\n",
    "    # 주의: v_paths[:, 0]은 v_0입니다.\n",
    "    v0 = v_paths[:, 0]\n",
    "    K_var = theta + (v0 - theta) * (1 - torch.exp(-kappa * T)) / (kappa * T)\n",
    "\n",
    "    # 3. 미래 기대 분산 (Expected Future Variance) - Heston 공식\n",
    "    # E[int_t^T v_u du] / T 가 아니라, 적분값 자체를 구함\n",
    "    # 식: (T-t)*theta + (v_t - theta) * (1 - e^(-kappa*(T-t))) / kappa\n",
    "\n",
    "    term1 = theta * tau\n",
    "    term2 = (v_paths - theta) * (1 - torch.exp(-kappa * tau)) / kappa\n",
    "    expected_future_integral = term1 + term2 # (Batch, Steps+1)\n",
    "\n",
    "    # 4. 과거 실현 분산 (Realized Variance)\n",
    "    # 이산 시간에서는 적분 대신 합(Sum) 사용: sum(v_i * dt)\n",
    "    # cumsum을 사용하여 0~t까지의 누적합을 구함\n",
    "    # 주의: t시점의 가격을 구할 때, 보통 t까지의 실현분산 + t이후의 기대분산을 합칩니다.\n",
    "    # 그러나, 우리는 이산시간을 다루기 때문에, t=0에서의 가격이 0이 되기 위해서,\n",
    "    # 아울러 중복 계산을 배제하기 위해서 t-1까지의 실현분산과 t부터의 기대분산을 합치겠습니다.\n",
    "\n",
    "    '''\n",
    "    # v_paths * dt 의 누적 합\n",
    "    current_cumsum = torch.cumsum(v_paths * dt, dim=1) # annual -> daily\n",
    "    realized_integral = current_cumsum - (v_paths * dt) # rv: t -> t-1\n",
    "    '''\n",
    "\n",
    "    # ------------> 수정: 현실성 & 모델 교차 검증을 위해, p_paths로부터 계산된 ln_return^2 = v_t로 정의.)\n",
    "\n",
    "    # S_paths: (Batch, Steps+1) -> [S0, S1, S2, ..., ST]\n",
    "\n",
    "    # 1. 로그 수익률 계산 (크기: Steps)\n",
    "    # r_1 = ln(S1/S0), r_2 = ln(S2/S1), ...\n",
    "    ln_S = torch.log(S_paths)\n",
    "    ln_return = ln_S[:, 1:] - ln_S[:, :-1]  # 차분 (Batch, Steps)\n",
    "\n",
    "    # 2. 제곱 (Realized Variance contribution)\n",
    "    rv_daily = ln_return ** 2\n",
    "\n",
    "    # 3. 누적 합 (Cumsum)을 구하되, t=0 시점(0)을 앞에 붙여줌\n",
    "    # 이렇게 하면 shape가 다시 (Batch, Steps+1)이 되어 time grid와 맞습니다.\n",
    "    zeros = torch.zeros(batch_size, 1).to(device)\n",
    "    rv_stream = torch.cat((zeros, rv_daily), dim=1) # [0, r1^2, r2^2, ...]\n",
    "\n",
    "    # 4. 최종 실현 분산 경로\n",
    "    realized_integral = torch.cumsum(rv_stream, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "    # 5. Variance Swap Price (Pt) 계산\n",
    "    # Pt = e^(-r*tau) * [ (Realized + Expected) / T - K_var ] * N(명목금액=1)\n",
    "\n",
    "    # 차원 맞추기 (K_var는 (Batch,) 이므로 (Batch, 1)로 변경)\n",
    "    if K_var.dim() == 1:\n",
    "        K_var_expanded = K_var.unsqueeze(1)\n",
    "    else:\n",
    "        K_var_expanded = K_var\n",
    "\n",
    "    total_expected_variance = (realized_integral + expected_future_integral) / T\n",
    "\n",
    "    # 할인율 적용\n",
    "    df = torch.exp(-r * tau)\n",
    "\n",
    "    var_swap_prices = df * (total_expected_variance - K_var_expanded)\n",
    "\n",
    "    # LSTM Input 형태인 (Batch, Steps+1, 1)로 변환\n",
    "    return K_var, var_swap_prices.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cs3SBtWQCpS"
   },
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ksMozD-nyI4"
   },
   "outputs": [],
   "source": [
    "#Loss Functions\n",
    "\n",
    "def entropic_loss(pnl, risk_aversion=1.0):\n",
    "    # pnl: (batch_size,)\n",
    "    x = -risk_aversion * pnl\n",
    "    # log(mean(exp(x))) = logsumexp(x) - log(N)\n",
    "    # logsumexp는 내부적으로 max 값을 빼서 계산하므로 inf가 안 뜸\n",
    "    loss = (1/risk_aversion) * (torch.logsumexp(x, dim=0) - torch.log(torch.tensor(x.size(0), device=pnl.device)))\n",
    "    return loss\n",
    "\n",
    "def cvar_loss(pnl, alpha=0.05):\n",
    "    \"\"\"\n",
    "    pnl: (Batch Size,) 형태의 텐서. 모델의 헷징 결과로 얻은 최종 손익.\n",
    "    alpha: 상위 몇 %의 악성 손실을 볼 것인가 (보통 1%, 5%)\n",
    "    \"\"\"\n",
    "    # 1. P&L을 오름차순 정렬 (손실이 큰 순서대로, 즉 값이 작은 순서대로)\n",
    "    sorted_pnl, _ = torch.sort(pnl)\n",
    "\n",
    "    # 2. 하위 alpha%에 해당하는 인덱스 계산\n",
    "    n_samples = pnl.size(0)\n",
    "    cutoff_index = int(n_samples * alpha)\n",
    "\n",
    "    # 3. 하위 alpha%의 평균 계산 (Expected Shortfall)\n",
    "    # pnl이 이익(+)일 수도 손실(-)일 수도 있음.\n",
    "    # CVaR은 보통 '손실의 크기'를 양수로 표현하므로 -를 붙여줌.\n",
    "    # 즉, -100원이면 손실이 100원이므로 Loss는 100이 되어야 함.\n",
    "    tail_loss = -torch.mean(sorted_pnl[:cutoff_index])\n",
    "\n",
    "    return tail_loss\n",
    "\n",
    "def mean_loss(pnl):\n",
    "  se = pnl ** 2\n",
    "  return torch.mean(se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-4Xmtk_n4j6"
   },
   "source": [
    "## BS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTEvGArHnyI4"
   },
   "outputs": [],
   "source": [
    "def bscall(S,K,T,r,sig):\n",
    "  d1 = (np.log(S/K) + (r+0.5*sig**2)*T)/(sig*np.sqrt(T))\n",
    "  d2 = d1 - sig * np.sqrt(T)\n",
    "  return S * norm.cdf(d1) - K*np.exp(-r*T) * norm.cdf(d2)\n",
    "\n",
    "def bsput(S,K,T,r,sig):\n",
    "  d1 = (np.log(S/K) + (r+0.5*sig**2)*T)/(sig*np.sqrt(T))\n",
    "  d2 = d1 - sig * np.sqrt(T)\n",
    "  return K*np.exp(-r*T) * norm.cdf(-d2) - S * norm.cdf(-d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GV6ilrfnfp2J"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import Normal\n",
    "\n",
    "# 1. Black-Scholes Delta 계산 함수 (Vectorized)\n",
    "def calculate_bs_delta(S, time_remaining, K, r, sigma):\n",
    "    \"\"\"\n",
    "    S: 현재 주가 (Tensor)\n",
    "    time_remaining: 잔여 만기 (Tensor)\n",
    "    K: 행사가\n",
    "    r: 무위험 이자율\n",
    "    sigma: 변동성\n",
    "    \"\"\"\n",
    "    # 만기 시점(time_remaining=0) 근처에서의 0으로 나누기 에러 방지용 epsilon\n",
    "    epsilon = 1e-8\n",
    "\n",
    "    d1 = (torch.log(S / K) + (r + 0.5 * sigma ** 2) * time_remaining) / (sigma * torch.sqrt(time_remaining) + epsilon)\n",
    "\n",
    "    normal = Normal(0, 1)\n",
    "    delta = normal.cdf(d1)\n",
    "\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9L9NkOOiGkM"
   },
   "source": [
    "## DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTt4MZIxiI96"
   },
   "outputs": [],
   "source": [
    "def clean_price_data(price_series):\n",
    "    # 1. Pandas Series로 변환 (아직 아니라면)\n",
    "    s = pd.Series(price_series)\n",
    "\n",
    "    # 2. 0 또는 음수값이 있다면 NaN으로 처리 (비정상 데이터 제거)\n",
    "    s[s <= 0] = np.nan\n",
    "    print(f'The number of Nulls : {s.isnull().sum()}')\n",
    "\n",
    "    # 3. 선형 보간 (Linear Interpolation)\n",
    "    # 주변 가격의 평균으로 메꿈으로써 수익률의 급격한 왜곡 방지\n",
    "    s = s.interpolate(method='linear')\n",
    "\n",
    "    # 4. 양 끝단에 남은 결측치 처리 (보통 bfill/ffill로 마무리)\n",
    "    s = s.bfill().ffill()\n",
    "\n",
    "    # 5. data 개수: 3000개 이하\n",
    "    print(f'The number of data points : {len(s)}')\n",
    "    if len(s) > 3000:\n",
    "        s = s.tail(3000)\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4wRPS5OA2G7f"
   },
   "outputs": [],
   "source": [
    "def rolling_rv(prices, window=10):\n",
    "    # prices shape: (Batch, Total_Steps) 이라고 가정\n",
    "    # 1. Log Return 계산\n",
    "    # prices가 float64일 수 있으니 안전하게 .float() 처리\n",
    "    prices = prices.float()\n",
    "    ln_prices = torch.log(prices)\n",
    "    ln_diff = ln_prices[:, 1:] - ln_prices[:, :-1] # (Batch, Total_Steps-1)\n",
    "\n",
    "    # 2. Unfold를 사용하여 Rolling Window 만들기\n",
    "    # dimension 1(시간축)에서 window 사이즈만큼 묶음\n",
    "    # step=1: 한 칸씩 이동\n",
    "    windows = ln_diff.unfold(dimension=1, size=window, step=1)\n",
    "    # windows shape: (Batch, Number_of_Windows, window)\n",
    "\n",
    "    # 3. 각 윈도우의 표준편차(std) 혹은 분산(var) 계산\n",
    "    # Deep Hedging에서는 보통 Std를 많이 쓰지만, RV 개념상 분산이 필요하면 var 유지\n",
    "    # 여기서는 질문주신 코드대로 var 유지하되, 차원 유지\n",
    "    rolling_vars = torch.std(windows, dim=2) # (Batch, Number_of_Windows)\n",
    "\n",
    "    # 4. 차원 확장 (Batch, Steps, 1) - Concat을 위해\n",
    "    rolling_vars = rolling_vars.unsqueeze(-1)\n",
    "\n",
    "    return rolling_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_IWVgPIeB1t"
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "\n",
    "# 1. 기초자산 티커 설정 (예: 애플)\n",
    "aapl = yf.Ticker(\"AAPL\")\n",
    "\n",
    "# 2. 가능한 만기일(Expiration Dates) 확인\n",
    "expirations = aapl.options\n",
    "print(expirations) # 상위 5개만 출력\n",
    "'''\n",
    "# 3. 특정 만기일의 옵션 체인 가져오기 (가장 가까운 만기일 예시)\n",
    "opt_chain = aapl.option_chain(expirations[0])\n",
    "\n",
    "# 4. 콜옵션(Calls)과 풋옵션(Puts) 데이터프레임 추출\n",
    "calls = opt_chain.calls\n",
    "puts = opt_chain.puts\n",
    "\n",
    "# 5. 주요 데이터 확인 (행사가, 현재가, 변동성 등)\n",
    "print(calls[['contractSymbol', 'strike', 'lastPrice', 'impliedVolatility']].head())\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-INnx2TaoC76"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7FpMLLV1oRJM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DeepHedgingModelwoPreviousValues(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim=1):\n",
    "        super(DeepHedgingModel, self).__init__()\n",
    "        '''\n",
    "        PyTorch에서 모델을 만들 때는 보통 nn.Module이라는 기본 클래스를 상속받습니다. nn.Module 안에는 신경망 모델이 동작하는 데 꼭 필요한 복잡한 기능들(파라미터 추적, GPU 이동, 레이어 등록 등)이 이미 구현되어 있습니다.\n",
    "\n",
    "        super(...).__init__()을 호출하는 이유는 \"내가 만든 모델(DeepHedgingModel)도 nn.Module이 가진 그 기능들을 그대로 초기화해서 쓰겠다\"고 선언하는 것입니다.\n",
    "\n",
    "        2. 코드의 구성 요소\n",
    "        super(): 부모 클래스(여기서는 nn.Module)를 가리킵니다.\n",
    "\n",
    "        DeepHedgingModel: 현재 본인이 정의하고 있는 클래스의 이름입니다.\n",
    "\n",
    "        self: 현재 생성된 인스턴스 자기 자신을 의미합니다.\n",
    "\n",
    "        .__init__(): 부모 클래스의 초기화 함수(생성자)를 실행하라는 뜻입니다.\n",
    "        '''\n",
    "\n",
    "        # LSTM 레이어 정의\n",
    "        # input_dim: 시장 정보의 수 (예: 주가, 변동성, 이전 델타 등)\n",
    "        # hidden_dim: 정보를 압축할 은닉 노드 수\n",
    "        # batch_first=True: 입력 데이터 형태를 (Batch, Time, Feat)로 설정\n",
    "        # Batch: 샘플 크기 Time: 말 그대로 며칠 동안의 데이터 인지 Feat: 말 그대로 column 개수\n",
    "        # ex) (1000,20,3): 1000개의 MC 경로가 있고, 20일치이며, 사용하는 데이터가 3개(주가, vol, current delta 처럼)다.\n",
    "        self.lstm = nn.LSTM(input_size=input_dim,\n",
    "                            hidden_size=hidden_dim,\n",
    "                            num_layers=3, #hidden layer 개수\n",
    "                            batch_first=True)\n",
    "\n",
    "        # 출력 레이어 (델타 산출)\n",
    "        # 0과 1 사이의 비중을 출력하기 위해 Tanh나 Sigmoid를 쓰기도 하지만,\n",
    "        # 논문에서는 제약조건에 따라 활성화 함수가 달라질 수 있음\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        # fc indicates fully connected(dense) layer, 즉 마지막 출력 layer로 바로 앞 hidden layer를 전부 받겠다.\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "        # 이건 마지막 출력층에만 가해지는 activaion funciton -> 엥 그럼 각 hidden layer는요?\n",
    "        # 그게 이미 내장되어 있음. 보통 tanh이랑 sigmoid임. -> 엥 왜요?\n",
    "        # 그게 가장 안정적이고 효과가 좋음. 흔히 수정 안하고, 혹여나 자기가 바꾸고 싶으면 아래와 같이 층을 나눠줘야함.\n",
    "\n",
    "        '''\n",
    "        # 이런 식으로 짜면 층 사이에 원하는 함수를 넣을 수 있습니다.\n",
    "        self.lstm1 = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.relu = nn.ReLU() # 층 사이에 넣고 싶은 함수\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "        # forward 함수에서\n",
    "        out, _ = self.lstm1(x)\n",
    "        out = self.relu(out) # 1층 통과 후 ReLU 적용\n",
    "        out, _ = self.lstm2(out) # 그 다음 2층 통과\n",
    "        '''\n",
    "\n",
    "    def forward(self, x, prev_hedge=None):\n",
    "        \"\"\"\n",
    "        x shape: (Batch Size, Time Steps, Features)\n",
    "        \"\"\"\n",
    "        # 1. LSTM 통과\n",
    "        # out shape: (Batch, Time, Hidden) -> 모든 시점의 은닉 상태\n",
    "        # (h_n, c_n): 마지막 시점의 상태 (여기선 사용 안 함)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "\n",
    "        # 2. 델타 계산 (모든 타임 스텝에 대해)\n",
    "        # Deep Hedging은 만기까지의 '모든 시점'에서 리밸런싱이 일어나므로\n",
    "        # 전체 시퀀스(lstm_out)를 다 사용합니다.\n",
    "        deltas = self.activation(self.fc(lstm_out))\n",
    "\n",
    "        return deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1sMJKuYssBzT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DeepHedgingModelWithState(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, output_dim=2):\n",
    "        super(DeepHedgingModelWithState, self).__init__()\n",
    "\n",
    "        # input_dim: 시장 데이터 개수 (예: Log Moneyness + VarSwap Price = 2개)\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        # 실제 입력 차원 계산\n",
    "        # 시장 데이터(input_dim) + 이전 Stock 델타(1) + 이전 VarSwap N(1) + 잔존만기 tau(1)\n",
    "        self.total_input_dim = input_dim + 3\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # LSTMCell\n",
    "        self.lstm_cell = nn.LSTMCell(self.total_input_dim, hidden_dim)\n",
    "\n",
    "        # Normalization\n",
    "        self.layer_normalization = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        # 출력 레이어 (Output dim = 2)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        # 활성화 함수 (Tanh: -1 ~ 1)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, x, initial_delta=None, initial_N=None, T=None, action_bound=1.0):\n",
    "        \"\"\"\n",
    "        x: (Batch, Steps, input_dim)\n",
    "        \"\"\"\n",
    "        batch_size, steps, _ = x.size()\n",
    "\n",
    "        # 1. 초기 은닉 상태 초기화\n",
    "        h_t = torch.zeros(batch_size, self.hidden_dim, device=x.device)\n",
    "        c_t = torch.zeros(batch_size, self.hidden_dim, device=x.device)\n",
    "\n",
    "        # 2. 초기 포지션 설정\n",
    "        # prev_delta (Stock): (Batch, 1)\n",
    "        if initial_delta is None:\n",
    "            prev_delta = torch.zeros(batch_size, 1, device=x.device)\n",
    "        else:\n",
    "            prev_delta = initial_delta\n",
    "\n",
    "        # prev_N (VarSwap): (Batch, 1)\n",
    "        if initial_N is None:\n",
    "            prev_N = torch.zeros(batch_size, 1, device=x.device)\n",
    "        else:\n",
    "            prev_N = initial_N\n",
    "\n",
    "        deltas = []\n",
    "        var_swap_ns = []\n",
    "\n",
    "        # dt 계산 (Steps가 N이므로 dt = T/Steps)\n",
    "        dt = T / steps\n",
    "\n",
    "        # 3. Time Step Loop\n",
    "        for t in range(steps):\n",
    "            # (1) 현재 시점 데이터: (Batch, input_dim)\n",
    "            market_input = x[:, t, :]\n",
    "\n",
    "            # shape: (Batch, 1)\n",
    "            current_time = t * dt\n",
    "            remaining_time = T - current_time\n",
    "            tau = torch.full((batch_size, 1), remaining_time, device=x.device)\n",
    "\n",
    "            # (2) 입력 결합\n",
    "            # [Market(3), Prev_Stock(1), Prev_Var(1), Tau(1)] -> Total 6\n",
    "            lstm_input = torch.cat([market_input, prev_delta, prev_N, tau], dim=1)\n",
    "\n",
    "            # (3) LSTM Cell\n",
    "            h_t, c_t = self.lstm_cell(lstm_input, (h_t, c_t))\n",
    "            h_t_norm = self.layer_normalization(h_t)\n",
    "\n",
    "            # (4) Action 출력 및 분리 (Unpacking)\n",
    "            # fc output: (Batch, 2)\n",
    "            raw_output = self.fc(h_t_norm)\n",
    "            action = self.activation(raw_output) * action_bound\n",
    "\n",
    "            # 텐서 슬라이싱으로 분리 (중요!)\n",
    "            # action[:, 0]은 (Batch,)가 되므로 unsqueeze(1)을 해줘야 (Batch, 1)이 유지됨\n",
    "            delta_t = action[:, 0].unsqueeze(1)      # Stock Hedge Ratio\n",
    "            var_swap_n_t = action[:, 1].unsqueeze(1) # VarSwap Notional\n",
    "\n",
    "            # (5) 저장\n",
    "            deltas.append(delta_t)\n",
    "            var_swap_ns.append(var_swap_n_t)\n",
    "\n",
    "            # (6) 상태 업데이트 (다음 스텝의 입력으로 사용)\n",
    "            prev_delta = delta_t\n",
    "            prev_N = var_swap_n_t\n",
    "\n",
    "        # 4. 결과 합치기 (Batch, Steps, 1)\n",
    "        deltas = torch.stack(deltas, dim=1)\n",
    "        var_swap_ns = torch.stack(var_swap_ns, dim=1)\n",
    "\n",
    "        return deltas, var_swap_ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95588GogvunY"
   },
   "outputs": [],
   "source": [
    "#Deep Hedging with Transformer\n",
    "import math\n",
    "\n",
    "class DeepHedgingModelTransformerViz(nn.Module):\n",
    "    def __init__(self, input_dim, d_model=64, nhead=8, output_dim=2, max_len=90):\n",
    "        super(DeepHedgingModelTransformerViz, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.total_input_dim = input_dim + 3\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # 1. Embedding & PE\n",
    "        self.embedding = nn.Linear(self.total_input_dim, d_model)\n",
    "        self.pos_encoder = nn.Parameter(torch.zeros(1, max_len, d_model))\n",
    "\n",
    "        # 2. Transformer Components (수동 분해)\n",
    "        # nn.TransformerEncoderLayer 대신 직접 정의\n",
    "        # D1 generating Q/K/V with hyperparameters: d/nhead -> QK' = A -> AV = Z\n",
    "        self.mha = nn.MultiheadAttention(embed_dim=d_model, num_heads=nhead, batch_first=True)\n",
    "\n",
    "        # Feed Forward Network\n",
    "        self.linear1 = nn.Linear(d_model, d_model * 4)\n",
    "        self.dropout = nn.Dropout(0.1) #일부 뉴런 의도적으로 끄기. 이건 한 뉴런이 학습 전에 꺼질 확률\n",
    "        self.linear2 = nn.Linear(d_model * 4, d_model)\n",
    "\n",
    "        # Layer Norms\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Activation for FFN\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # 3. Output Layer\n",
    "        self.fc = nn.Linear(d_model, output_dim)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            # 1. Linear & Embedding 초기화\n",
    "            if isinstance(m, (nn.Linear, nn.Embedding)):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.02)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "            # 2. [추가] MultiheadAttention 초기화\n",
    "            elif isinstance(m, nn.MultiheadAttention):\n",
    "                # in_proj_weight: Q, K, V를 만드는 가장 중요한 가중치 (3 * d_model, d_model)\n",
    "                if m.in_proj_weight is not None:\n",
    "                    nn.init.normal_(m.in_proj_weight, mean=0, std=0.02)\n",
    "\n",
    "                # bias도 있다면 0으로 초기화\n",
    "                if m.in_proj_bias is not None:\n",
    "                    nn.init.zeros_(m.in_proj_bias)\n",
    "\n",
    "                # out_proj는 내부적으로 nn.Linear이므로,\n",
    "                # 위 loop가 재귀적으로 돌 때 (1)번 조건에서 처리될 수도 있지만,\n",
    "                # 명시적으로 확실히 하고 싶다면 여기서 해도 됩니다.\n",
    "                # (보통 PyTorch의 재귀적 modules() 호출 덕분에 out_proj는 (1)에서 처리됩니다.)\n",
    "\n",
    "            # 3. Positional Encoding 파라미터\n",
    "            elif isinstance(m, nn.Parameter):\n",
    "                pass\n",
    "\n",
    "        # Positional Encoding 명시적 초기화\n",
    "        nn.init.normal_(self.pos_encoder, mean=0, std=0.02)\n",
    "\n",
    "    def forward(self, x, initial_delta=None, initial_N=None, T=None, action_bound=1.0):\n",
    "        batch_size, steps, _ = x.size()\n",
    "        device = x.device\n",
    "\n",
    "        # 초기값 설정 (생략 가능, 위 코드와 동일)\n",
    "        prev_delta = initial_delta if initial_delta is not None else torch.zeros(batch_size, 1, device=device)\n",
    "        prev_N = initial_N if initial_N is not None else torch.zeros(batch_size, 1, device=device)\n",
    "\n",
    "        deltas = []\n",
    "        var_swap_ns = []\n",
    "\n",
    "        # *** Attention Map을 저장할 리스트 ***\n",
    "        # 매 Time Step마다 모델이 어디를 쳐다봤는지 기록\n",
    "        causal_attention_map = torch.zeros(steps, steps)\n",
    "\n",
    "        final_inputs = torch.empty(batch_size, 0, self.d_model, device=device)\n",
    "        dt = T / steps\n",
    "\n",
    "        for t in range(steps):\n",
    "            # (1) Input 구성 & Embedding\n",
    "            market_input = x[:, t, :]\n",
    "            current_time = t * dt\n",
    "            remaining_time = T - current_time\n",
    "            tau = torch.full((batch_size, 1), remaining_time, device=device)\n",
    "\n",
    "            current_raw_input = torch.cat([market_input, prev_delta, prev_N, tau], dim=1)\n",
    "            current_embed = self.embedding(current_raw_input).unsqueeze(1) * math.sqrt(self.d_model)\n",
    "            current_embed = current_embed + self.pos_encoder[:, t:t+1, :]\n",
    "\n",
    "            final_inputs = torch.cat([final_inputs, current_embed], dim=1)\n",
    "\n",
    "            # (2) Multi-Head Attention (수동 호출)\n",
    "            # need_weights=True로 설정해야 가중치(Map)가 나옴\n",
    "            # attn_output: (Batch, Seq_Len, d_model)\n",
    "            # attn_weights: (Batch, Seq_Len, Seq_Len) -> 이게 바로 Attention Map!\n",
    "            attn_output, attn_weights = self.mha(final_inputs, final_inputs, final_inputs, need_weights=True)\n",
    "            #전자가 Z(20000,sz_times,64), 후자가 A(20000,sz_times,sz_times)\n",
    "\n",
    "            # Residual Connection + LayerNorm\n",
    "            #final_inputs로 미분될 때 gradient vanishing 방지를 위해\n",
    "            # (예컨대 final_inputs로 가는 bias)\n",
    "            x_sub = self.norm1(final_inputs + attn_output)\n",
    "\n",
    "            # (3) Feed Forward\n",
    "            # noise(wx+b = 음수, 필요없음)날리고, 미분값(if 양수) = 1로 해서 빠르게 학습 시키기 위해\n",
    "            ff_output = self.linear2(self.dropout(self.relu(self.linear1(x_sub))))\n",
    "            transformer_output = self.norm2(x_sub + ff_output)\n",
    "\n",
    "            # (4) Attention Map 저장 (가장 마지막 시점 t가 과거를 어떻게 보는지)\n",
    "            # attn_weights[:, -1, :] : 현재 시점(마지막 행)이 과거 모든 시점에 준 가중치\n",
    "            causal_attention_map[t, :t+1] = attn_weights[0, -1, :].detach().cpu()\n",
    "\n",
    "            # (5) Action 도출\n",
    "            last_hidden_state = transformer_output[:, -1, :]\n",
    "            raw_output = self.fc(last_hidden_state)\n",
    "            action = self.activation(raw_output) * action_bound\n",
    "\n",
    "            delta_t = action[:, 0].unsqueeze(1)\n",
    "            var_swap_n_t = action[:, 1].unsqueeze(1)\n",
    "\n",
    "            deltas.append(delta_t) #At each t node, each deltas of samples\n",
    "            var_swap_ns.append(var_swap_n_t)\n",
    "\n",
    "            prev_delta = delta_t\n",
    "            prev_N = var_swap_n_t\n",
    "\n",
    "        deltas = torch.stack(deltas, dim=1)\n",
    "        var_swap_ns = torch.stack(var_swap_ns, dim=1)\n",
    "\n",
    "        # 모델이 뱉는 값에 attention_maps 추가\n",
    "        return deltas, var_swap_ns, causal_attention_map\n",
    "\n",
    "\"\"\"\n",
    "class DeepHedgingModelTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, d_model=64, nhead=8, num_layers=2, output_dim=2, max_len=90): #d_model = hidden_dim\n",
    "        super(DeepHedgingModelTransformer, self).__init__()\n",
    "\n",
    "        # 1. 입력 차원 정의\n",
    "        self.input_dim = input_dim\n",
    "        # 실제 입력: Market(input_dim) + Prev_Stock(1) + Prev_Var(1) + Tau(1) = input_dim + 3\n",
    "        self.total_input_dim = input_dim + 3\n",
    "\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # 2. Embedding Layer\n",
    "        # Raw Input을 Transformer 내부 차원(d_model)으로 뻥튀기 해주는 역할\n",
    "        # (LSTM은 그냥 넣어도 되지만 Transformer는 차원을 맞춰주는 게 성능상 유리함)\n",
    "        self.embedding = nn.Linear(self.total_input_dim, d_model)\n",
    "\n",
    "        # 3. Positional Encoding\n",
    "        # 순서 정보를 주입 (학습 가능한 파라미터로 설정)\n",
    "        self.pos_encoder = nn.Parameter(torch.zeros(1, max_len, d_model)) # max_len x d_model 0 mtx 1개\n",
    "\n",
    "        # 4. Transformer Encoder\n",
    "        # batch_first=True: (Batch, Steps, Features) 형태 유지\n",
    "        # EncoderLayer는 후술할 D1 D2 D3를 DEF / 그냥 Encoder는 그런 Encoderlayer를 몇겹 쌓을지 결정)\n",
    "\n",
    "        # initial W를 통과하고 t by d(=d_model)이 된 mtx에다가, D1 = d x d / D2 = d x dim_feedforward(관습적으로 d*4) / D3 = d*4 x d mtx에 차례대로 projection\n",
    "        # D1: 'Multi Head Attention', 말그대로 본격적으로 d로 뻥튀기된 데이터 정보들에 대해 '어떻게 바라볼까?' 하는 거.\n",
    "        # 이 때 nhead가 들어오는데 nhead = 'data를 몇개의 group(perspective)에서 분석할까?'를 정하는 거고, 각 그룹이 d/n = k차원을 갖는 것 현재는 n=8개의 관점에서, 각 관점마다 8(64/8)개의 차원에서 분석하자\n",
    "        # 무조건 d/n % = 0이어야 하고, 보통 8~64 dim per 1 head가 golden rule.\n",
    "        # D2는 말그대로 고차원으로 걍 한번 projection 해주는 역할\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=d_model*4, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers) #financial scene 에선 under/overfitting 방지를 위해 2~3 정도\n",
    "\n",
    "        # 5. 출력 레이어\n",
    "        self.fc = nn.Linear(d_model, output_dim)\n",
    "\n",
    "        # 6. 활성화 함수\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        # 가중치 초기화 (선택 사항)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "      for m in self.modules():\n",
    "          # Linear 레이어나 Embedding 레이어인 경우\n",
    "          if isinstance(m, (nn.Linear, nn.Embedding)):\n",
    "              nn.init.normal_(m.weight, mean=0, std=0.02)\n",
    "              if m.bias is not None:\n",
    "                  nn.init.zeros_(m.bias) # 편향은 보통 0으로 시작\n",
    "          # Positional Encoding 파라미터인 경우\n",
    "          elif isinstance(m, nn.Parameter):\n",
    "              # 이 부분은 수동으로 지정한 경우라 따로 체크 필요\n",
    "              pass\n",
    "\n",
    "      # PE는 따로 한 번 더 확실히 해줌, 얘는 nn.parameter로 부른거라,module로 안잡힘 즉 layer가 아니라 안잡힘.\n",
    "      nn.init.normal_(self.pos_encoder, mean=0, std=0.02)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz_times, device='cpu'): #지금 당장은 어쩌피 loop 돌면서 attention map 마지막 행만 쓰므로 필요가 없음.\n",
    "        # 미래 정보를 못 보게 가리는 마스크 (Upper Triangular Mask)\n",
    "        # 대각선 위쪽을 -inf로 채움\n",
    "        mask = (torch.triu(torch.ones(sz_times, sz_times, device=device)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def forward(self, x, initial_delta=None, initial_N=None, T=None, action_bound=1.0):\n",
    "\n",
    "        x: (Batch, Steps, input_dim) -> Market Data는 이미 다 알고 있음\n",
    "        하지만 Action은 Loop를 돌면서 하나씩 채워나가야 함.\n",
    "\n",
    "        batch_size, steps, _ = x.size()\n",
    "        device = x.device\n",
    "\n",
    "        # 1. 초기 포지션 설정\n",
    "        if initial_delta is None:\n",
    "            prev_delta = torch.zeros(batch_size, 1, device=device)\n",
    "        else:\n",
    "            prev_delta = initial_delta\n",
    "\n",
    "        if initial_N is None:\n",
    "            prev_N = torch.zeros(batch_size, 1, device=device)\n",
    "        else:\n",
    "            prev_N = initial_N\n",
    "\n",
    "        # 결과를 저장할 리스트\n",
    "        deltas = []\n",
    "        var_swap_ns = []\n",
    "\n",
    "        # Transformer에 넣을 History를 저장하는 버퍼\n",
    "        # (Batch, 0, total_input_dim)에서 시작해서 매 스텝 쌓아감\n",
    "        final_inputs = torch.empty(batch_size, 0, self.d_model, device=device)\n",
    "\n",
    "        dt = T / steps\n",
    "\n",
    "        # --- Time Step Loop (Autoregressive) ---\n",
    "        for t in range(steps):\n",
    "            # (1) 현재 시점의 입력 Feature 구성\n",
    "            market_input = x[:, t, :] # (Batch, input_dim)\n",
    "\n",
    "            current_time = t * dt\n",
    "            remaining_time = T - current_time\n",
    "            tau = torch.full((batch_size, 1), remaining_time, device=device)\n",
    "\n",
    "            # [Market, Prev_Stock, Prev_Var, Tau] 결합 -> (Batch, Total_Input_Dim)\n",
    "            current_raw_input = torch.cat([market_input, prev_delta, prev_N, tau], dim=1)\n",
    "\n",
    "            # (2) Embedding & Scaling\n",
    "            # (Batch, 1, d_model)\n",
    "            current_embed = self.embedding(current_raw_input).unsqueeze(1) * math.sqrt(self.d_model)\n",
    "            # root(d)를 곱해주는 건, embed가 pe에 지지 않게 하기 위해.\n",
    "            # 기존의 pe방식인 sin/cos는 -1~1의 값이 나와 초기값이 임베딩 값보다 커질 가능성 O\n",
    "            # 따라서 이걸 곱해서 임베드도 SCALING해줌. 우리야 0언저리에서 시작하는 learnable PE로 해서 상관 없지만, 있어도 무관하니 남\n",
    "\n",
    "            # (3) Positional Encoding 더하기\n",
    "            # 현재 시점 t에 해당하는 pos_encoding만 가져와서 더함\n",
    "            current_embed = current_embed + self.pos_encoder[:, t:t+1, :]\n",
    "\n",
    "            # (4) History Buffer에 추가\n",
    "            # 이제 history_buffer는 t=0부터 t까지의 정보를 담고 있음 shape: (Batch, t+1, d_model)\n",
    "            final_inputs = torch.cat([final_inputs, current_embed], dim=1)\n",
    "\n",
    "            # (5) Transformer Encoder 통과\n",
    "            # 매 스텝마다 전체 History를 다 다시 봄 (Self-Attention)\n",
    "            # 마스크는 사실 Loop 방식이라 없어도 되지만, 습관적으로 넣거나 패딩용으로 쓸 수 있음.\n",
    "            # 여기서는 causal 구조상 Loop를 돌리므로 t시점 output만 잘 뽑으면 됨.\n",
    "\n",
    "            # (Batch, t+1, d_model)\n",
    "            transformer_output = self.transformer_encoder(final_inputs)\n",
    "\n",
    "            # (6) 현재 시점(t)의 결과만 가져오기\n",
    "            # 마지막 시점의 Hidden State 사용\n",
    "            last_hidden_state = transformer_output[:, -1, :] # (Batch, d_model)\n",
    "\n",
    "            # (7) Action 도출\n",
    "            raw_output = self.fc(last_hidden_state)\n",
    "            action = self.activation(raw_output) * action_bound\n",
    "\n",
    "            # (8) Unpacking & Save\n",
    "            delta_t = action[:, 0].unsqueeze(1)\n",
    "            var_swap_n_t = action[:, 1].unsqueeze(1)\n",
    "\n",
    "            deltas.append(delta_t)\n",
    "            var_swap_ns.append(var_swap_n_t)\n",
    "\n",
    "            # (9) 상태 업데이트\n",
    "            prev_delta = delta_t\n",
    "            prev_N = var_swap_n_t\n",
    "\n",
    "        # 결과 합치기\n",
    "        deltas = torch.stack(deltas, dim=1)\n",
    "        var_swap_ns = torch.stack(var_swap_ns, dim=1)\n",
    "\n",
    "        return deltas, var_swap_ns #2dim\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WSs1Dm3f_7S"
   },
   "source": [
    "# Preparation: Generating df for Learning / Setting HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqEb7jJUf_dT"
   },
   "outputs": [],
   "source": [
    "# Generating Data\n",
    "subject = 'AAPL'\n",
    "N=30\n",
    "\n",
    "\n",
    "df = fdr.DataReader(f'{subject}', '2011', '2025-11')\n",
    "df = df['Close']\n",
    "df = clean_price_data(df)\n",
    "\n",
    "df_train = df.iloc[:-N]\n",
    "\n",
    "print(f'The number of Nulls : {df.isnull().sum()}')\n",
    "print('-'*40)\n",
    "print('-'*40)\n",
    "print(f'The Period of Test Data : {df.index[-N]} ~ {df.index[-1]}' )\n",
    "print('-'*40)\n",
    "print('-'*40)\n",
    "S_0 = df_train.iloc[-1]\n",
    "print(f'S0 = {S_0}')\n",
    "print('-'*40)\n",
    "print('-'*40)\n",
    "\n",
    "plt.plot(df)\n",
    "plt.title(f'{subject} Daily Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oOk1JYQLEy9v"
   },
   "outputs": [],
   "source": [
    "# --- 하이퍼파라미터 설정 ---\n",
    "M = 20000   # 배치 사이즈 (User Code의 주석 참고)\n",
    "T = 30/252\n",
    "dt = T/N\n",
    "r = 0.0\n",
    "NUMBER_OPT = 10000.0\n",
    "RV_WINDOW = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pi-9TV5oYMC"
   },
   "source": [
    "# '1 LSTM with HESTON\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oxPpqx8xgVsK"
   },
   "outputs": [],
   "source": [
    "# HESTON\n",
    "params, v_t = garch_heston_analysis(df)\n",
    "print(f'\\n{params}\\n')\n",
    "# 디바이스 설정 (GPU 권장)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- 하이퍼파라미터 설정 ---\n",
    "mean = torch.tensor(params['mu_simple'])\n",
    "kappa = torch.tensor(params['kappa'])\n",
    "theta = torch.tensor(params['theta'])\n",
    "xi = torch.tensor(params['xi'])\n",
    "rho = torch.tensor(params['rho'])\n",
    "V_0 = torch.tensor(params['v0'])\n",
    "sig_0 = torch.sqrt(V_0)\n",
    "S_0 = torch.tensor(df[-1])\n",
    "S_minus1 = torch.tensor(df[-2].item())\n",
    "K = torch.tensor(df[-1])   # ATM 옵션\n",
    "number_opt = 10000.0\n",
    "window = 10\n",
    "initial_cf = bscall(S_0, K, T, mean, sig_0)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 256 # 논문 설정대로 미니 배치 크기 지정\n",
    "\n",
    "\n",
    "# --- 모델 초기화 ---\n",
    "model_lstm = DeepHedgingModelWithState(input_dim=3, hidden_dim=64).to(device)\n",
    "optimizer = optim.Adam(model_lstm.parameters(), lr=0.005) #deep hedging 논문은 0.005엿음. / batc_size= 256\n",
    "\n",
    "\n",
    "# --- 학습 루프 ---\n",
    "print(\"\\n\\nTraining Start...\")\n",
    "for epoch in range(101):\n",
    "\n",
    "    # 1. 데이터 생성 (generate_heston이 S와 v를 둘 다 뱉도록 수정 필수!)\n",
    "    # prices: (Batch, Steps+1, 1), variances: (Batch, Steps+1)\n",
    "    prices, variances = generate_heston(M, N, T, mean, kappa, theta, xi, rho, V_0, S_0, device=device)\n",
    "\n",
    "    S_T = prices[:, -1, 0]\n",
    "\n",
    "    past_10_prices = (torch.tensor(df[-11:-1].values) * torch.ones(M, 10)).to(device)\n",
    "\n",
    "    prices_expanded = torch.cat([past_10_prices, prices.squeeze(-1)], dim=1)\n",
    "    rolling_rvs = rolling_rv(prices_expanded, window = window)\n",
    "\n",
    "\n",
    "    # 2. Variance Swap Path 생성 (위에서 정의한 함수 사용)\n",
    "    K_var, var_swap_prices = generate_var_swap_prices_heston(T, dt,S_minus1, variances[:, :, 0], kappa, theta, r, device)\n",
    "\n",
    "    # 3. Inputs 구성\n",
    "    log_moneyness = torch.log(prices / K)\n",
    "\n",
    "    # shape: (Batch, Steps+1, 3)\n",
    "    inputs = torch.cat([log_moneyness, var_swap_prices, rolling_rvs], dim=2)\n",
    "\n",
    "    # 마지막 시점(T)은 Action을 취할 필요가 없으므로 제외 (Batch, Steps, 2)\n",
    "    inputs = inputs[:, :-1, :]\n",
    "\n",
    "\n",
    "\n",
    "    # 2. 미니 배치 루프\n",
    "\n",
    "    COST_BPS_STOCK = 10.0\n",
    "    COST_BPS_VAR   = 50.0  # 분산 스왑은 유동성 고려하여 조금 더 높게 설정\n",
    "\n",
    "    # 2. 미니 배치 루프\n",
    "    epoch_loss = 0.0\n",
    "    epoch_loss_mse = 0.0\n",
    "    epoch_loss_entropy = 0.0\n",
    "    epoch_final_pnl = 0.0\n",
    "    num_iters = 0\n",
    "\n",
    "    for i in range(0, M, BATCH_SIZE):\n",
    "\n",
    "        # [변수명 변경 반영] var_swap_paths -> var_swap_prices\n",
    "        if (i + 2*BATCH_SIZE) > M:\n",
    "            # 마지막 짜투리 배치\n",
    "            batch_inputs = inputs[i:, :, :]\n",
    "            batch_prices = prices[i:, :, :]             # Stock Price Path\n",
    "            batch_varswaps = var_swap_prices[i:, :, :]  # VarSwap Price Path (Batch, Steps+1, 1)\n",
    "            batch_K_var = K_var[i:]                     # K_var (Batch,) - 비용 계산용\n",
    "            option_payoff = torch.relu(S_T - K)[i:]\n",
    "            is_last_batch = True\n",
    "        else:\n",
    "            # 일반 배치\n",
    "            batch_inputs = inputs[i : i + BATCH_SIZE, :, :]\n",
    "            batch_prices = prices[i : i + BATCH_SIZE, :, :]\n",
    "            batch_varswaps = var_swap_prices[i : i + BATCH_SIZE, :, :]\n",
    "            batch_K_var = K_var[i : i + BATCH_SIZE]\n",
    "            option_payoff = torch.relu(S_T - K)[i : i + BATCH_SIZE]\n",
    "            is_last_batch = False\n",
    "\n",
    "        # 3. 모델 예측 (Action)\n",
    "        # deltas: Stock Hedge Ratio, var_swap_ns: VarSwap Notional\n",
    "        deltas, var_swap_ns = model_lstm(batch_inputs, T=T)\n",
    "\n",
    "        # 4. 차원 맞추기 (Squeeze) -> (Batch, Steps)\n",
    "        deltas = deltas.squeeze(-1)\n",
    "        var_swap_ns = var_swap_ns.squeeze(-1)\n",
    "\n",
    "        # 5. 자산 가격 변화량 계산 (t+1 - t)\n",
    "        # Stock Change\n",
    "        price_changes_stock = batch_prices[:, 1:, 0] - batch_prices[:, :-1, 0]\n",
    "        # VarSwap Change (변수명 변경 반영)\n",
    "        price_changes_var = batch_varswaps[:, 1:, 0] - batch_varswaps[:, :-1, 0]\n",
    "\n",
    "        # 6. 거래 비용 (Transaction Cost) 계산\n",
    "\n",
    "        # (A) Stock Cost\n",
    "        # 이전 델타와 현재 델타의 차이 (거래량)\n",
    "        prev_deltas = torch.cat([torch.zeros(deltas.size(0), 1).to(device), deltas[:, :-1]], dim=1)\n",
    "        delta_changes = torch.abs(deltas - prev_deltas)\n",
    "        # 비용 = 거래량 * 주가 * bps\n",
    "        cost_stock = torch.sum(delta_changes * batch_prices[:, :-1, 0] * (COST_BPS_STOCK / 10000), dim=1)\n",
    "\n",
    "        # (B) VarSwap Cost\n",
    "        # 이전 N과 현재 N의 차이\n",
    "        prev_ns = torch.cat([torch.zeros(var_swap_ns.size(0), 1).to(device), var_swap_ns[:, :-1]], dim=1)\n",
    "        n_changes = torch.abs(var_swap_ns - prev_ns)\n",
    "\n",
    "        # VarSwap 비용은 '가격(0 근처)'이 아닌 'Notional(K_var)' 기준으로 매기는 것이 일반적\n",
    "        # batch_K_var 차원 확장: (Batch,) -> (Batch, 1) -> Broadcasting\n",
    "        k_var_expanded = batch_K_var.unsqueeze(1)\n",
    "        cost_var = torch.sum(n_changes * k_var_expanded * (COST_BPS_VAR / 10000), dim=1)\n",
    "\n",
    "        # 7. Hedging P&L 계산 (수익 - 비용)\n",
    "        # Stock P&L + VarSwap P&L - Stock Cost - Var Cost\n",
    "        gain_stock = torch.sum(deltas * price_changes_stock, dim=1)\n",
    "        gain_var = torch.sum(var_swap_ns * price_changes_var, dim=1)\n",
    "\n",
    "        hedging_pnl = (gain_stock + gain_var) - (cost_stock + cost_var)\n",
    "\n",
    "        # 8. 최종 P&L 및 Loss 계산\n",
    "        # Total P&L = (옵션 프리미엄 + 헷징 손익) - 옵션 Payoff\n",
    "        total_pnl = hedging_pnl - option_payoff\n",
    "        final_pnl = number_opt * (total_pnl + initial_cf)\n",
    "\n",
    "        # Loss Function\n",
    "        loss = cvar_loss(total_pnl)\n",
    "        loss_mse = mean_loss(total_pnl)\n",
    "        loss_entropy = entropic_loss(total_pnl)\n",
    "\n",
    "        # 9. 역전파 및 업데이트\n",
    "        optimizer.zero_grad()\n",
    "        torch.nn.utils.clip_grad_norm_(model_lstm.parameters(), max_norm=1.0)\n",
    "        loss_entropy.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 10. 기록\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_loss_mse += loss_mse.item()\n",
    "        epoch_loss_entropy += loss_entropy.item()\n",
    "        epoch_final_pnl += final_pnl.mean().item()\n",
    "        num_iters += 1\n",
    "\n",
    "        if is_last_batch:\n",
    "            break\n",
    "\n",
    "    if epoch  % 10 == 0:\n",
    "       avg_loss = epoch_loss / num_iters\n",
    "       avg_mse = epoch_loss_mse / num_iters\n",
    "       avg_entropy = epoch_loss_entropy / num_iters\n",
    "       avg_pnl = epoch_final_pnl / num_iters\n",
    "\n",
    "       print(f\"\\nEpoch {epoch} | CVaR Loss: {avg_loss:.4f} | MSE Loss: {avg_mse:.4f} | Entropic Loss: {avg_entropy:.4f} | Mean Final PnL: {avg_pnl:.4f}\")\n",
    "print(f\"Training Finished. FAIR PRICE : {avg_entropy:.7f} | BSCALL PRICE : {initial_cf:.7f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bzRJoooNsBzU"
   },
   "outputs": [],
   "source": [
    "model_lstm.eval()  # 모델을 평가 모드로 전환 (Dropout, BatchNorm 비활성화)\n",
    "\n",
    "#generating test stock data\n",
    "\n",
    "prices_test, variances_test = generate_heston(M, N, T, mean, kappa, theta, xi, rho, V_0, S_0, device=device)\n",
    "prices_test = a\n",
    "variances_test=b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGibGCe4sBzU"
   },
   "outputs": [],
   "source": [
    "# --- Test 데이터 준비 (Test Loop 진입 전 실행) ---\n",
    "# prices_test: (Test_Size, Steps+1, 1)\n",
    "# variances_test: (Test_Size, Steps+1) -> Test 데이터 생성 시 분산도 같이 받아야 함\n",
    "# ------------------------------------------------\n",
    "\n",
    "with torch.no_grad(): # 기울기 계산 끄기 (메모리 절약)\n",
    "\n",
    "    # 1. Test용 Variance Swap 데이터 생성\n",
    "    # dt는 학습 때와 동일하게 정의되어 있어야 함 (dt = T/N)\n",
    "    # r_rate = 0.0 (학습과 동일 가정)\n",
    "    K_var_test, var_swap_prices_test = generate_var_swap_prices_heston(T, dt, variances_test[:,:,0], kappa, theta, 0.0, device)\n",
    "    prices_expanded_test = torch.cat([past_10_prices, prices_test.squeeze(-1)], dim=1)\n",
    "    rolling_rvs_test = rolling_rv(prices_expanded_test, window = window)\n",
    "\n",
    "    # 2. Input 구성\n",
    "    log_moneyness_test = torch.log(prices_test / K)\n",
    "\n",
    "    inputs_test = torch.cat([log_moneyness_test, var_swap_prices_test, rolling_rvs_test], dim=2)\n",
    "    inputs_test = inputs_test[:, :-1, :] # 마지막 시점 제외\n",
    "\n",
    "    # 3. 모델 예측 (Action)\n",
    "    # 결과: Stock 델타, VarSwap Notional\n",
    "    deltas_test, var_swap_ns_test = model_lstm(inputs_test, T=T)\n",
    "\n",
    "    # 차원 축소 (Batch, Steps, 1) -> (Batch, Steps)\n",
    "    deltas_test = deltas_test.squeeze(-1)\n",
    "    var_swap_ns_test = var_swap_ns_test.squeeze(-1)\n",
    "\n",
    "    # 4. 자산 가격 변화량 계산 (t+1 - t)\n",
    "    price_changes_stock_test = prices_test[:, 1:, 0] - prices_test[:, :-1, 0]\n",
    "    price_changes_var_test = var_swap_prices_test[:, 1:, 0] - var_swap_prices_test[:, :-1, 0]\n",
    "\n",
    "    # 5. 거래 비용 (Transaction Cost) 계산\n",
    "\n",
    "    # (A) Stock Cost\n",
    "    prev_deltas_stock = torch.cat([torch.zeros(deltas_test.size(0), 1).to(device), deltas_test[:, :-1]], dim=1)\n",
    "    delta_changes_test = torch.abs(deltas_test - prev_deltas_stock)\n",
    "    cost_stock_test = torch.sum(delta_changes_test * prices_test[:, :-1, 0] * (COST_BPS_STOCK / 10000), dim=1)\n",
    "\n",
    "    # (B) VarSwap Cost\n",
    "    prev_ns_var = torch.cat([torch.zeros(var_swap_ns_test.size(0), 1).to(device), var_swap_ns_test[:, :-1]], dim=1)\n",
    "    n_changes_test = torch.abs(var_swap_ns_test - prev_ns_var)\n",
    "\n",
    "    # K_var_test 차원 확장 및 비용 계산\n",
    "    k_var_test_expanded = K_var_test.unsqueeze(1)\n",
    "    cost_var_test = torch.sum(n_changes_test * k_var_test_expanded * (COST_BPS_VAR / 10000), dim=1)\n",
    "\n",
    "    # 6. Hedging P&L 계산 (수익 - 비용)\n",
    "    gain_stock_test = torch.sum(deltas_test * price_changes_stock_test, dim=1)\n",
    "    gain_var_test = torch.sum(var_swap_ns_test * price_changes_var_test, dim=1)\n",
    "\n",
    "    hedging_pnl_test = (gain_stock_test + gain_var_test) - (cost_stock_test + cost_var_test)\n",
    "\n",
    "    # 7. 최종 P&L 및 Loss 계산\n",
    "    S_T_test = prices_test[:, -1, 0]\n",
    "    option_payoff_test = torch.relu(S_T_test - K)\n",
    "\n",
    "    total_pnl_test = hedging_pnl_test - option_payoff_test\n",
    "    # initial_cf는 옵션 프리미엄(초기 현금흐름)\n",
    "    final_pnl_test = (total_pnl_test + initial_cf) # * number_opt (필요시 곱하기)\n",
    "\n",
    "    # Loss Metric 계산\n",
    "    loss_test = cvar_loss(total_pnl_test)\n",
    "    loss_mse_test = mean_loss(total_pnl_test)\n",
    "    loss_entropy_test = entropic_loss(total_pnl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qcf02E-AsBzU"
   },
   "outputs": [],
   "source": [
    "# 2. BS Hedging Simulation\n",
    "# ---------------------------------------------------------\n",
    "# prices_test shape: (Batch, Steps+1, 1)\n",
    "# 우리가 헷징 포지션을 잡아야 하는 건 t=0 부터 t=T-1 까지입니다.\n",
    "\n",
    "with torch.no_grad():\n",
    "    # (1) 입력 데이터 준비\n",
    "    # 시뮬레이션에 사용된 주가 (마지막 만기 시점 제외)\n",
    "    S_t = prices_test[:, :-1, 0] # shape: (Batch, Steps)\n",
    "\n",
    "    # (2) 잔여 만기(Time to Maturity) 텐서 생성\n",
    "    # t=0일 때 잔여만기 T, t=1일 때 T-dt, ...\n",
    "    # shape를 (Batch, Steps)로 맞춰줍니다.\n",
    "    batch_size, steps = S_t.shape\n",
    "    dt = T / steps\n",
    "\n",
    "    # [T, T-dt, T-2dt, ... , dt] 형태로 시간 생성\n",
    "    times = torch.linspace(T, dt, steps, device=device)\n",
    "    time_remaining_matrix = times.unsqueeze(0).expand(batch_size, steps) # (Batch, Steps)\n",
    "\n",
    "    # (3) BS Delta 계산\n",
    "    # r=0 (가정), sigma=sig\n",
    "    bs_deltas = calculate_bs_delta(S_t, time_remaining_matrix, K, 0.0, sig_0)\n",
    "\n",
    "    bs_prev_deltas = torch.cat([torch.zeros(bs_deltas.size(0), 1).to(device), bs_deltas[:, :-1]], dim=1)\n",
    "    bs_delta_changes = torch.abs(bs_deltas - bs_prev_deltas) # (Batch, Steps)\n",
    "\n",
    "    bs_transaction_costs = torch.sum(bs_delta_changes * prices_test[:, :-1, 0] * (COST_BPS_STOCK / 10000), dim=1)\n",
    "\n",
    "    # (4) BS P&L 계산 (Deep Hedging과 동일한 로직)\n",
    "    # 주가 변동분\n",
    "    price_changes_test = prices_test[:, 1:, 0] - prices_test[:, :-1, 0]\n",
    "\n",
    "    # 헷징 포트폴리오 수익\n",
    "    bs_hedging_pnl = torch.sum(bs_deltas * price_changes_test, dim=1) - bs_transaction_costs\n",
    "\n",
    "    # 옵션 Payoff (만기 시점)\n",
    "    S_T_test = prices_test[:, -1, 0]\n",
    "    option_payoff_test = torch.relu(S_T_test - K)\n",
    "\n",
    "    # 최종 P&L (Initial Premium + Hedging PnL - Payoff)\n",
    "    # initial_cf는 BS Call Price라고 하셨으므로, 이론상 이 값의 평균은 0에 수렴해야 함\n",
    "    bs_total_pnl = bs_hedging_pnl - option_payoff_test\n",
    "    bs_final_pnl = (initial_cf + bs_total_pnl) #* number_opt\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. 결과 비교 및 출력\n",
    "# ---------------------------------------------------------\n",
    "print(f\"--- Comparison (Test Paths: {M}) ---\")\n",
    "print(f\"[Deep Hedging] Mean PnL: {final_pnl_test.mean().item():.4f} | Std: {final_pnl_test.std().item():.4f} | CVaR(5%) w/o inital cf: {cvar_loss(final_pnl_test).item():.4f}\")\n",
    "print(f\"[BS Delta]     Mean PnL: {bs_final_pnl.mean().item():.4f} | Std: {bs_final_pnl.std().item():.4f} | CVaR(5%) w/o inital cf: {cvar_loss(bs_final_pnl).item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndYGANZm24TW"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "# 딥러닝 PnL 분포\n",
    "plt.hist(final_pnl_test.cpu().numpy(), bins=75, alpha=0.5, label='Deep Hedging', density=True, color='blue')\n",
    "# BS PnL 분포\n",
    "plt.hist(bs_final_pnl.cpu().numpy(), bins=75, alpha=0.5, label='BS Hedging', density=True, color='red')\n",
    "\n",
    "plt.axvline(x=0, color='k', linestyle='--')\n",
    "plt.title('PnL Distribution Comparison with transaction cost')\n",
    "plt.xlabel('Profit & Loss')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IU2ua2TqsBzV"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 한글 폰트 설정 (필요시 주석 해제)\n",
    "# plt.rcParams['font.family'] = 'Malgun Gothic' # Windows\n",
    "# plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "def visualize_deep_hedging_results(prices, variances, deltas, ns, pnls, T, dt, K):\n",
    "    \"\"\"\n",
    "    prices: (Batch, Steps+1)\n",
    "    variances: (Batch, Steps+1)\n",
    "    deltas: (Batch, Steps) -> Stock Hedge\n",
    "    ns: (Batch, Steps) -> VarSwap Hedge\n",
    "    pnls: (Batch) -> Final P&L\n",
    "    K: Strike Price (Scalar or Tensor)\n",
    "    \"\"\"\n",
    "\n",
    "    # 텐서를 넘파이로 변환 (CPU로 이동 후)\n",
    "    if torch.is_tensor(prices): prices = prices.cpu().numpy()\n",
    "    if torch.is_tensor(variances): variances = variances.cpu().numpy()\n",
    "    if torch.is_tensor(deltas): deltas = deltas.cpu().numpy()\n",
    "    if torch.is_tensor(ns): ns = ns.cpu().numpy()\n",
    "    if torch.is_tensor(pnls): pnls = pnls.cpu().numpy()\n",
    "\n",
    "    # K가 텐서면 변환, 아니면 그대로 사용\n",
    "    if torch.is_tensor(K):\n",
    "        K_val = K.detach().cpu().numpy()\n",
    "    else:\n",
    "        K_val = K\n",
    "\n",
    "    # 시간 축 생성\n",
    "    steps = deltas.shape[1]\n",
    "    time_axis = np.linspace(0, T, steps)\n",
    "\n",
    "    # ==========================================================\n",
    "    # 1. Sample Paths 시각화 (개별 샘플에서의 움직임)\n",
    "    # ==========================================================\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Sample Hedging Paths (Random 3 Samples)', fontsize=16)\n",
    "\n",
    "    sample_indices = np.random.choice(len(prices), 3, replace=False)\n",
    "    colors = ['r', 'g', 'b']\n",
    "\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        # 주가 & 변동성 흐름\n",
    "        ax1 = axes[0, 0]\n",
    "        ax1.plot(time_axis, prices[idx, :-1], color=colors[i], linestyle='-', label=f'Price {i}')\n",
    "        ax1.set_title('Underlying Price Process')\n",
    "        ax1.set_xlabel('Time')\n",
    "\n",
    "        ax2 = axes[0, 1]\n",
    "        ax2.plot(time_axis, np.sqrt(variances[idx, :-1]), color=colors[i], linestyle='--', label=f'Vol {i}')\n",
    "        ax2.set_title('Volatility Process (sqrt(v_t))')\n",
    "        ax2.set_xlabel('Time')\n",
    "\n",
    "        # 헷징 포지션 흐름\n",
    "        ax3 = axes[1, 0]\n",
    "        ax3.plot(time_axis, deltas[idx, :], color=colors[i], label=f'Delta {i}')\n",
    "        ax3.set_title('Stock Hedge Ratio (Delta)')\n",
    "        ax3.set_xlabel('Time')\n",
    "\n",
    "        ax4 = axes[1, 1]\n",
    "        ax4.plot(time_axis, ns[idx, :], color=colors[i], label=f'VarSwap N {i}')\n",
    "        ax4.set_title('VarSwap Notional (N)')\n",
    "        ax4.set_xlabel('Time')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    # ==========================================================\n",
    "    # 2. Scatter Plots + Trendline (Aggregate: 전체 기간 뭉뚱그림)\n",
    "    # ==========================================================\n",
    "    # 데이터를 1차원으로 펼치기 (Batch * Steps)\n",
    "    flat_prices = prices[:, :-1].flatten()\n",
    "    flat_vars = variances[:, :-1].flatten()\n",
    "    flat_vols = np.sqrt(flat_vars)\n",
    "    flat_deltas = deltas.flatten()\n",
    "    flat_ns = ns.flatten()\n",
    "\n",
    "    # K_val이 스칼라일 때와 배열일 때 처리\n",
    "    if np.ndim(K_val) == 0:\n",
    "        flat_moneyness = np.log(flat_prices / K_val)\n",
    "    else:\n",
    "        # K가 (Batch,) 형태라면 확장 필요\n",
    "        # 여기서는 간단히 처리 (사용자 환경에 맞게 조정)\n",
    "        pass\n",
    "        flat_moneyness = np.log(flat_prices / K_val) # K가 스칼라라고 가정\n",
    "\n",
    "    # 샘플링\n",
    "    sample_mask = np.random.choice(len(flat_prices), 5000, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    fig.suptitle('Aggregate Hedging Strategy (All Time Steps)', fontsize=16)\n",
    "\n",
    "    sns.regplot(x=flat_vols[sample_mask], y=flat_deltas[sample_mask], ax=axes[0],\n",
    "                scatter_kws={'alpha':0.1}, line_kws={'color':'red'}, order=2)\n",
    "    axes[0].set_title('Volatility vs Stock Delta')\n",
    "\n",
    "    sns.regplot(x=flat_vols[sample_mask], y=flat_ns[sample_mask], ax=axes[1],\n",
    "                scatter_kws={'alpha':0.1}, line_kws={'color':'red'}, order=2)\n",
    "    axes[1].set_title('Volatility vs VarSwap N')\n",
    "\n",
    "    sns.regplot(x=flat_moneyness[sample_mask], y=flat_deltas[sample_mask], ax=axes[2],\n",
    "                scatter_kws={'alpha':0.1}, line_kws={'color':'red'}, order=3)\n",
    "    axes[2].set_title('Log Moneyness vs Stock Delta')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ==========================================================\n",
    "    # [NEW] 2-1. Time-Sliced Analysis (at t = T/2)\n",
    "    # 특정 시점(중간 지점)을 잘라서 만기 효과(Tau)를 제거하고 봅니다.\n",
    "    # ==========================================================\n",
    "    mid_idx = steps // 2  # 중간 시점 인덱스\n",
    "\n",
    "    # 중간 시점의 데이터만 추출 (Batch Size만큼의 데이터)\n",
    "    slice_vol = np.sqrt(variances[:, mid_idx])\n",
    "    slice_n = ns[:, mid_idx]\n",
    "    slice_delta = deltas[:, mid_idx]\n",
    "    slice_moneyness = np.log(prices[:, mid_idx] / K_val)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    fig.suptitle(f'Time-Sliced Analysis (at Step {mid_idx}/{steps}, t={T/2:.2f})', fontsize=16, color='darkblue')\n",
    "\n",
    "    # (1) Sliced: Vol vs N (여기가 핵심)\n",
    "    # Lowess 추세선을 사용하여 비선형 관계를 더 부드럽게 봅니다.\n",
    "    sns.regplot(x=slice_vol, y=slice_n, ax=axes[1],\n",
    "                scatter_kws={'alpha':0.3, 'color': 'green'},\n",
    "                line_kws={'color':'darkgreen'}, lowess=True)\n",
    "    axes[1].set_title('Volatility vs VarSwap N (at T/2)')\n",
    "    axes[1].set_xlabel('Volatility (sigma)')\n",
    "    axes[1].set_ylabel('VarSwap Notional')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    # (2) Sliced: Vol vs Delta\n",
    "    sns.regplot(x=slice_vol, y=slice_delta, ax=axes[0],\n",
    "                scatter_kws={'alpha':0.3, 'color': 'purple'},\n",
    "                line_kws={'color':'indigo'}, order=2)\n",
    "    axes[0].set_title('Volatility vs Stock Delta (at T/2)')\n",
    "    axes[0].set_xlabel('Volatility (sigma)')\n",
    "    axes[0].set_ylabel('Hedge Ratio (Delta)')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # (3) Sliced: Moneyness vs Delta\n",
    "    sns.regplot(x=slice_moneyness, y=slice_delta, ax=axes[2],\n",
    "                scatter_kws={'alpha':0.3, 'color': 'orange'},\n",
    "                line_kws={'color':'brown'}, order=3)\n",
    "    axes[2].set_title('Moneyness vs Delta (at T/2)')\n",
    "    axes[2].set_xlabel('Log Moneyness')\n",
    "    axes[2].set_ylabel('Hedge Ratio (Delta)')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ==========================================================\n",
    "    # 3. [Alpha] P&L Distribution (성능 증명)\n",
    "    # ==========================================================\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(pnls, bins=50, kde=True, color='blue', stat='density', label='Deep Hedging P&L')\n",
    "\n",
    "    plt.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "    mean_val = np.mean(pnls)\n",
    "    std_val = np.std(pnls)\n",
    "    cvar_val = np.sort(pnls)[:int(len(pnls)*0.05)].mean()\n",
    "\n",
    "    plt.axvline(x=cvar_val, color='red', linestyle=':', label=f'CVaR (5%): {cvar_val:.4f}')\n",
    "    plt.title(f'Final P&L Distribution\\nMean: {mean_val:.4f} | Std: {std_val:.4f} | CVaR: {cvar_val:.4f}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # ==========================================================\n",
    "    # 4. [Alpha] Strategy Heatmap (Aggregate)\n",
    "    # ==========================================================\n",
    "    df_map = pd.DataFrame({\n",
    "        'Moneyness': flat_moneyness[sample_mask],\n",
    "        'Volatility': flat_vols[sample_mask],\n",
    "        'VarSwap_N': flat_ns[sample_mask]\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sc = plt.scatter(df_map['Moneyness'], df_map['Volatility'], c=df_map['VarSwap_N'],\n",
    "                     cmap='coolwarm', alpha=0.7, s=20)\n",
    "    plt.colorbar(sc, label='VarSwap Notional Position')\n",
    "    plt.title('Strategy Heatmap: When does the model buy/sell VarSwap?')\n",
    "    plt.xlabel('Log Moneyness (ln S/K)')\n",
    "    plt.ylabel('Volatility')\n",
    "    plt.axvline(0, color='black', linestyle='--', alpha=0.5)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# --- 실행 코드 ---\n",
    "# 데이터는 Test Loop를 돌리고 난 후의 변수들을 넣으시면 됩니다.\n",
    "# 텐서 상태여도 함수 내부에서 자동으로 numpy로 변환합니다.\n",
    "visualize_deep_hedging_results(\n",
    "    prices_test[:,:,0],\n",
    "    variances_test[:,:,0], # <- 이거 test loop 전에 저장해둔 변동성 path\n",
    "    deltas_test,\n",
    "    var_swap_ns_test,\n",
    "    final_pnl_test,\n",
    "    T, dt, K\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jRBs9acvnCm"
   },
   "source": [
    "# '2 Transformer with Heston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y50B7-ty1lJA"
   },
   "outputs": [],
   "source": [
    "# HESTON\n",
    "params, v_t = garch_heston_analysis(df_train)\n",
    "print(f'\\nEstimated Hyperparameters of Heston: {params}\\n')\n",
    "# 디바이스 설정 (GPU 권장)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- 하이퍼파라미터 설정 ---\n",
    "mean = torch.tensor(params['mu_simple'])\n",
    "kappa = torch.tensor(params['kappa'])\n",
    "theta = torch.tensor(params['theta'])\n",
    "xi = torch.tensor(params['xi'])\n",
    "rho = torch.tensor(params['rho'])\n",
    "V_0 = torch.tensor(params['v0'])\n",
    "sig_0 = torch.sqrt(V_0)\n",
    "S_0 = torch.tensor(df_train[-1])\n",
    "K = torch.tensor(df_train[-1])   # ATM 옵션\n",
    "number_opt = NUMBER_OPT\n",
    "rv_window = RV_WINDOW\n",
    "initial_cf = bscall(S_0, K, T, mean, sig_0)\n",
    "BATCH_SIZE_HESTON = 256\n",
    "\n",
    "\n",
    "# --- 모델 초기화 (Transformer) ---\n",
    "# input_dim=3 (LogMoneyness, VarSwapPrice, RollingRV)\n",
    "model_transformer = DeepHedgingModelTransformerViz(input_dim=3, d_model=64, nhead=4, output_dim=2, max_len=N+10).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model_transformer.parameters(), lr=0.005)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "# [3] Training Loop\n",
    "print(\"\\n\\nTraining Start with Transformer...\")\n",
    "\n",
    "COST_BPS_STOCK = 10.0\n",
    "COST_BPS_VAR   = 30.0\n",
    "\n",
    "epochs = 51\n",
    "attention_maps_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 1. 데이터 생성\n",
    "    prices, variances = generate_heston(M, N, T, mean, kappa, theta, xi, rho, V_0, S_0, device=device)\n",
    "    S_T = prices[:, -1, 0]\n",
    "\n",
    "    # Past Prices 처리\n",
    "    past_prices = (torch.tensor(df_train.iloc[-rv_window-1:-1].values).float() * torch.ones(M, rv_window)).to(device) #t=-1로 부터 rv_window만큼 이전일 까지\n",
    "    prices_expanded = torch.cat([past_prices, prices.squeeze(-1)], dim=1)\n",
    "    rolling_rvs = rolling_rv(prices_expanded, window=rv_window)\n",
    "\n",
    "    # 2. Variance Swap Inputs\n",
    "    K_var, var_swap_prices = generate_var_swap_prices_heston(T, dt, prices[:, :, 0], variances[:, :, 0], kappa, theta, r, device)\n",
    "\n",
    "    # 3. Inputs 구성 (Batch, Steps+1, 3)\n",
    "    log_moneyness = torch.log(prices / K)\n",
    "    inputs = torch.cat([log_moneyness, var_swap_prices, rolling_rvs], dim=2)\n",
    "    inputs = inputs[:, :-1, :] # (Batch, Steps, 3) Action은 T-1까지만 필요\n",
    "\n",
    "    # 배치 루프 변수 초기화\n",
    "    epoch_loss = 0.0\n",
    "    epoch_loss_mse = 0.0\n",
    "    epoch_loss_entropy = 0.0\n",
    "    epoch_final_pnl = 0.0\n",
    "    num_iters = 0\n",
    "\n",
    "    for i in range(0, M, BATCH_SIZE_HESTON):\n",
    "        if (i + 2 * BATCH_SIZE_HESTON) > M:\n",
    "            batch_inputs = inputs[i:, :, :]\n",
    "            batch_prices = prices[i:, :, :]\n",
    "            batch_var = variances[i:, :, 0]\n",
    "            batch_varswaps = var_swap_prices[i:, :, :]\n",
    "            batch_K_var = K_var[i:]\n",
    "            option_payoff = torch.relu(S_T - K)[i:]\n",
    "            is_last_batch = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            batch_inputs = inputs[i : i + BATCH_SIZE_HESTON, :, :]\n",
    "            batch_prices = prices[i : i + BATCH_SIZE_HESTON, :, :]\n",
    "            batch_varswaps = var_swap_prices[i : i + BATCH_SIZE_HESTON, :, :]\n",
    "            batch_K_var = K_var[i : i + BATCH_SIZE_HESTON]\n",
    "            option_payoff = torch.relu(S_T - K)[i : i + BATCH_SIZE_HESTON]\n",
    "            is_last_batch = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # --- [변경] 모델 호출 (Unpacking attention_maps) ---\n",
    "        deltas, var_swap_ns, attn_map_matrix = model_transformer(batch_inputs, T=T)\n",
    "\n",
    "        # 마지막 배치의 Attention Map 저장 (시각화용)\n",
    "        if is_last_batch:\n",
    "            revised_attention_mtx = torch.zeros((N,N), device=device)\n",
    "            for i in range(N):\n",
    "              revised_attention_mtx[i,:i+1] = attn_map_matrix[i][0]\n",
    "\n",
    "            attention_maps_history.append(revised_attention_mtx)\n",
    "\n",
    "        deltas = deltas.squeeze(-1)\n",
    "        var_swap_ns = var_swap_ns.squeeze(-1)\n",
    "\n",
    "        # ... (이하 비용 계산 로직은 기존과 100% 동일) ...\n",
    "        price_changes_stock = batch_prices[:, 1:, 0] - batch_prices[:, :-1, 0]\n",
    "        price_changes_var = batch_varswaps[:, 1:, 0] - batch_varswaps[:, :-1, 0]\n",
    "\n",
    "        prev_deltas = torch.cat([torch.zeros(deltas.size(0), 1).to(device), deltas[:, :-1]], dim=1)\n",
    "        delta_changes = torch.abs(deltas - prev_deltas)\n",
    "        cost_stock = torch.sum(delta_changes * batch_prices[:, :-1, 0] * (COST_BPS_STOCK / 10000), dim=1)\n",
    "\n",
    "        prev_ns = torch.cat([torch.zeros(var_swap_ns.size(0), 1).to(device), var_swap_ns[:, :-1]], dim=1)\n",
    "        n_changes = torch.abs(var_swap_ns - prev_ns)\n",
    "        k_var_expanded = batch_K_var.unsqueeze(1)\n",
    "        cost_var = torch.sum(n_changes * k_var_expanded * (COST_BPS_VAR / 10000), dim=1)\n",
    "\n",
    "        gain_stock = torch.sum(deltas * price_changes_stock, dim=1)\n",
    "        gain_var = torch.sum(var_swap_ns * price_changes_var, dim=1)\n",
    "        hedging_pnl = (gain_stock + gain_var) - (cost_stock + cost_var)\n",
    "\n",
    "        total_pnl = hedging_pnl - option_payoff\n",
    "        final_pnl = number_opt * (total_pnl + initial_cf)\n",
    "\n",
    "        loss = cvar_loss(total_pnl)\n",
    "        loss_mse = mean_loss(total_pnl)\n",
    "        loss_entropy = entropic_loss(total_pnl, risk_aversion = 0.7)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        torch.nn.utils.clip_grad_norm_(model_transformer.parameters(), max_norm=1.0)\n",
    "        loss_entropy.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_loss_mse += loss_mse.item()\n",
    "        epoch_loss_entropy += loss_entropy.item()\n",
    "        epoch_final_pnl += final_pnl.mean().item()\n",
    "        num_iters += 1\n",
    "\n",
    "        if is_last_batch: break\n",
    "\n",
    "    # 에포크 마지막 부분\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    avg_entropy = epoch_loss_entropy / num_iters\n",
    "\n",
    "    # 스케줄러 업데이트\n",
    "    scheduler.step(avg_entropy)\n",
    "\n",
    "\n",
    "    # 학습률이 변했는지 체크해서 알려주는 로직 (수동 verbose)\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    if new_lr < current_lr:\n",
    "        print(f\"--- When Epoch {epoch} is over, Learning Rate Reduced: {current_lr:.6f} -> {new_lr:.6f} ---\")\n",
    "        if new_lr <= 0.0001:\n",
    "          print(f'Stop Learning. (Final Epoch = {epoch})')\n",
    "          print(f\"Epoch {epoch} | CVaR: {avg_loss:.4f} | Entropic Loss: {avg_entropy:.4f} | PnL: {avg_pnl:.4f}\")\n",
    "          break\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "       avg_loss = epoch_loss / num_iters\n",
    "       avg_pnl = epoch_final_pnl / num_iters\n",
    "       avg_entropy = epoch_loss_entropy / num_iters\n",
    "\n",
    "\n",
    "       print(f\"Epoch {epoch} | CVaR: {avg_loss:.4f} | Entropic Loss: {avg_entropy:.4f} | PnL: {avg_pnl:.4f}\")\n",
    "\n",
    "print(f\"Training Finished.\")\n",
    "\n",
    "#[시각화 코드] - 이제 for문 돌면서 리스트를 깔 필요가 없어졌습니다!\n",
    "print(\"\\nVisualizing Attention Map...\")\n",
    "\n",
    "target_epochs = [5, 10, 25, 50]\n",
    "target_epochs = [e for e in target_epochs if e < len(attention_maps_history)]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(24, 6))\n",
    "\n",
    "for i, epoch_idx in enumerate(target_epochs):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # 모델이 이미 예쁘게 만들어준 (N, N) 행렬을 바로 사용\n",
    "    heatmap_data = attention_maps_history[epoch_idx].detach().cpu().numpy()\n",
    "\n",
    "    sns.heatmap(heatmap_data, ax=ax, cmap='viridis', square=True, cbar=True)\n",
    "    ax.set_title(f\"Epoch {epoch_idx}\")\n",
    "    ax.set_xlabel(\"Key (Past)\")\n",
    "    if i == 0: ax.set_ylabel(\"Query (Current)\")\n",
    "    else: ax.set_ylabel(\"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmfxjbgWpvl3"
   },
   "source": [
    "### Saving the Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "87F0hAvipvl3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from google.colab import files # 코랩 브라우저로 바로 다운로드할 때 필요\n",
    "\n",
    "# 1. 모델의 가중치(State Dict)를 파일로 저장\n",
    "save_tf_heston = 'tf_heston_best_weights.pth'\n",
    "torch.save(model_transformer.state_dict(), save_tf_heston)\n",
    "print(f\"가중치가 {save_tf_heston}에 저장되었습니다.\")\n",
    "\n",
    "# 2. 내 컴퓨터(로컬)로 파일 다운로드\n",
    "files.download(save_tf_heston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mAuVdY5Opvl3"
   },
   "outputs": [],
   "source": [
    "# 1. 수정된 클래스로 '새 빈 껍데기' 인스턴스 생성\n",
    "# (init 인자값들은 기존 학습 때와 100% 동일해야 함)\n",
    "model_transformer = DeepHedgingModelTransformerViz(input_dim=3, d_model=64, nhead=4, output_dim=2, max_len=N+10).to(device)\n",
    "\n",
    "\n",
    "# 2. 저장해둔 가중치 파일 불러오기\n",
    "# 로컬에 다운받았던 파일을 다시 코랩 왼쪽 '파일' 탭에 드래그해서 업로드한 후 실행\n",
    "load_path = 'tf_heston_best_weights.pth'\n",
    "model_transformer.load_state_dict(torch.load(load_path, map_location=device))\n",
    "\n",
    "# 3. 모델을 GPU로 보내고 추론 모드로 설정\n",
    "model_transformer.to(device)\n",
    "model_transformer.eval()\n",
    "\n",
    "print(\"수정된 클래스에 기존 가중치 로드가 완료되었습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9ZbHtFxpxl6"
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3Odnnk42qkn"
   },
   "outputs": [],
   "source": [
    "model_transformer.eval()  # 모델을 평가 모드로 전환 (Dropout, BatchNorm 비활성화)\n",
    "\n",
    "#generating test stock data\n",
    "\n",
    "prices_test, variances_test = generate_heston(M, N, T, mean, kappa, theta, xi, rho, V_0, S_0, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NsU2DhIF2qko"
   },
   "outputs": [],
   "source": [
    "# --- Test 데이터 준비 (Test Loop 진입 전 실행) ---\n",
    "with torch.no_grad(): # 기울기 계산 끄기 (메모리 절약)\n",
    "\n",
    "    # 1. Test용 Variance Swap 데이터 생성\n",
    "    K_var_test, var_swap_prices_test = generate_var_swap_prices_heston(T, dt, prices_test[:,:,0], variances_test[:,:,0], kappa, theta, r, device)\n",
    "    prices_expanded_test = torch.cat([past_10_prices, prices_test.squeeze(-1)], dim=1)\n",
    "    rolling_rvs_test = rolling_rv(prices_expanded_test, window = window)\n",
    "\n",
    "    # 2. Input 구성\n",
    "    log_moneyness_test = torch.log(prices_test / K)\n",
    "\n",
    "    inputs_test = torch.cat([log_moneyness_test, var_swap_prices_test, rolling_rvs_test], dim=2).float()\n",
    "    inputs_test = inputs_test[:, :-1, :] # 마지막 시점 제외\n",
    "\n",
    "    # 3. 모델 예측 (Action)\n",
    "    # 결과: Stock 델타, VarSwap Notional\n",
    "    deltas_test, var_swap_ns_test,_ = model_transformer(inputs_test, T=T)\n",
    "\n",
    "    # 차원 축소 (Batch, Steps, 1) -> (Batch, Steps)\n",
    "    deltas_test = deltas_test.squeeze(-1)\n",
    "    var_swap_ns_test = var_swap_ns_test.squeeze(-1)\n",
    "\n",
    "    # 4. 자산 가격 변화량 계산 (t+1 - t)\n",
    "    price_changes_stock_test = prices_test[:, 1:, 0] - prices_test[:, :-1, 0]\n",
    "    price_changes_var_test = var_swap_prices_test[:, 1:, 0] - var_swap_prices_test[:, :-1, 0]\n",
    "\n",
    "    # 5. 거래 비용 (Transaction Cost) 계산\n",
    "\n",
    "    # (A) Stock Cost\n",
    "    prev_deltas_stock = torch.cat([torch.zeros(deltas_test.size(0), 1).to(device), deltas_test[:, :-1]], dim=1)\n",
    "    delta_changes_test = torch.abs(deltas_test - prev_deltas_stock)\n",
    "    cost_stock_test = torch.sum(delta_changes_test * prices_test[:, :-1, 0] * (COST_BPS_STOCK / 10000), dim=1)\n",
    "\n",
    "    # (B) VarSwap Cost\n",
    "    prev_ns_var = torch.cat([torch.zeros(var_swap_ns_test.size(0), 1).to(device), var_swap_ns_test[:, :-1]], dim=1)\n",
    "    n_changes_test = torch.abs(var_swap_ns_test - prev_ns_var)\n",
    "\n",
    "    # K_var_test 차원 확장 및 비용 계산\n",
    "    k_var_test_expanded = K_var_test.unsqueeze(1)\n",
    "    cost_var_test = torch.sum(n_changes_test * k_var_test_expanded * (COST_BPS_VAR / 10000), dim=1)\n",
    "\n",
    "    # 6. Hedging P&L 계산 (수익 - 비용)\n",
    "    gain_stock_test = torch.sum(deltas_test * price_changes_stock_test, dim=1)\n",
    "    gain_var_test = torch.sum(var_swap_ns_test * price_changes_var_test, dim=1)\n",
    "\n",
    "    hedging_pnl_test = (gain_stock_test + gain_var_test) - (cost_stock_test + cost_var_test)\n",
    "\n",
    "    # 7. 최종 P&L 및 Loss 계산\n",
    "    S_T_test = prices_test[:, -1, 0]\n",
    "    option_payoff_test = torch.relu(S_T_test - K)\n",
    "\n",
    "    total_pnl_test = hedging_pnl_test - option_payoff_test\n",
    "    # initial_cf는 옵션 프리미엄(초기 현금흐름)\n",
    "    final_pnl_test = (total_pnl_test + initial_cf) # * number_opt (필요시 곱하기)\n",
    "\n",
    "    # Loss Metric 계산\n",
    "    loss_test = cvar_loss(total_pnl_test)\n",
    "    loss_mse_test = mean_loss(total_pnl_test)\n",
    "    loss_entropy_test = entropic_loss(total_pnl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p_uQKVIc2qkp"
   },
   "outputs": [],
   "source": [
    "# 2. BS Hedging Simulation\n",
    "# ---------------------------------------------------------\n",
    "# prices_test shape: (Batch, Steps+1, 1)\n",
    "# 우리가 헷징 포지션을 잡아야 하는 건 t=0 부터 t=T-1 까지입니다.\n",
    "\n",
    "with torch.no_grad():\n",
    "    # (1) 입력 데이터 준비\n",
    "    # 시뮬레이션에 사용된 주가 (마지막 만기 시점 제외)\n",
    "    S_t = prices_test[:, :-1, 0] # shape: (Batch, Steps)\n",
    "\n",
    "    # (2) 잔여 만기(Time to Maturity) 텐서 생성\n",
    "    # t=0일 때 잔여만기 T, t=1일 때 T-dt, ...\n",
    "    # shape를 (Batch, Steps)로 맞춰줍니다.\n",
    "    batch_size, steps = S_t.shape\n",
    "    dt = T / steps\n",
    "\n",
    "    # [T, T-dt, T-2dt, ... , dt] 형태로 시간 생성\n",
    "    times = torch.linspace(T, dt, steps, device=device)\n",
    "    time_remaining_matrix = times.unsqueeze(0).expand(batch_size, steps) # (Batch, Steps)\n",
    "\n",
    "    # (3) BS Delta 계산\n",
    "    # r=0 (가정), sigma=sig\n",
    "    bs_deltas = calculate_bs_delta(S_t, time_remaining_matrix, K, 0.0, sig_0)\n",
    "\n",
    "    bs_prev_deltas = torch.cat([torch.zeros(bs_deltas.size(0), 1).to(device), bs_deltas[:, :-1]], dim=1)\n",
    "    bs_delta_changes = torch.abs(bs_deltas - bs_prev_deltas) # (Batch, Steps)\n",
    "\n",
    "    bs_transaction_costs = torch.sum(bs_delta_changes * prices_test[:, :-1, 0] * (COST_BPS_STOCK / 10000), dim=1)\n",
    "\n",
    "    # (4) BS P&L 계산 (Deep Hedging과 동일한 로직)\n",
    "    # 주가 변동분\n",
    "    price_changes_test = prices_test[:, 1:, 0] - prices_test[:, :-1, 0]\n",
    "\n",
    "    # 헷징 포트폴리오 수익\n",
    "    bs_hedging_pnl = torch.sum(bs_deltas * price_changes_test, dim=1) - bs_transaction_costs\n",
    "\n",
    "    # 옵션 Payoff (만기 시점)\n",
    "    S_T_test = prices_test[:, -1, 0]\n",
    "    option_payoff_test = torch.relu(S_T_test - K)\n",
    "\n",
    "    # 최종 P&L (Initial Premium + Hedging PnL - Payoff)\n",
    "    # initial_cf는 BS Call Price라고 하셨으므로, 이론상 이 값의 평균은 0에 수렴해야 함\n",
    "    bs_total_pnl = bs_hedging_pnl - option_payoff_test\n",
    "    bs_final_pnl = (initial_cf + bs_total_pnl) #* number_opt\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. 결과 비교 및 출력\n",
    "# ---------------------------------------------------------\n",
    "print(f\"--- Comparison (Test Paths: {M}) ---\")\n",
    "print(f\"[Deep Hedging] Mean PnL: {final_pnl_test.mean().item():.4f} | Std: {final_pnl_test.std().item():.4f} | CVaR(5%) w/o inital cf: {cvar_loss(final_pnl_test).item():.4f}\")\n",
    "print(f\"[BS Delta]     Mean PnL: {bs_final_pnl.mean().item():.4f} | Std: {bs_final_pnl.std().item():.4f} | CVaR(5%) w/o inital cf: {cvar_loss(bs_final_pnl).item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUJ7fSeL2qkp"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "# 딥러닝 PnL 분포\n",
    "plt.hist(final_pnl_test.cpu().numpy(), bins=75, alpha=0.5, label='Deep Hedging', density=True, color='blue')\n",
    "# BS PnL 분포\n",
    "plt.hist(bs_final_pnl.cpu().numpy(), bins=75, alpha=0.5, label='BS Hedging', density=True, color='red')\n",
    "\n",
    "plt.axvline(x=0, color='k', linestyle='--')\n",
    "plt.title('PnL Distribution Comparison with transaction cost')\n",
    "plt.xlabel('Profit & Loss')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTgDOwBu2qkq"
   },
   "outputs": [],
   "source": [
    "# 한글 폰트 설정 (필요시 주석 해제)\n",
    "# plt.rcParams['font.family'] = 'Malgun Gothic' # Windows\n",
    "# plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "def visualize_deep_hedging_results(prices, variances, deltas, ns, pnls, T, dt, K):\n",
    "    \"\"\"\n",
    "    prices: (Batch, Steps+1)\n",
    "    variances: (Batch, Steps+1)\n",
    "    deltas: (Batch, Steps) -> Stock Hedge\n",
    "    ns: (Batch, Steps) -> VarSwap Hedge\n",
    "    pnls: (Batch) -> Final P&L\n",
    "    K: Strike Price (Scalar or Tensor)\n",
    "    \"\"\"\n",
    "\n",
    "    # 텐서를 넘파이로 변환 (CPU로 이동 후)\n",
    "    if torch.is_tensor(prices): prices = prices.cpu().numpy()\n",
    "    if torch.is_tensor(variances): variances = variances.cpu().numpy()\n",
    "    if torch.is_tensor(deltas): deltas = deltas.cpu().numpy()\n",
    "    if torch.is_tensor(ns): ns = ns.cpu().numpy()\n",
    "    if torch.is_tensor(pnls): pnls = pnls.cpu().numpy()\n",
    "\n",
    "    # K가 텐서면 변환, 아니면 그대로 사용\n",
    "    if torch.is_tensor(K):\n",
    "        K_val = K.detach().cpu().numpy()\n",
    "    else:\n",
    "        K_val = K\n",
    "\n",
    "    # 시간 축 생성\n",
    "    steps = deltas.shape[1]\n",
    "    time_axis = np.linspace(0, T, steps)\n",
    "\n",
    "    # ==========================================================\n",
    "    # 1. Sample Paths 시각화 (개별 샘플에서의 움직임)\n",
    "    # ==========================================================\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Sample Hedging Paths (Random 3 Samples)', fontsize=16)\n",
    "\n",
    "    sample_indices = np.random.choice(len(prices), 3, replace=False)\n",
    "    colors = ['r', 'g', 'b']\n",
    "\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        # 주가 & 변동성 흐름\n",
    "        ax1 = axes[0, 0]\n",
    "        ax1.plot(time_axis, prices[idx, :-1], color=colors[i], linestyle='-', label=f'Price {i}')\n",
    "        ax1.set_title('Underlying Price Process')\n",
    "        ax1.set_xlabel('Time')\n",
    "\n",
    "        ax2 = axes[0, 1]\n",
    "        ax2.plot(time_axis, np.sqrt(variances[idx, :-1]), color=colors[i], linestyle='--', label=f'Vol {i}')\n",
    "        ax2.set_title('Volatility Process (sqrt(v_t))')\n",
    "        ax2.set_xlabel('Time')\n",
    "\n",
    "        # 헷징 포지션 흐름\n",
    "        ax3 = axes[1, 0]\n",
    "        ax3.plot(time_axis, deltas[idx, :], color=colors[i], label=f'Delta {i}')\n",
    "        ax3.set_title('Stock Hedge Ratio (Delta)')\n",
    "        ax3.set_xlabel('Time')\n",
    "\n",
    "        ax4 = axes[1, 1]\n",
    "        ax4.plot(time_axis, ns[idx, :], color=colors[i], label=f'VarSwap N {i}')\n",
    "        ax4.set_title('VarSwap Notional (N)')\n",
    "        ax4.set_xlabel('Time')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    # ==========================================================\n",
    "    # 2. Scatter Plots + Trendline (Aggregate: 전체 기간 뭉뚱그림)\n",
    "    # ==========================================================\n",
    "    # 데이터를 1차원으로 펼치기 (Batch * Steps)\n",
    "    flat_prices = prices[:, :-1].flatten()\n",
    "    flat_vars = variances[:, :-1].flatten()\n",
    "    flat_vols = np.sqrt(flat_vars)\n",
    "    flat_deltas = deltas.flatten()\n",
    "    flat_ns = ns.flatten()\n",
    "\n",
    "    # K_val이 스칼라일 때와 배열일 때 처리\n",
    "    if np.ndim(K_val) == 0:\n",
    "        flat_moneyness = np.log(flat_prices / K_val)\n",
    "    else:\n",
    "        # K가 (Batch,) 형태라면 확장 필요\n",
    "        # 여기서는 간단히 처리 (사용자 환경에 맞게 조정)\n",
    "        pass\n",
    "        flat_moneyness = np.log(flat_prices / K_val) # K가 스칼라라고 가정\n",
    "\n",
    "    # 샘플링\n",
    "    sample_mask = np.random.choice(len(flat_prices), 5000, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    fig.suptitle('Aggregate Hedging Strategy (All Time Steps)', fontsize=16)\n",
    "\n",
    "    sns.regplot(x=flat_vols[sample_mask], y=flat_deltas[sample_mask], ax=axes[0],\n",
    "                scatter_kws={'alpha':0.1}, line_kws={'color':'red'}, order=2)\n",
    "    axes[0].set_title('Volatility vs Stock Delta')\n",
    "\n",
    "    sns.regplot(x=flat_vols[sample_mask], y=flat_ns[sample_mask], ax=axes[1],\n",
    "                scatter_kws={'alpha':0.1}, line_kws={'color':'red'}, order=2)\n",
    "    axes[1].set_title('Volatility vs VarSwap N')\n",
    "\n",
    "    sns.regplot(x=flat_moneyness[sample_mask], y=flat_deltas[sample_mask], ax=axes[2],\n",
    "                scatter_kws={'alpha':0.1}, line_kws={'color':'red'}, order=3)\n",
    "    axes[2].set_title('Log Moneyness vs Stock Delta')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ==========================================================\n",
    "    # [NEW] 2-1. Time-Sliced Analysis (at t = T/2)\n",
    "    # 특정 시점(중간 지점)을 잘라서 만기 효과(Tau)를 제거하고 봅니다.\n",
    "    # ==========================================================\n",
    "    mid_idx = steps // 2  # 중간 시점 인덱스\n",
    "\n",
    "    # 중간 시점의 데이터만 추출 (Batch Size만큼의 데이터)\n",
    "    slice_vol = np.sqrt(variances[:, mid_idx])\n",
    "    slice_n = ns[:, mid_idx]\n",
    "    slice_delta = deltas[:, mid_idx]\n",
    "    slice_moneyness = np.log(prices[:, mid_idx] / K_val)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    fig.suptitle(f'Time-Sliced Analysis (at Step {mid_idx}/{steps}, t={T/2:.2f})', fontsize=16, color='darkblue')\n",
    "\n",
    "    # (1) Sliced: Vol vs N (여기가 핵심)\n",
    "    # Lowess 추세선을 사용하여 비선형 관계를 더 부드럽게 봅니다.\n",
    "    sns.regplot(x=slice_vol, y=slice_n, ax=axes[1],\n",
    "                scatter_kws={'alpha':0.3, 'color': 'green'},\n",
    "                line_kws={'color':'darkgreen'}, lowess=True)\n",
    "    axes[1].set_title('Volatility vs VarSwap N (at T/2)')\n",
    "    axes[1].set_xlabel('Volatility (sigma)')\n",
    "    axes[1].set_ylabel('VarSwap Notional')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    # (2) Sliced: Vol vs Delta\n",
    "    sns.regplot(x=slice_vol, y=slice_delta, ax=axes[0],\n",
    "                scatter_kws={'alpha':0.3, 'color': 'purple'},\n",
    "                line_kws={'color':'indigo'}, order=2)\n",
    "    axes[0].set_title('Volatility vs Stock Delta (at T/2)')\n",
    "    axes[0].set_xlabel('Volatility (sigma)')\n",
    "    axes[0].set_ylabel('Hedge Ratio (Delta)')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # (3) Sliced: Moneyness vs Delta\n",
    "    sns.regplot(x=slice_moneyness, y=slice_delta, ax=axes[2],\n",
    "                scatter_kws={'alpha':0.3, 'color': 'orange'},\n",
    "                line_kws={'color':'brown'}, order=3)\n",
    "    axes[2].set_title('Moneyness vs Delta (at T/2)')\n",
    "    axes[2].set_xlabel('Log Moneyness')\n",
    "    axes[2].set_ylabel('Hedge Ratio (Delta)')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ==========================================================\n",
    "    # 3. [Alpha] P&L Distribution (성능 증명)\n",
    "    # ==========================================================\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(pnls, bins=50, kde=True, color='blue', stat='density', label='Deep Hedging P&L')\n",
    "\n",
    "    plt.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "    mean_val = np.mean(pnls)\n",
    "    std_val = np.std(pnls)\n",
    "    cvar_val = np.sort(pnls)[:int(len(pnls)*0.05)].mean()\n",
    "\n",
    "    plt.axvline(x=cvar_val, color='red', linestyle=':', label=f'CVaR (5%): {cvar_val:.4f}')\n",
    "    plt.title(f'Final P&L Distribution\\nMean: {mean_val:.4f} | Std: {std_val:.4f} | CVaR: {cvar_val:.4f}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # ==========================================================\n",
    "    # 4. [Alpha] Strategy Heatmap (Aggregate)\n",
    "    # ==========================================================\n",
    "    df_map = pd.DataFrame({\n",
    "        'Moneyness': flat_moneyness[sample_mask],\n",
    "        'Volatility': flat_vols[sample_mask],\n",
    "        'VarSwap_N': flat_ns[sample_mask]\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sc = plt.scatter(df_map['Moneyness'], df_map['Volatility'], c=df_map['VarSwap_N'],\n",
    "                     cmap='coolwarm', alpha=0.7, s=20)\n",
    "    plt.colorbar(sc, label='VarSwap Notional Position')\n",
    "    plt.title('Strategy Heatmap: When does the model buy/sell VarSwap?')\n",
    "    plt.xlabel('Log Moneyness (ln S/K)')\n",
    "    plt.ylabel('Volatility')\n",
    "    plt.axvline(0, color='black', linestyle='--', alpha=0.5)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# --- 실행 코드 ---\n",
    "# 데이터는 Test Loop를 돌리고 난 후의 변수들을 넣으시면 됩니다.\n",
    "# 텐서 상태여도 함수 내부에서 자동으로 numpy로 변환합니다.\n",
    "visualize_deep_hedging_results(\n",
    "    prices_test[:,:,0],\n",
    "    variances_test[:,:,0], # <- 이거 test loop 전에 저장해둔 변동성 path\n",
    "    deltas_test,\n",
    "    var_swap_ns_test,\n",
    "    final_pnl_test,\n",
    "    T, dt, K\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSGuU_9g8AW_"
   },
   "source": [
    "# '3 Transformer with Time-VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yR_N5XMnrnkZ"
   },
   "source": [
    "## Time-VAE Fuctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcSoHZoDrtGX"
   },
   "source": [
    "### Time-VAE En/Decoding & Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "twhoLFDIJWfr"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# ==========================================\n",
    "# DGP\n",
    "# ==========================================\n",
    "\n",
    "def prepare_data_for_Time_VAE(df, N=30, window = 10):\n",
    "\n",
    "  # [전처리] Log Return과 20일 이동 표준편차(Historical Vol)를 같이 씁니다.\n",
    "  log_returns = np.log(df / df.shift(1))\n",
    "  rv = log_returns.rolling(window=window).std() * np.sqrt(252) # 연율화된 변동성\n",
    "\n",
    "  # Feature Concatenate\n",
    "  # Shape: (N, 2) -> [Return, Vol]\n",
    "  data = pd.concat([log_returns, rv], axis=1).dropna()\n",
    "  print(data)\n",
    "\n",
    "  # 데이터셋 분할 (Train / Test)\n",
    "  # 마지막  N일은 Test용으로 남겨둠\n",
    "  train_data_raw = data.iloc[:-N].values\n",
    "  test_data_raw = data.iloc[-N:].values\n",
    "  print(train_data_raw)\n",
    "\n",
    "  print(f\"Train shape: {train_data_raw.shape}, Test shape: {test_data_raw.shape}\")\n",
    "\n",
    "  # ==========================================\n",
    "  # 4. Scaling (StandardScaler)\n",
    "  # ==========================================\n",
    "  # 주의: Scaler는 오직 'Train 데이터'로만 학습(fit)해야 함 (Data Leakage 방지) + 일일 수익률에 대해서만 적용\n",
    "  i = 0 + 1  # scaler 적용 대상\n",
    "  train_not_scaled = train_data_raw[:, i:]\n",
    "  test_not_scaled = test_data_raw[:, i:]\n",
    "\n",
    "  scaler = StandardScaler() # n.samples/ n.features로 보고, sample에 대하여 mu/sig구해서 scaling하는 거라 위에서 미리 reshape(-1,1)할 필요 있음\n",
    "  train_scaled = scaler.fit_transform(train_data_raw[:,:i])\n",
    "  test_scaled = scaler.transform(test_data_raw[:,:i])\n",
    "\n",
    "  test_data = np.concatenate([test_scaled, test_not_scaled], axis=1)\n",
    "  train_data = np.concatenate([train_scaled, train_not_scaled], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # 나중에 복원을 위해 scaler 객체는 잘 보관해야 함\n",
    "  print(f\"Mean: {scaler.mean_[0]:.4f}, Var: {scaler.var_[0]:.4f}\")\n",
    "\n",
    "  # ==========================================\n",
    "  # 5. Sliding Window (Sliding to make samples)\n",
    "  # ==========================================\n",
    "  def create_dataset(data, seq_length):\n",
    "      sequences = []\n",
    "      # 데이터 전체를 순회하며 N개씩 자름\n",
    "      for i in range(len(data) - seq_length + 1):\n",
    "          seq = data[i : i + seq_length]\n",
    "          sequences.append(seq)\n",
    "      return np.array(sequences)\n",
    "\n",
    "  # 학습 데이터 생성 (Batch, Seq_Len, Feature)\n",
    "  X_train = create_dataset(train_data, N)\n",
    "\n",
    "  # 텐서 변환\n",
    "  X_train_tensor = torch.tensor(X_train).float()\n",
    "  # Test 데이터는 그냥 그 자체로 하나의 시퀀스라고 가정 (Batch=1)\n",
    "  X_test_tensor = torch.tensor(test_data).float().unsqueeze(0)\n",
    "\n",
    "  # ==========================================\n",
    "  # 6. Final Check\n",
    "  # ==========================================\n",
    "  print(f\"\\n[Preprocessing Complete]\")\n",
    "  print(f\"Input Shape (Batch, Seq, Feat): {X_train_tensor.shape}\")\n",
    "  print(f\"Test Shape: {X_test_tensor.shape}\")\n",
    "\n",
    "  # 샘플 하나 그려보기 (로그 수익률)\n",
    "  plt.figure(figsize=(10, 4))\n",
    "  plt.plot(X_train_tensor[0, :, 0].numpy(), label='Sample 0 (Log Return)')\n",
    "  plt.title(f\"Preprocessed Input Sample (Standardized Log Return, N={N})\")\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "  return X_train_tensor, X_test_tensor, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "byGuP_X7MkZl"
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Encoder\n",
    "# ==========================================\n",
    "\n",
    "class TimeVAE_Encoder(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=64, latent_dim=8, num_layers=2):\n",
    "        super(TimeVAE_Encoder, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # 1. Feature Extraction (Optional but recommended)\n",
    "        # 입력이 1개라 너무 적으니 16개 정도로 늘려줌\n",
    "        self.feature_embed = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # 2. LSTM Backbone: 한 seq 안에서는 lstm으로 hidden output나옴!\n",
    "        # batch_first=True: 입력이 (Batch, Seq, Feat)일 때 필수\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=16,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # 3. Latent Projections (mu & logvar)\n",
    "        # LSTM의 마지막 hidden state를 받아서 z의 재료를 만듦\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x shape: (Batch, Seq_Len, Input_Dim) -> (Batch, 60, 1)\n",
    "        \"\"\"\n",
    "        # Embed: (Batch, 60, 1) -> (Batch, 60, 16)\n",
    "        x_emb = self.feature_embed(x)\n",
    "\n",
    "        # LSTM Pass\n",
    "        # output: (Batch, Seq, Hidden) -> 전체 시퀀스 출력\n",
    "        # hidden: (h_n, c_n) -> 마지막 타임스텝의 상태\n",
    "        lstm_out, (h_n, _) = self.lstm(x_emb)\n",
    "\n",
    "        # lstm_out shape: (Batch_size, steps, hidden)\n",
    "        # h_n shape: (Num_Layers, Batch, Hidden)\n",
    "        # 즉,lstm_out은 하나하나의 샘플에 대해 마지막 layer에서 진행된 각 t의 각 h_n값들을 전부 샘플마다 기록함.\n",
    "        # h_n(단, lstm_cell아니고 lstm에서)은, 각 layer마다 '마지막 h_n'만 sample들 끼리 묶어서 돌려줌\n",
    "        # 즉, lstm_out[:,-1,:] == h_t[-1] == h_t[-1,:,:] 인거\n",
    "\n",
    "        # h_n shape: (Num_Layers, Batch, Hidden)\n",
    "        # 우리는 마지막 레이어의 마지막 상태만 필요함 -> h_n[-1]\n",
    "        last_hidden = h_n[-1] # Shape: (Batch, Hidden_Dim)\n",
    "\n",
    "        # Project to Latent Parameters\n",
    "        mu = self.fc_mu(last_hidden) # shape: (Batch, latent_dim)\n",
    "        logvar = self.fc_logvar(last_hidden) # shape: (Batch, latent_dim)\n",
    "\n",
    "        return mu, logvar\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMiYwMnVW7LH"
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Decoder 1: Calculating Trend\n",
    "# ==========================================\n",
    "\n",
    "class TrendDecoder(nn.Module):\n",
    "    def __init__(self, z_dim=2, seq_len=60, output_dim=1, degree=5):\n",
    "        \"\"\"\n",
    "        z_dim: Trend용 z의 차원\n",
    "        seq_len: 시계열 길이 (60)\n",
    "        degree: 다항식 차수 (2차 함수면 p=2 -> w0, w1, w2 3개 필요)\n",
    "        \"\"\"\n",
    "        super(TrendDecoder, self).__init__()\n",
    "\n",
    "        self.z_dim = z_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.degree = degree\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        #input: (Batch, z_dim)\n",
    "\n",
    "        # 1. Coefficient Generator (Polynomial Coefficients)\n",
    "        # z를 받아서 (차수 + 1)개의 계수를 만듦. 예: 2차함수면 계수 3개(상수항 포함)\n",
    "        # * output dim은 나중에 수익률 외의 데이터 generate할 때 대비해서!(P+1개씩 늘어남)\n",
    "        self.fc_coeffs = nn.Linear(z_dim, (degree + 1) * output_dim)\n",
    "\n",
    "        # 2. Time Matrix (Fixed, Not Learnable)\n",
    "        # 시간 t = [0, 1, ..., 59]를 미리 만들어둠\n",
    "        # 학습되는 파라미터가 아니므로 buffer로 등록\n",
    "        time_steps = torch.arange(seq_len).float()\n",
    "\n",
    "        # Matrix T: [t^0, t^1, t^2, ...] -> Shape: (Seq_Len, Degree+1)\n",
    "        # 예: [[1, 0, 0], [1, 1/60, 1/3600], [1, 2/60, 4/3600], ...]\n",
    "        time_matrix = []\n",
    "        for d in range(degree + 1):\n",
    "            # 숫자가 너무 커지지 않게 정규화(t / seq_len)해서 거듭제곱\n",
    "            time_matrix.append((time_steps / seq_len) ** d)\n",
    "\n",
    "        time_matrix = torch.stack(time_matrix, dim=1) # (Seq, Deg+1)\n",
    "        self.register_buffer('time_matrix', time_matrix)\n",
    "        #register_buffer는 nn.Module의 method\n",
    "        # 1) backprop에서 not being updated(근데 이건 그냥 torch로 생성해도 동일)\n",
    "        # 2) model.to('cuda') 쓸 때 그냥 하면 time_matrix는 cpu로 인식되어서 오류 뜨는데 register_buffer로 해놓으면 알아서 gpu로 해줌\n",
    "        # 3) model.state_dict하면 같이 불러옴\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        z shape: (Batch, z_dim)\n",
    "        \"\"\"\n",
    "        # 1. Get Coefficients w\n",
    "        # shape: (Batch, Degree+1)\n",
    "        coeffs = self.fc_coeffs(z)\n",
    "\n",
    "        # Output dim이 1보다 클 경우를 대비해 Reshape (우리는 1이라 사실 그대로)\n",
    "        # (Batch, Output_Dim, Degree+1)\n",
    "        # (batch 전체 수(-1로 하면 알아서 계산 때림, 얘도 조절 가능함), row, col로 reshape)\n",
    "        # reshape보다 연산 빠른 대신 애초에 오는게 dim=1 아니면 error\n",
    "\n",
    "        coeffs = coeffs.view(-1, self.output_dim, self.degree + 1)\n",
    "\n",
    "        # 2. Matrix Multiplication (Trend Construction)\n",
    "        # (Batch, Out, Deg+1) @ (Deg+1, Seq) -> (Batch, Out, Seq)\n",
    "        # time_matrix는 (Seq, Deg+1)이므로 transpose해서 곱함\n",
    "        trend = torch.matmul(coeffs, self.time_matrix.t())\n",
    "\n",
    "        # 3. Final Reshape\n",
    "        # (Batch, Out, Seq) -> (Batch, Seq, Out)\n",
    "        trend = trend.permute(0, 2, 1)\n",
    "\n",
    "        return trend\n",
    "\n",
    "# ==========================================\n",
    "# Test the Trend Decoder\n",
    "# ==========================================\n",
    "# 설정: z 2개 사용, 2차 함수(degree=2)\n",
    "trend_decoder = TrendDecoder(z_dim=2, seq_len=60, degree=2)\n",
    "\n",
    "# 가짜 z (Batch=5, Dim=2)\n",
    "dummy_z_trend = torch.randn(5, 2)\n",
    "generated_trend = trend_decoder(dummy_z_trend)\n",
    "\n",
    "print(\"\\n[Trend Decoder Check]\")\n",
    "print(f\"z Input Shape: {dummy_z_trend.shape}\")\n",
    "print(f\"Output Shape:  {generated_trend.shape} (Expected: 5, 60, 1)\")\n",
    "\n",
    "# 그려보기 (첫번째 배치의 Trend)\n",
    "plt.plot(generated_trend[0, :, 0].detach().numpy())\n",
    "plt.title(\"Generated Trend (Polynomial Degree 2)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MqmwyX2_7PXN"
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Decoder 2: Calculating seasonality\n",
    "# ==========================================\n",
    "\n",
    "class SeasonalityDecoder(nn.Module):\n",
    "    def __init__(self, z_dim=2, seq_len=60, output_dim=1, n_harmonics=3):\n",
    "        \"\"\"\n",
    "        n_harmonics: 몇 개의 주파수를 섞을 것인가? (기본 3개 추천)\n",
    "        - k=1: 기본 주기 (데이터 전체 길이에 해당하는 파동)\n",
    "        - k=2: 2배 빠른 파동\n",
    "        - ...\n",
    "        \"\"\"\n",
    "        super(SeasonalityDecoder, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.output_dim = output_dim\n",
    "        self.n_harmonics = n_harmonics\n",
    "\n",
    "        # 1. Amplitudes Generator (Fourier Coefficients)\n",
    "        # 각 harmonic마다 sin, cos 2개의 계수가 필요함 -> 총 2 * n_harmonics 개\n",
    "        # output_dim(채널 수)도 고려\n",
    "        self.fc_total_coefs = nn.Linear(z_dim, 2 * n_harmonics * output_dim)\n",
    "\n",
    "        # 2. Fourier Basis Matrix (Fixed)\n",
    "        # Trend의 time_matrix처럼 미리 계산해두는 파동 기저\n",
    "        # 시간 t = [0, 1, ..., 59]\n",
    "        t = torch.arange(seq_len).float()\n",
    "\n",
    "        # sin, cos 행렬 생성\n",
    "        # Shape: (2 * n_harmonics, Seq_Len)\n",
    "        # 행 구성: [cos_k1, sin_k1, cos_k2, sin_k2, ...] 순서로 쌓음\n",
    "        cos_sin_matrix = []\n",
    "        for k in range(1, n_harmonics + 1):\n",
    "            # 2 * pi * k * t / N\n",
    "            omega_t = 2 * math.pi * k * t / seq_len\n",
    "            cos_sin_matrix.append(torch.cos(omega_t))\n",
    "            cos_sin_matrix.append(torch.sin(omega_t))\n",
    "\n",
    "        cos_sin_matrix = torch.stack(cos_sin_matrix, dim=0) # (2*Harmonics, Seq)\n",
    "\n",
    "        # 역시 학습되지 않는 고정 버퍼로 등록\n",
    "        self.register_buffer('cos_sin_matrix', cos_sin_matrix)\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        z: (Batch, z_dim)\n",
    "        \"\"\"\n",
    "        # 1. 계수 생성 (a_k, b_k)\n",
    "        # amps shape: (Batch, Output_Dim * 2 * Harmonics)\n",
    "        total_coefs = self.fc_total_coefs(z)\n",
    "\n",
    "        # 2. Reshape for Matrix Multiplication\n",
    "        # (Batch, Output_Dim, 2 * Harmonics)\n",
    "        # 여기서도 view를 써서 채널과 계수를 분리\n",
    "        arranged_coefs = total_coefs.view(-1, self.output_dim, 2 * self.n_harmonics)\n",
    "\n",
    "        # 3. Fourier Series Construction (MatMul)\n",
    "        # (Batch, Out, 2*H) @ (2*H, Seq) -> (Batch, Out, Seq)\n",
    "        seasonality = torch.matmul(arranged_coefs, self.cos_sin_matrix)\n",
    "\n",
    "        seasonality = seasonality.permute(0, 2, 1)\n",
    "\n",
    "        # 4. Final Reshape\n",
    "        # (Batch, Seq, Out)\n",
    "        return seasonality\n",
    "\n",
    "# ==========================================\n",
    "# Test the Seasonality Decoder\n",
    "# ==========================================\n",
    "# 설정: z 2개, harmonics 3개 (총 6개의 계수를 z=2에서 뽑아냄)\n",
    "season_decoder = SeasonalityDecoder(z_dim=2, seq_len=60, n_harmonics=3)\n",
    "\n",
    "# 가짜 z\n",
    "dummy_z_season = torch.randn(5, 2)\n",
    "generated_season = season_decoder(dummy_z_season)\n",
    "\n",
    "print(\"\\n[Seasonality Decoder Check]\")\n",
    "print(f\"z Input Shape: {dummy_z_season.shape}\")\n",
    "print(f\"Basis Shape:   {season_decoder.cos_sin_matrix.shape} (Expect: 6, 60)\")\n",
    "print(f\"Output Shape:  {generated_season.shape} (Expect: 5, 60, 1)\")\n",
    "\n",
    "# 시각화 (서로 다른 z가 어떤 파동을 만드는지 2개만 비교)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(generated_season[0, :, 0].detach().numpy(), label='Sample 1')\n",
    "plt.plot(generated_season[1, :, 0].detach().numpy(), label='Sample 2')\n",
    "plt.title(\"Generated Seasonality (3 Harmonics)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zW3ynbFSH-CO"
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Decoder 3: Optimizing Residuals\n",
    "# ==========================================\n",
    "class ResidualDecoder(nn.Module):\n",
    "    def __init__(self, z_dim=4, seq_len=60, hidden_dim=64, output_dim=2):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.sequential = nn.Sequential(nn.Linear(z_dim+1, 16),#시간 추가\n",
    "                                         nn.ReLU())\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=16,\n",
    "                            hidden_size=hidden_dim,\n",
    "                            batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        # 시간 인덱스 생성 (0 ~ 59)\n",
    "        times = torch.arange(seq_len).float()\n",
    "        self.register_buffer('times', times)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # z shape: (batch_size, 4)\n",
    "        batch_size = z.size(0)\n",
    "\n",
    "        # 1. z 확장: (Batch, 4) -> (Batch, 60, 4)\n",
    "        z_expanded = z.unsqueeze(1).expand(-1, self.seq_len, -1)\n",
    "\n",
    "        # 2. times 확장: (60,) -> (1, 60, 1) -> (Batch, 60, 1)\n",
    "        # [수정 2] 브로드캐스팅을 위해 차원을 3개로 맞추고 Batch만큼 늘림\n",
    "        times_expanded = self.times.view(1, -1, 1).expand(batch_size, -1, -1)\n",
    "\n",
    "        # 3. 결합: (Batch, 60, 4) + (Batch, 60, 1) = (Batch, 60, 5)\n",
    "        lstm_input = torch.cat((z_expanded, times_expanded), dim=2)\n",
    "\n",
    "        # 4. LSTM 실행\n",
    "        # output: (Batch, 60, 64)\n",
    "        lstm_out, _ = self.lstm(self.sequential(lstm_input))\n",
    "\n",
    "        # 5. 최종 출력\n",
    "        # (Batch, 60, 1)\n",
    "        residual = self.fc(lstm_out)\n",
    "\n",
    "        return residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwoYjZ_uOQb-"
   },
   "outputs": [],
   "source": [
    "class TimeVAE(nn.Module):\n",
    "    def __init__(self, z_dim1=2, z_dim2=2, z_dim3=4, latent_dim=8, seq_len=60, output_dim=2, trend_degree = 5, n_harmonics = 5):\n",
    "        super().__init__()\n",
    "        self.z_dim1 = z_dim1\n",
    "        self.z_dim2 = z_dim2\n",
    "        self.z_dim3 = z_dim3\n",
    "        self.latent_dim = latent_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.output_dim = output_dim\n",
    "        self.trend_degree = trend_degree\n",
    "        self.n_harmonics = n_harmonics\n",
    "\n",
    "        assert z_dim1 + z_dim2 + z_dim3 == latent_dim, 'Please Check the z_dims'\n",
    "\n",
    "        self.encoder = TimeVAE_Encoder(input_dim=output_dim, hidden_dim=64, latent_dim=latent_dim, num_layers=2)\n",
    "        self.decoder_trend = TrendDecoder(z_dim=z_dim1, seq_len=seq_len, output_dim=output_dim, degree=self.trend_degree)\n",
    "        self.decoder_seasonality = SeasonalityDecoder(z_dim=z_dim2, seq_len=seq_len, output_dim=output_dim, n_harmonics=self.n_harmonics)\n",
    "        self.decoder_residual = ResidualDecoder(z_dim=z_dim3, seq_len=seq_len, hidden_dim=64, output_dim=output_dim)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return mu + eps * std\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    # [New] 디코딩 로직 분리 (생성할 때 쓰려고 뺌)\n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        z: (Batch, latent_dim)가 들어오면 복원된 시계열을 뱉음\n",
    "        \"\"\"\n",
    "        # 1. Z Slicing\n",
    "        z_trend = z[:, : self.z_dim1]\n",
    "        z_seasonality = z[:, self.z_dim1 : self.z_dim1+self.z_dim2]\n",
    "        z_residual = z[:, self.z_dim1+self.z_dim2 : ]\n",
    "\n",
    "        # 2. Decoding\n",
    "        trend = self.decoder_trend(z_trend)\n",
    "        seasonality = self.decoder_seasonality(z_seasonality)\n",
    "        residual = self.decoder_residual(z_residual)\n",
    "\n",
    "        # 3. Summation\n",
    "        recon_x = trend + seasonality + residual\n",
    "\n",
    "        return recon_x, trend, seasonality, residual\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1. Encoding\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "\n",
    "        # 2. Decoding (분리한 함수 호출)\n",
    "        recon_x, trend, seasonality, residual = self.decode(z)\n",
    "\n",
    "        return recon_x, mu, logvar, trend, seasonality, residual\n",
    "\n",
    "\n",
    "    # 딥헤징용 시나리오 제작기\n",
    "    def generate_synthetic_data(self, n_samples, device, vol_of_vol=0.13, df_t=4.0, coef_resid = 1.0, ln_mu = 0.0):\n",
    "        \"\"\"\n",
    "        vol_of_vol: 0.2 권장. (0.3은 Heston 기준 좀 센 편이고, 0.5는 너무 큽니다)\n",
    "                    0.2로 설정하면 1시그마 이벤트 시 약 1.2배, 2시그마 시 1.5배 정도 튑니다.\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            # 1. Latent Sampling\n",
    "            z_sample = torch.randn(n_samples, self.latent_dim).to(device)\n",
    "\n",
    "            # 2. Decode\n",
    "            recon, trend, seasonality, resid = self.decode(z_sample)\n",
    "            recon = trend + seasonality + coef_resid * resid\n",
    "\n",
    "            # 3. RV Extraction & Scaling\n",
    "            pred_annual_rv = torch.abs(recon[:, :, 1])\n",
    "            pred_daily_rv = pred_annual_rv / np.sqrt(252)\n",
    "\n",
    "            # [핵심] Volatility Scaling\n",
    "            # 형님의 우려대로 exp가 너무 커지는 것을 막기 위해\n",
    "            # vol_of_vol을 0.2 정도로 낮게 잡습니다.\n",
    "            # 이러면 sqrt(exp(...))와 같은 효과를 내면서도 코드는 간결합니다.\n",
    "\n",
    "            vol_noise = torch.randn_like(pred_daily_rv) * vol_of_vol\n",
    "\n",
    "            # Spot Volatility = Predicted * Noise (Right Skewed)\n",
    "            spot_vol = pred_daily_rv * torch.exp(vol_noise)\n",
    "\n",
    "            #4. Price Generation (Fat Tail with Standardization)\n",
    "            from torch.distributions import StudentT\n",
    "            t_dist = StudentT(df=df_t)\n",
    "\n",
    "            raw_t_noise = t_dist.sample(spot_vol.shape).to(device)\n",
    "\n",
    "            # ★ 핵심 수정: t-분포의 분산(Var = df/(df-2))을 1로 정규화 ★\n",
    "            if df_t > 2:\n",
    "                std_correction = torch.sqrt(torch.tensor(df_t / (df_t - 2.0)))\n",
    "                heavy_tailed_noise = raw_t_noise / std_correction\n",
    "            else:\n",
    "                heavy_tailed_noise = raw_t_noise # df <= 2는 분산 무한대라 보정 불가\n",
    "\n",
    "            stochastic_returns = ln_mu + heavy_tailed_noise * spot_vol\n",
    "\n",
    "            # 결과 합치기\n",
    "            generated_data = torch.stack([stochastic_returns, pred_annual_rv], dim=2)\n",
    "\n",
    "            return generated_data, pred_annual_rv\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # [Method 2] 형님의 역작: Physically Consistent Generation\n",
    "    # ------------------------------------------------------------------\n",
    "    def generate_physically_consistent_paths(self, historical_returns, n_samples, n_steps,\n",
    "                                             N_window=20, device='cpu', coef_resid=1.0,\n",
    "                                             noise_level= 0.05, z_coef = 1.0, reversion_prob= 0.5, batch_size=20000):\n",
    "        \"\"\"\n",
    "        [Pure Physics Generation - No Compromise]\n",
    "        데이터의 정합성을 위해 인위적 보정을 하지 않고,\n",
    "        수학적 제약(D >= 0)을 통과하는 시나리오가 나올 때까지\n",
    "        무한히 샘플링하여 수집합니다. (Rejection Sampling)\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "\n",
    "        collected_returns = []\n",
    "        collected_rvs = []\n",
    "        total_valid_count = 0\n",
    "        iteration = 0\n",
    "\n",
    "        # Historical Data (N-1개)\n",
    "        hist_tensor_base = torch.tensor(historical_returns[-(N_window-1):], device=device).float()\n",
    "\n",
    "        # 상수 미리 계산\n",
    "        N = float(N_window)\n",
    "        c1 = N**3.0 - N**2.0\n",
    "        c2 = N**2.0 - N\n",
    "        c3 = N\n",
    "        denom = N - 1.0\n",
    "\n",
    "        print(f\"\\n[Pure Physics Generation] Target: {n_samples} | Mode: Rejection Sampling (Strict)\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # 목표 개수를 채울 때까지 무한 루프\n",
    "            while total_valid_count < n_samples:\n",
    "                iteration += 1\n",
    "\n",
    "                # 1. 대량생산 (VAE Generation)\n",
    "                z_sample = (z_coef * torch.randn(batch_size, self.latent_dim)).to(device)\n",
    "\n",
    "                # Decode\n",
    "                recon, trend, seasonality, resid = self.decode(z_sample)\n",
    "                recon = trend + seasonality + coef_resid * resid\n",
    "\n",
    "                # Target Variance\n",
    "                base_rv = torch.abs(recon[:, :, 1])\n",
    "                random_noise = 1.0 + torch.randn_like(base_rv) * noise_level\n",
    "                pred_annual_rv = base_rv * random_noise\n",
    "                target_daily_vars = (pred_annual_rv ** 2) / 252.0\n",
    "\n",
    "                # 2. Physics Check (Vectorized Loop)\n",
    "                current_buffer = hist_tensor_base.unsqueeze(0).repeat(batch_size, 1)\n",
    "\n",
    "                # [변수명 수정 1] 초기화했던 변수명 사용\n",
    "                batch_gen_returns = torch.zeros(batch_size, n_steps, device=device)\n",
    "\n",
    "                # 생존자 마스크 (초기엔 모두 생존)\n",
    "                mask_valid = torch.ones(batch_size, dtype=torch.bool, device=device)\n",
    "\n",
    "                for t in range(n_steps):\n",
    "                    # S, Pi, V_tilde 계산\n",
    "                    S = torch.sum(current_buffer, dim=1)\n",
    "                    Pi = torch.sum(current_buffer ** 2, dim=1)\n",
    "                    V_tilde = target_daily_vars[:, t]\n",
    "\n",
    "                    # 판별식\n",
    "                    discriminant = (c1 * V_tilde) - (c2 * Pi) + (c3 * (S**2))\n",
    "\n",
    "                    # 생존 체크\n",
    "                    step_mask = discriminant >= 0\n",
    "                    mask_valid = mask_valid & step_mask\n",
    "\n",
    "                    discriminant = torch.clamp(discriminant, min=0.0)\n",
    "                    sqrt_det = torch.sqrt(discriminant)\n",
    "\n",
    "                    # [Mean Reversion Logic]\n",
    "                    s_sign = torch.sign(S)\n",
    "                    rand_probs = torch.rand(batch_size, device=device)\n",
    "                    reversion_mask = rand_probs < reversion_prob\n",
    "\n",
    "                    signs = torch.where(reversion_mask, -s_sign, s_sign)\n",
    "                    # S가 0일 경우 랜덤 처리\n",
    "                    signs[S == 0] = torch.randint(0, 2, (batch_size,), device=device)[S == 0].float() * 2 - 1\n",
    "\n",
    "                    # r_new 계산\n",
    "                    r_new = (S + signs * sqrt_det) / denom\n",
    "\n",
    "                    # [변수명 수정 2] 오타 수정 (batch_gen_returns_newurns_org -> batch_gen_returns)\n",
    "                    batch_gen_returns[:, t] = r_new\n",
    "                    current_buffer = torch.cat([current_buffer[:, 1:], r_new.unsqueeze(1)], dim=1)\n",
    "\n",
    "                # 3. 생존자 수거 (Harvest)\n",
    "                # [변수명 수정 3] 오타 및 문법 수정 (valid_rets gen_returns_new_returns_org -> valid_rets =)\n",
    "                valid_rets = batch_gen_returns[mask_valid]\n",
    "                valid_pred_rv = pred_annual_rv[mask_valid]\n",
    "\n",
    "                num_valid = valid_rets.shape[0]\n",
    "\n",
    "                if num_valid > 0:\n",
    "                    collected_returns.append(valid_rets)\n",
    "                    collected_rvs.append(valid_pred_rv)\n",
    "                    total_valid_count += num_valid\n",
    "\n",
    "                survival_rate = num_valid / batch_size\n",
    "                print(f\"\\rIter {iteration}: +{num_valid} (Rate: {survival_rate:.2%}) | Total: {total_valid_count}/{n_samples}\", end=\"\")\n",
    "\n",
    "                del recon, trend, seasonality, resid, z_sample, current_buffer\n",
    "\n",
    "        print(\"\\n[Done] Collection Complete.\")\n",
    "\n",
    "        final_returns = torch.cat(collected_returns, dim=0)[:n_samples]\n",
    "        final_rvs = torch.cat(collected_rvs, dim=0)[:n_samples]\n",
    "\n",
    "        return torch.stack([final_returns, final_rvs], dim=2), final_rvs\n",
    "\n",
    "    def generate_physically_consistent_paths_by_increasing_prob_of_satisfying_det(self, historical_returns, n_samples, n_steps,\n",
    "                                                                                  N_window=20, device='cpu', coef_resid=1.0,\n",
    "                                                                                  noise_level=0.0, z_coef=1.0, batch_size=20000):\n",
    "\n",
    "\n",
    "        self.eval()\n",
    "        \"\"\"\n",
    "        [Survival Optimization Strategy]\n",
    "        Clamping(값 조작)을 하지 않고,\n",
    "        이차방정식의 두 해(Roots) 중에서 '다음 스텝의 생존 확률'을\n",
    "        높여주는(Discriminant를 키우는) 해를 선택하여 생존율을 극대화함.\n",
    "        \"\"\"\n",
    "\n",
    "        collected_returns = []\n",
    "        collected_rvs = []\n",
    "        total_valid_count = 0\n",
    "        iteration = 0\n",
    "\n",
    "        # Historical Data\n",
    "        hist_tensor_base = torch.tensor(historical_returns[-(N_window-1):], device=device).float()\n",
    "\n",
    "        # 상수 미리 계산\n",
    "        N = float(N_window)\n",
    "        c1 = N**3.0 - N**2.0\n",
    "        c2 = N**2.0 - N\n",
    "        c3 = N\n",
    "        denom = N - 1.0\n",
    "\n",
    "        print(f\"\\n[Opt-Physics Generation] Target: {n_samples} | Mode: Maximize Future Survival Score\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            while total_valid_count < n_samples:\n",
    "                iteration += 1\n",
    "\n",
    "                # 1. VAE Generation\n",
    "                z_sample = (z_coef * torch.randn(batch_size, self.latent_dim)).to(device)\n",
    "                recon, trend, seasonality, resid = self.decode(z_sample)\n",
    "                recon = trend + seasonality + coef_resid * resid\n",
    "\n",
    "                base_rv = torch.abs(recon[:, :, 1])\n",
    "                random_noise = 1.0 + torch.randn_like(base_rv) * noise_level\n",
    "                pred_annual_rv = base_rv * random_noise\n",
    "                target_daily_vars = (pred_annual_rv ** 2) / 252.0\n",
    "\n",
    "                # 2. Physics Simulation\n",
    "                current_buffer = hist_tensor_base.unsqueeze(0).repeat(batch_size, 1)\n",
    "                batch_gen_returns = torch.zeros(batch_size, n_steps, device=device)\n",
    "                mask_valid = torch.ones(batch_size, dtype=torch.bool, device=device)\n",
    "\n",
    "                for t in range(n_steps):\n",
    "                    # 현재 상태 계산\n",
    "                    S = torch.sum(current_buffer, dim=1)\n",
    "                    Pi = torch.sum(current_buffer ** 2, dim=1)\n",
    "                    V_tilde = target_daily_vars[:, t]\n",
    "\n",
    "                    # -------------------------------------------------------\n",
    "                    # [Step 1] 현재 생존 여부 체크 (여기는 어쩔 수 없음)\n",
    "                    # -------------------------------------------------------\n",
    "                    discriminant = (c1 * V_tilde) - (c2 * Pi) + (c3 * (S**2))\n",
    "\n",
    "                    step_mask = discriminant >= 0\n",
    "                    mask_valid = mask_valid & step_mask\n",
    "\n",
    "                    discriminant = torch.clamp(discriminant, min=0.0)\n",
    "                    sqrt_det = torch.sqrt(discriminant)\n",
    "\n",
    "                    # -------------------------------------------------------\n",
    "                    # [Step 2] 두 개의 후보 해 계산\n",
    "                    # -------------------------------------------------------\n",
    "                    # Root 1: (S + sqrt_D) / (N-1)\n",
    "                    r_plus = (S + sqrt_det) / denom\n",
    "                    # Root 2: (S - sqrt_D) / (N-1)\n",
    "                    r_minus = (S - sqrt_det) / denom\n",
    "\n",
    "                    # -------------------------------------------------------\n",
    "                    # [Step 3] 미래 예측 (Lookahead Optimization)\n",
    "                    # 다음 스텝의 물리적 유리함을 계산하여 더 좋은 해를 선택\n",
    "                    # Score = -c2 * Pi_next + c3 * S_next^2\n",
    "                    # -------------------------------------------------------\n",
    "\n",
    "                    # 윈도우에서 빠져나갈 가장 오래된 값 (FIFO)\n",
    "                    r_old = current_buffer[:, 0]\n",
    "\n",
    "                    # [Scenario Plus] r_plus를 선택했을 때의 미래\n",
    "                    S_next_plus = S - r_old + r_plus\n",
    "                    Pi_next_plus = Pi - (r_old**2) + (r_plus**2)\n",
    "                    score_plus = (-c2 * Pi_next_plus) + (c3 * (S_next_plus**2))\n",
    "\n",
    "                    # [Scenario Minus] r_minus를 선택했을 때의 미래\n",
    "                    S_next_minus = S - r_old + r_minus\n",
    "                    Pi_next_minus = Pi - (r_old**2) + (r_minus**2)\n",
    "                    score_minus = (-c2 * Pi_next_minus) + (c3 * (S_next_minus**2))\n",
    "\n",
    "                    # 점수가 더 높은 쪽 선택 (True: Plus, False: Minus)\n",
    "                    choose_plus = score_plus > score_minus\n",
    "\n",
    "                    # 최종 해 선택\n",
    "                    r_new = torch.where(choose_plus, r_plus, r_minus)\n",
    "\n",
    "                    # 업데이트\n",
    "                    batch_gen_returns[:, t] = r_new\n",
    "                    current_buffer = torch.cat([current_buffer[:, 1:], r_new.unsqueeze(1)], dim=1)\n",
    "\n",
    "                # 3. Harvest Valid Samples\n",
    "                valid_rets = batch_gen_returns[mask_valid]\n",
    "                valid_pred_rv = pred_annual_rv[mask_valid]\n",
    "\n",
    "                num_valid = valid_rets.shape[0]\n",
    "                if num_valid > 0:\n",
    "                    collected_returns.append(valid_rets)\n",
    "                    collected_rvs.append(valid_pred_rv)\n",
    "                    total_valid_count += num_valid\n",
    "\n",
    "                survival_rate = num_valid / batch_size\n",
    "                print(f\"\\rIter {iteration}: +{num_valid} (Rate: {survival_rate:.2%}) | Total: {total_valid_count}/{n_samples}\", end=\"\")\n",
    "\n",
    "                del recon, trend, seasonality, resid, z_sample, current_buffer\n",
    "\n",
    "        print(\"\\n[Done] Collection Complete.\")\n",
    "\n",
    "        final_returns = torch.cat(collected_returns, dim=0)[:n_samples]\n",
    "        final_rvs = torch.cat(collected_rvs, dim=0)[:n_samples]\n",
    "\n",
    "        return torch.stack([final_returns, final_rvs], dim=2), final_rvs\n",
    "\n",
    "    def generate_physically_consistent_paths_with_clamping(self, historical_returns, n_samples, n_steps,\n",
    "                                                   N_window=20, device='cpu', coef_resid=1.0,\n",
    "                                                   noise_level=0.0, z_coef=1.0, reversion_prob=0.6,\n",
    "                                                   batch_size=20000\n",
    "                                                   ):\n",
    "        self.eval()\n",
    "        \"\"\"\n",
    "        [Final Strategy]\n",
    "        1. Clamping: 판별식 < 0 이면 0으로 만들고\n",
    "        2. Correction: Target RV를 상향 조정하여 물리적 정합성(Label Consistency) 유지\n",
    "        3. Mean Reversion: 'reversion_prob'를 사용하여 가격 발산(Explosion) 방지\n",
    "        \"\"\"\n",
    "\n",
    "        collected_returns = []\n",
    "        collected_rvs = []\n",
    "        total_generated = 0\n",
    "\n",
    "        hist_tensor_base = torch.tensor(historical_returns[-(N_window-1):], device=device).float()\n",
    "\n",
    "        N = float(N_window)\n",
    "        c1 = N**3.0 - N**2.0\n",
    "        c2 = N**2.0 - N\n",
    "        c3 = N\n",
    "        denom = N - 1.0\n",
    "\n",
    "        #print(f\"\\n[Final Generation] Target: {n_samples} | Mean Reversion Prob: {reversion_prob}\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            while total_generated < n_samples:\n",
    "\n",
    "                current_batch_size = min(batch_size, n_samples - total_generated)\n",
    "\n",
    "                # 1. VAE Generation\n",
    "                z_sample = (z_coef * torch.randn(current_batch_size, self.latent_dim)).to(device)\n",
    "                recon, trend, seasonality, resid = self.decode(z_sample)\n",
    "                recon = trend + seasonality + coef_resid * resid\n",
    "\n",
    "                base_rv = torch.abs(recon[:, :, 1])\n",
    "                random_noise = 1.0 + torch.randn_like(base_rv) * noise_level\n",
    "\n",
    "                # Correction을 위해 clone\n",
    "                pred_annual_rv = (base_rv * random_noise).clone()\n",
    "                target_daily_vars = (pred_annual_rv ** 2) / 252.0\n",
    "\n",
    "                # 2. Physics Simulation\n",
    "                current_buffer = hist_tensor_base.unsqueeze(0).repeat(current_batch_size, 1)\n",
    "                batch_gen_returns = torch.zeros(current_batch_size, n_steps, device=device)\n",
    "\n",
    "                for t in range(n_steps):\n",
    "                    S = torch.sum(current_buffer, dim=1)\n",
    "                    Pi = torch.sum(current_buffer ** 2, dim=1)\n",
    "                    V_tilde = target_daily_vars[:, t]\n",
    "\n",
    "                    # -------------------------------------------------------\n",
    "                    # [Step 1] 판별식 계산 & Correction\n",
    "                    # -------------------------------------------------------\n",
    "                    discriminant = (c1 * V_tilde) - (c2 * Pi) + (c3 * (S**2))\n",
    "\n",
    "                    # 판별식이 음수인 경우 (Infeasible)\n",
    "                    mask_infeasible = discriminant < 0\n",
    "                    if mask_infeasible.any():\n",
    "                        # D=0이 되게 하는 최소 V로 업데이트 (Correction)\n",
    "                        V_corrected = (c2 * Pi[mask_infeasible] - c3 * (S[mask_infeasible]**2)) / c1\n",
    "                        V_corrected = torch.maximum(V_corrected, V_tilde[mask_infeasible]) # 안전장치\n",
    "\n",
    "                        # 텐서 값 업데이트 (Label Consistency)\n",
    "                        V_tilde[mask_infeasible] = V_corrected\n",
    "                        target_daily_vars[mask_infeasible, t] = V_corrected\n",
    "                        pred_annual_rv[mask_infeasible, t] = torch.sqrt(V_corrected * 252.0)\n",
    "\n",
    "                        # 판별식 0으로 설정\n",
    "                        discriminant[mask_infeasible] = 0.0\n",
    "\n",
    "                    sqrt_det = torch.sqrt(discriminant)\n",
    "\n",
    "                    # -------------------------------------------------------\n",
    "                    # [Step 2] 두 개의 해 (Roots)\n",
    "                    # -------------------------------------------------------\n",
    "                    r_plus = (S + sqrt_det) / denom  # 큰 해\n",
    "                    r_minus = (S - sqrt_det) / denom # 작은 해\n",
    "\n",
    "                    # -------------------------------------------------------\n",
    "                    # [Step 3] Mean Reversion Selection (발산 방지 핵심)\n",
    "                    # -------------------------------------------------------\n",
    "                    # 현재 누적 수익률(S)이 양수(+)면 -> 가격을 내리고 싶음 -> 작은 해(r_minus) 선호\n",
    "                    # 현재 누적 수익률(S)이 음수(-)면 -> 가격을 올리고 싶음 -> 큰 해(r_plus) 선호\n",
    "\n",
    "                    # 1. 평균 회귀를 하려는 의도(Intention)가 발동할 확률 체크\n",
    "                    rand_p = torch.rand(current_batch_size, device=device)\n",
    "                    do_reversion = rand_p < reversion_prob  # e.g., 65% 확률로 회귀 선택\n",
    "\n",
    "                    # 2. S > 0 인 경우 (가격이 높음)\n",
    "                    #    - 회귀 O: r_minus 선택\n",
    "                    #    - 회귀 X: r_plus 선택 (모멘텀/발산)\n",
    "                    # 3. S <= 0 인 경우 (가격이 낮음)\n",
    "                    #    - 회귀 O: r_plus 선택\n",
    "                    #    - 회귀 X: r_minus 선택\n",
    "\n",
    "                    # 논리 연산으로 한 번에 처리:\n",
    "                    # (S > 0) XOR (do_reversion) == False 이면 r_plus, True 이면 r_minus\n",
    "                    # 쉽게 풀면:\n",
    "                    # Case A: S > 0 (High) AND Reversion -> Pick Minus (Down)\n",
    "                    # Case B: S < 0 (Low)  AND Reversion -> Pick Plus (Up)\n",
    "                    # 나머지는 반대\n",
    "\n",
    "                    mask_S_positive = S > 0\n",
    "\n",
    "                    # r_minus를 선택해야 하는 조건: (S>0 이면서 회귀) 또는 (S<=0 이면서 회귀 안 함-추세지속)\n",
    "                    # 하지만 통상적으로 \"회귀 확률\" 외에는 그냥 랜덤이 낫습니다.\n",
    "                    # 더 간단하고 강력한 로직:\n",
    "\n",
    "                    # 1) Base Choice: 50:50 Random\n",
    "                    base_choice_is_plus = torch.rand(current_batch_size, device=device) > 0.5\n",
    "\n",
    "                    # 2) Override with Reversion\n",
    "                    # S > 0 이면 -> r_minus 강제 할당 (override)\n",
    "                    # S < 0 이면 -> r_plus 강제 할당 (override)\n",
    "                    # 이 Override를 `reversion_prob` 만큼의 샘플에만 적용\n",
    "\n",
    "                    final_choice_is_plus = base_choice_is_plus.clone()\n",
    "\n",
    "                    # 회귀 적용할 마스크\n",
    "                    mask_apply_reversion = rand_p < reversion_prob\n",
    "\n",
    "                    # 회귀 적용 대상 중 S > 0 인 놈들은 False (r_minus) 로 강제\n",
    "                    final_choice_is_plus[mask_apply_reversion & mask_S_positive] = False\n",
    "\n",
    "                    # 회귀 적용 대상 중 S <= 0 인 놈들은 True (r_plus) 로 강제\n",
    "                    final_choice_is_plus[mask_apply_reversion & (~mask_S_positive)] = True\n",
    "\n",
    "                    # 최종 해 선택\n",
    "                    r_new = torch.where(final_choice_is_plus, r_plus, r_minus)\n",
    "\n",
    "                    # 업데이트\n",
    "                    batch_gen_returns[:, t] = r_new\n",
    "                    current_buffer = torch.cat([current_buffer[:, 1:], r_new.unsqueeze(1)], dim=1)\n",
    "\n",
    "                collected_returns.append(batch_gen_returns)\n",
    "                collected_rvs.append(pred_annual_rv)\n",
    "                total_generated += current_batch_size\n",
    "\n",
    "                #print(f\"\\rGenerating... {total_generated}/{n_samples}\", end=\"\")\n",
    "\n",
    "        #print(\"\\n[Done] Collection Complete.\")\n",
    "\n",
    "        final_returns = torch.cat(collected_returns, dim=0)\n",
    "        final_rvs = torch.cat(collected_rvs, dim=0)\n",
    "\n",
    "        return torch.stack([final_returns, final_rvs], dim=2), final_rvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSFp_nlEsEoM"
   },
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9CCFL4PXEiV"
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Loss Function 1: only price\n",
    "# ==========================================\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TimeVAELoss(nn.Module):\n",
    "    def __init__(self, beta=1.0, gamma=1.0):\n",
    "        \"\"\"\n",
    "        beta: KL Divergence 가중치 (정규분포화 강도)\n",
    "        gamma: Residual Penalty 가중치 (Trend/Seasonality 우선시 강도)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, recon_x, x, mu, logvar, residual):\n",
    "        \"\"\"\n",
    "        recon_x: 복원된 전체 데이터\n",
    "        x: 원본 데이터\n",
    "        mu, logvar: Latent 변수\n",
    "        residual: Decoder_Residual이 뱉은 값 (Batch, Seq, 1)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # 1. Reconstruction Loss (Main Task)\n",
    "        # \"원본과 똑같이 그려라\"\n",
    "        recon_loss = F.mse_loss(recon_x, x, reduction='sum') / batch_size\n",
    "\n",
    "        # 2. KL Divergence (Regularization 1)\n",
    "        # \"잠재 공간을 예쁘게 써라\"\n",
    "        kld_element = -0.5 * (1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        kld_loss = torch.sum(kld_element) / batch_size # (sum over dim, mean over batch)\n",
    "\n",
    "        # 3. Residual Sparsity Loss (Regularization 2) - [님의 아이디어!]\n",
    "        # \"Residual은 가능한 0에 가깝게 유지해라 (Trend/Season이 다 하게 해라)\"\n",
    "        # target이 0인 MSE와 같습니다.\n",
    "        resid_loss = F.mse_loss(residual, torch.zeros_like(residual), reduction='sum') / batch_size\n",
    "\n",
    "        # 4. Total Loss Combination\n",
    "        # Recon은 1로 고정, 나머지는 계수 부여\n",
    "        total_loss = recon_loss + (self.beta * kld_loss) + (self.gamma * resid_loss)\n",
    "\n",
    "        return {\n",
    "            \"total_loss\": total_loss,\n",
    "            \"recon_loss\": recon_loss,\n",
    "            \"kld_loss\": kld_loss,\n",
    "            \"resid_loss\": resid_loss\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4jaGYKa5Zyb"
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Loss Function 2: price & rv\n",
    "# ==========================================\n",
    "class TimeVAELossWithVol(nn.Module):\n",
    "    def __init__(self, beta=1.0, gamma=1.0, coef_vol = 10.0):\n",
    "        \"\"\"\n",
    "        beta: KL Divergence 가중치 (정규분포화 강도)\n",
    "        gamma: Residual Penalty 가중치 (Trend/Seasonality 우선시 강도)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.coef_vol = coef_vol\n",
    "\n",
    "\n",
    "    def forward(self,recon_x, x, mu, logvar, residual):\n",
    "        \"\"\"\n",
    "        recon_x: (Batch, Seq, 2) -> [:, :, 0]은 Return, [:, :, 1]은 RV\n",
    "        x:       (Batch, Seq, 2)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # 1. Return Loss (방향성)\n",
    "        # 얘는 그냥 \"말도 안 되는 값\"만 안 뱉게 느슨하게 관리 (가중치 0.1)\n",
    "        # 방향은 신의 영역이므로, 모델이 이걸 완벽히 맞추라고 강요하면 과적합됨.\n",
    "        loss_return = F.mse_loss(recon_x[:,:,0], x[:,:,0], reduction='sum')\n",
    "\n",
    "        # 2. Volatility Loss (변동성) - [여기에 집중!]\n",
    "        # 얘는 수학과 통계의 영역이므로 엄격하게 관리 (가중치 10.0)\n",
    "        # 딥헤징에서 리스크 계산 틀리면 망함.\n",
    "        loss_rv = F.mse_loss(recon_x[:,:,1], x[:,:,1], reduction='sum')\n",
    "\n",
    "        # [철학 반영 비율] Return : RV = 1 : n\n",
    "        recon_loss = (1.0 * loss_return + self.coef_vol * loss_rv) / batch_size\n",
    "\n",
    "        # 2. KL Divergence (Regularization 1)\n",
    "        # \"잠재 공간을 예쁘게 써라\"\n",
    "        kld_element = -0.5 * (1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        kld_loss = torch.sum(kld_element) / batch_size # (sum over dim, mean over batch)\n",
    "\n",
    "        # 3. Residual Sparsity Loss (Regularization 2) - [님의 아이디어!]\n",
    "        # \"Residual은 가능한 0에 가깝게 유지해라 (Trend/Season이 다 하게 해라)\"\n",
    "        # target이 0인 MSE와 같습니다.\n",
    "        resid_loss = F.mse_loss(residual, torch.zeros_like(residual), reduction='sum') / batch_size\n",
    "\n",
    "        # 4. Total Loss Combination\n",
    "        # Recon은 1로 고정, 나머지는 계수 부여\n",
    "        total_loss = recon_loss + (self.beta * kld_loss) + (self.gamma * resid_loss)\n",
    "\n",
    "        return {\n",
    "            \"total_loss\": total_loss,\n",
    "            \"recon_loss\": recon_loss,\n",
    "            \"kld_loss\": kld_loss,\n",
    "            \"resid_loss\": resid_loss\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrKxhUNALqR2"
   },
   "source": [
    "### Visualizing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPE5piTqOTlr"
   },
   "outputs": [],
   "source": [
    "#모델 성능 확인\n",
    "\n",
    "def plot_decomposition_dual(model, sample_tensor, scaler=None):\n",
    "    \"\"\"\n",
    "    sample_tensor: (1, Seq_Len, 2) -> [Returns, Volatility]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        sample_tensor = sample_tensor.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        # 모든 리턴값의 Shape은 (Batch, Seq, 2) 입니다.\n",
    "        recon, mu, logvar, trend, season, resid = model(sample_tensor)\n",
    "\n",
    "        # CPU로 가져오기 & Numpy 변환\n",
    "        # (Seq, 2) 형태로 변환\n",
    "        x_org = sample_tensor[0].cpu().numpy()\n",
    "        x_recon = recon[0].cpu().numpy()\n",
    "        x_trend = trend[0].cpu().numpy()\n",
    "        x_season = season[0].cpu().numpy()\n",
    "        x_resid = resid[0].cpu().numpy()\n",
    "\n",
    "    # ==========================================\n",
    "    # Plotting: 4행 2열 (Left: Returns, Right: Volatility)\n",
    "    # ==========================================\n",
    "    fig, axes = plt.subplots(4, 2, figsize=(16, 14), sharex=True)\n",
    "\n",
    "    features = ['Log Return', 'Realized Volatility']\n",
    "    colors = ['#1f77b4', '#ff7f0e'] # 파랑, 주황\n",
    "\n",
    "    for col in range(2): # 0: Return, 1: Volatility\n",
    "        feat_name = features[col]\n",
    "        c = colors[col]\n",
    "\n",
    "        # 1. Original vs Reconstruction\n",
    "        axes[0, col].plot(x_org[:, col], label='Original', color='black', alpha=0.3)\n",
    "        axes[0, col].plot(x_recon[:, col], label='Reconstruction', color='red', linestyle='--')\n",
    "        axes[0, col].set_title(f'[{feat_name}] Org vs Recon')\n",
    "        axes[0, col].legend(loc='upper right')\n",
    "        axes[0, col].grid(True, alpha=0.3)\n",
    "\n",
    "        # 2. Trend Component\n",
    "        axes[1, col].plot(x_trend[:, col], label='Trend (Poly)', color=c, linewidth=2)\n",
    "        axes[1, col].set_title(f'[{feat_name}] Trend')\n",
    "        axes[1, col].grid(True, alpha=0.3)\n",
    "\n",
    "        # 3. Seasonality Component\n",
    "        axes[2, col].plot(x_season[:, col], label='Seasonality (Fourier)', color='green')\n",
    "        axes[2, col].set_title(f'[{feat_name}] Seasonality')\n",
    "        axes[2, col].grid(True, alpha=0.3)\n",
    "\n",
    "        # 4. Residual Component\n",
    "        axes[3, col].plot(x_resid[:, col], label='Residual (LSTM)', color='purple')\n",
    "        axes[3, col].set_title(f'[{feat_name}] Residual')\n",
    "        axes[3, col].axhline(0, color='black', linestyle='--', linewidth=0.8)\n",
    "        axes[3, col].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OavA0VObNVrS"
   },
   "outputs": [],
   "source": [
    "# simulation paths\n",
    "\n",
    "def analyze_and_plot_simulation(gen_returns, gen_rv, S0, title_prefix=\"Simulation\", figsize=(24, 18)):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gen_returns (np.array): (N_samples, N_steps) - 로그 수익률\n",
    "        gen_rv (np.array): (N_samples, N_steps) - 연율화된 변동성 (Regime/Target)\n",
    "        S0 (float): 초기 주가\n",
    "        title_prefix (str): 그래프 제목 접두사\n",
    "    \"\"\"\n",
    "\n",
    "    N_SAMPLES, N_STEPS = gen_returns.shape\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 1. Data Preparation\n",
    "    # -------------------------------------------------------\n",
    "    # Price Paths 변환: P_t = S0 * exp(cumsum(r))\n",
    "    gen_prices = S0 * np.exp(np.cumsum(gen_returns, axis=1))\n",
    "\n",
    "    # t=0 시점(S0) 추가 (그래프용)\n",
    "    start_points = np.full((N_SAMPLES, 1), S0)\n",
    "    gen_prices_concat = np.hstack([start_points, gen_prices])\n",
    "\n",
    "    # Terminal Returns\n",
    "    final_returns = np.sum(gen_returns, axis=1)\n",
    "\n",
    "    # Average Volatility per path\n",
    "    avg_vols = np.mean(gen_rv, axis=1)\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 2. Visualization\n",
    "    # -------------------------------------------------------\n",
    "    fig, axes = plt.subplots(3, 2, figsize=figsize)\n",
    "\n",
    "    # [A] Price Paths (0, 0)\n",
    "    # 100개만 샘플링하여 그림\n",
    "    plot_n = min(100, N_SAMPLES)\n",
    "    axes[0, 0].plot(gen_prices_concat[:plot_n].T, color='grey', alpha=0.3, linewidth=0.5)\n",
    "    axes[0, 0].plot(np.median(gen_prices_concat, axis=0), color='red', linewidth=2, label='Median Path')\n",
    "    axes[0, 0].plot(np.percentile(gen_prices_concat, 95, axis=0), color='blue', linestyle='--', label='95% Quantile')\n",
    "    axes[0, 0].plot(np.percentile(gen_prices_concat, 5, axis=0), color='blue', linestyle='--', label='5% Quantile')\n",
    "    axes[0, 0].set_title(f'[{title_prefix}] Price Paths (N={N_SAMPLES})')\n",
    "    axes[0, 0].set_ylabel('Price')\n",
    "    axes[0, 0].legend(loc='upper left')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # [B] Volatility Analysis (Sample 0, 1, 2) -> (0,1), (1,0), (1,1)\n",
    "    # 위치 매핑: i=0 -> (0,1) / i=1 -> (1,0) / i=2 -> (1,1)\n",
    "    sample_indices = [0, 1, 2]\n",
    "\n",
    "    for i, sample_idx in enumerate(sample_indices):\n",
    "        if i == 0:\n",
    "            ax = axes[0, 1]\n",
    "        elif i == 1:\n",
    "            ax = axes[1, 0]\n",
    "        else:\n",
    "            ax = axes[1, 1]\n",
    "\n",
    "        # 데이터 추출\n",
    "        target_rv = gen_rv[sample_idx]\n",
    "        realized_proxy = np.abs(gen_returns[sample_idx]) * np.sqrt(252)\n",
    "\n",
    "        ax.plot(target_rv, color='orange', linewidth=2, label='Predicted RV (Regime)')\n",
    "        ax.plot(realized_proxy, color='purple', alpha=0.5, label='|Return| (Ann.)')\n",
    "        ax.set_title(f'Sample {sample_idx}: Regime vs Realized')\n",
    "        ax.set_ylabel('Annualized Vol')\n",
    "        ax.legend(loc='upper right')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # [C] Terminal Return Distribution (2, 0)\n",
    "    axes[2, 0].hist(final_returns, bins=100, density=True, color='#1f77b4', alpha=0.7, label='Generated')\n",
    "\n",
    "    # Normal Fit\n",
    "    mu, std = norm.fit(final_returns)\n",
    "    xmin, xmax = axes[2, 0].get_xlim()\n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    p = norm.pdf(x, mu, std)\n",
    "    axes[2, 0].plot(x, p, 'k', linewidth=2, label=f'Normal Fit\\n(std={std:.4f})')\n",
    "\n",
    "    axes[2, 0].set_title(f'[{title_prefix}] Terminal Log Return Dist')\n",
    "    axes[2, 0].legend()\n",
    "    axes[2, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # [D] Volatility Regime Distribution (2, 1)\n",
    "    axes[2, 1].hist(avg_vols, bins=50, color='orange', alpha=0.7, edgecolor='black')\n",
    "    axes[2, 1].set_title(f'[{title_prefix}] Avg Volatility Distribution')\n",
    "    axes[2, 1].set_xlabel('Average Annualized Volatility')\n",
    "    axes[2, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 3. Statistics Summary\n",
    "    # -------------------------------------------------------\n",
    "    final_prices = gen_prices[:, -1]\n",
    "\n",
    "    print(f\"\\n[{title_prefix}] Simulation Statistics\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"S0 (Start Price)    : {S0:.2f}\")\n",
    "    print(f\"Final Price (Mean)  : {np.mean(final_prices):.2f}\")\n",
    "    print(f\"Final Price (Std)   : {np.std(final_prices):.2f}\")\n",
    "    print(f\"Final Price (Max)   : {np.max(final_prices):.2f}\")\n",
    "    print(f\"Final Price (Min)   : {np.min(final_prices):.2f}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Return Skewness     : {pd.Series(final_returns).skew():.4f} (Target: ~0 or Neg)\")\n",
    "    print(f\"Return Kurtosis     : {pd.Series(final_returns).kurtosis():.4f} (Target: >0, Fat Tail)\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5DZOfOS3RFRG"
   },
   "outputs": [],
   "source": [
    "# actual data ln returns & rv\n",
    "\n",
    "def plot_returns_and_rv(df, N=60, window=20):\n",
    "    \"\"\"\n",
    "    df: 일일 주가 데이터 (Series or DataFrame with single column)\n",
    "    N: 시퀀스 길이 (default=60)\n",
    "    \"\"\"\n",
    "    # 1. 데이터 전처리\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        price = df.iloc[:, 0]\n",
    "    else:\n",
    "        price = df\n",
    "\n",
    "    # (1) 일일 로그 수익률 계산\n",
    "    log_ret_daily = np.log(price / price.shift(1))\n",
    "\n",
    "    # (2) 수익률 연율화 (Daily Log Return * 252)\n",
    "    # 의미: \"오늘의 수익률이 1년(252일) 동안 매일 계속된다면?\" (Drift)\n",
    "    log_ret_annual = log_ret_daily * np.sqrt(252)\n",
    "\n",
    "    # (3) RV 연율화 (20-day std * sqrt(252))\n",
    "    rv_annual = log_ret_daily.rolling(window=window).std() * np.sqrt(252)\n",
    "\n",
    "    # 데이터 합치기\n",
    "    data = pd.concat([log_ret_annual, rv_annual], axis=1).dropna()\n",
    "    data.columns = ['Annualized Return', 'Annualized RV']\n",
    "\n",
    "    total_len = len(data)\n",
    "    if total_len < N:\n",
    "        print(f\"Error: 데이터 길이가 N={N}보다 짧습니다.\")\n",
    "        return\n",
    "\n",
    "    # 2. 샘플링 인덱스 선정 (4개)\n",
    "    # [0]: 무조건 마지막 N일\n",
    "    sample_indices = []\n",
    "    last_idx = total_len - N\n",
    "    sample_indices.append(last_idx)\n",
    "\n",
    "    # [1~3]: 랜덤 구간\n",
    "    for _ in range(3):\n",
    "        rand_idx = np.random.randint(0, last_idx)\n",
    "        sample_indices.append(rand_idx)\n",
    "\n",
    "    # 3. 시각화 (2x2 Grid)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10)) # 가로 사이즈 조금 더 키움\n",
    "    fig.suptitle(f'Annualized Return (x252) & Annualized RV (Duration = {N} / Window = {window})', fontsize=16)\n",
    "\n",
    "    titles = ['Most Recent (Last N Days)', 'Random Sample 1', 'Random Sample 2', 'Random Sample 3']\n",
    "    period = np.arange(0,N)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        start_idx = sample_indices[i]\n",
    "        end_idx = start_idx + N\n",
    "\n",
    "        subset = data.iloc[start_idx : end_idx]\n",
    "        dates = subset.index\n",
    "\n",
    "\n",
    "        # [축 1] 연율화된 수익률 (Left Axis)\n",
    "        color_ret = 'tab:blue'\n",
    "        ax.set_xlabel('Date')\n",
    "        # 라벨 변경: Annualized Return\n",
    "        ax.set_ylabel('Annualized Return (x252)', color=color_ret, fontweight='bold')\n",
    "\n",
    "        # 수익률은 0을 기준으로 위아래로 튀므로 0선(Zero line)을 하나 그어주면 보기 편함\n",
    "        ax.axhline(0, color='black', linewidth=0.5, linestyle='--')\n",
    "\n",
    "        ax.plot(period, subset['Annualized Return'], color=color_ret, alpha=0.5, label='Ann. Return', linewidth=1)\n",
    "        ax.tick_params(axis='y', labelcolor=color_ret)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # [축 2] 연율화된 RV (Right Axis)\n",
    "        ax2 = ax.twinx()\n",
    "        color_rv = 'tab:orange'\n",
    "        ax2.set_ylabel('Annualized RV (20d)', color=color_rv, fontweight='bold')\n",
    "        ax2.plot(period, subset['Annualized RV'], color=color_rv, linewidth=2, label='RV(20)', linestyle='-')\n",
    "        ax2.tick_params(axis='y', labelcolor=color_rv)\n",
    "\n",
    "        # 타이틀 (날짜 포함)\n",
    "        date_str = f\"{dates[0].strftime('%Y-%m-%d')} ~ {dates[-1].strftime('%Y-%m-%d')}\"\n",
    "        ax.set_title(f\"[{titles[i]}]\\n{date_str}\", fontsize=11)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Te_xWspwVFCu"
   },
   "outputs": [],
   "source": [
    "# simulaion_rv_paths\n",
    "def plot_random_rv_samples(rv_paths, n=10, figsize=(12, 6)):\n",
    "    \"\"\"\n",
    "    RV 경로들 중에서 n개를 무작위로 추출하여 시각화합니다.\n",
    "\n",
    "    Args:\n",
    "        rv_paths (Tensor or np.array): (N_samples, N_steps) 형태의 RV 데이터\n",
    "        n (int): 시각화할 샘플 개수\n",
    "        figsize (tuple): 그래프 크기\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. 데이터 타입 변환 (Tensor -> Numpy)\n",
    "    if hasattr(rv_paths, 'cpu'):\n",
    "        data = rv_paths.detach().cpu().numpy()\n",
    "    else:\n",
    "        data = np.array(rv_paths)\n",
    "\n",
    "    total_samples, n_steps = data.shape\n",
    "\n",
    "    # 샘플 개수가 전체 데이터보다 많으면 전체를 그림\n",
    "    if n > total_samples:\n",
    "        n = total_samples\n",
    "\n",
    "    # 2. 랜덤 인덱스 추출\n",
    "    random_indices = np.random.choice(total_samples, n, replace=False)\n",
    "\n",
    "    # 3. 플롯 그리기\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    # 개별 경로 그리기\n",
    "    # colors = plt.cm.viridis(np.linspace(0, 1, n)) # 색상 다양하게\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        plt.plot(data[idx], alpha=0.7, linewidth=1.5, label=f'Sample {idx}')\n",
    "\n",
    "    # 전체 평균선 그리기 (참고용)\n",
    "    mean_path = np.mean(data, axis=0)\n",
    "    plt.plot(mean_path, color='black', linewidth=3, linestyle='--', label='Population Mean')\n",
    "\n",
    "    # 스타일링\n",
    "    plt.title(f'Random Sampled Volatility Paths (n={n})', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Days', fontsize=12)\n",
    "    plt.ylabel('Annualized Volatility', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # 범례는 너무 많으면 가리니까 적당할 때만 표시\n",
    "    if n <= 15:\n",
    "        plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 사용 예시\n",
    "# plot_random_rv_samples(gen_smooth_rv_org, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WriAH7SDld33"
   },
   "source": [
    "## Time-VAE Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aSPOcteT8HFW"
   },
   "outputs": [],
   "source": [
    "X_train_tensor, X_test_tensor, scaler = prepare_data_for_Time_VAE(df,N,window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-Xds46X8U9D"
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Processing the Data\n",
    "# ==========================================\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time\n",
    "\n",
    "# 1. Hyperparameters\n",
    "BATCH_SIZE_F0R_VAE = 64\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 1200\n",
    "Z_DIM1 = 3  # Trend\n",
    "Z_DIM2 = 3  # Seasonality\n",
    "Z_DIM3 = 4  # Residual\n",
    "LATENT_DIM = Z_DIM1 + Z_DIM2 + Z_DIM3\n",
    "NUMBER_FEATURES = 2\n",
    "TREND_DEGREE = 5\n",
    "N_HARMONICS = 5\n",
    "\n",
    "# Beta (KLD 가중치) & Gamma (Residual Penalty 가중치)\n",
    "# Beta가 너무 크면 복원을 포기하므로 작게 시작하는 게 팁 (0.001 ~ 0.01)\n",
    "MAX_BETA = 0.4\n",
    "MAX_GAMMA = 2\n",
    "\n",
    "STANDARD_BETA_EPOCH= 300\n",
    "COEF_VOL = 100.0\n",
    "\n",
    "# 2. DataLoader 생성\n",
    "# TensorDataset으로 감싸야 DataLoader에 넣을 수 있습니다.\n",
    "train_dataset = TensorDataset(X_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_F0R_VAE, shuffle=True)\n",
    "\n",
    "print(f\"Dataset Ready: {len(train_loader)} batches per epoch.\")\n",
    "\n",
    "# 3. Device Setup (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USCy21ClGJKV"
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Initialize Model & Loss\n",
    "# ==========================================\n",
    "model_vae = TimeVAE(\n",
    "    z_dim1=Z_DIM1,\n",
    "    z_dim2=Z_DIM2,\n",
    "    z_dim3=Z_DIM3,\n",
    "    latent_dim=LATENT_DIM,\n",
    "    seq_len=N,\n",
    "    output_dim=NUMBER_FEATURES,\n",
    "    trend_degree=TREND_DEGREE,\n",
    "    n_harmonics=N_HARMONICS\n",
    ").to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model_vae.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=30)\n",
    "\n",
    "# Loss History (나중에 그래프 그리려고 저장)\n",
    "history = {'total': [], 'recon': [], 'kld': [], 'resid': []}\n",
    "\n",
    "# ==========================================\n",
    "# Training Loop\n",
    "# ==========================================\n",
    "print(\"\\n[Start Training]\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model_vae.train() # 학습 모드 전환\n",
    "    epoch_loss = 0\n",
    "    epoch_recon = 0\n",
    "    epoch_kld = 0\n",
    "    epoch_resid = 0\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    if epoch <= STANDARD_BETA_EPOCH:\n",
    "        BETA = (epoch / STANDARD_BETA_EPOCH) * MAX_BETA\n",
    "        GAMMA = (epoch / STANDARD_BETA_EPOCH) * MAX_GAMMA\n",
    "    else:\n",
    "        BETA = MAX_BETA\n",
    "        GAMMA = MAX_GAMMA\n",
    "\n",
    "\n",
    "\n",
    "    calculating_loss = TimeVAELossWithVol(beta=BETA, gamma=GAMMA, coef_vol=COEF_VOL)\n",
    "\n",
    "\n",
    "    for batch in train_loader:\n",
    "        # 1. Data Loading\n",
    "        # batch는 리스트로 나오므로 [0]으로 텐서를 꺼냄\n",
    "        x_batch = batch[0].to(device)\n",
    "\n",
    "        # 2. Forward Pass\n",
    "        # 반환값: recon_x, mu, logvar, trend, seasonality, residual\n",
    "        recon_x, mu, logvar, trend, season, resid = model_vae(x_batch)\n",
    "\n",
    "        # 3. Loss Calculation\n",
    "        # calculating_loss 반환값은 딕셔너리 형태\n",
    "        loss_dict = calculating_loss(recon_x, x_batch, mu, logvar, resid)\n",
    "\n",
    "        total_loss = loss_dict['total_loss']\n",
    "\n",
    "        # 4. Backward & Update\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 5. Logging\n",
    "        epoch_loss += total_loss.item()\n",
    "        epoch_recon += loss_dict['recon_loss'].item()\n",
    "        epoch_kld += loss_dict['kld_loss'].item()\n",
    "        epoch_resid += loss_dict['resid_loss'].item()\n",
    "\n",
    "    # 평균 Loss 계산\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    avg_recon = epoch_recon / len(train_loader)\n",
    "    avg_kld = epoch_kld / len(train_loader)\n",
    "    avg_resid = epoch_resid / len(train_loader)\n",
    "\n",
    "    # 기록 저장\n",
    "    history['total'].append(avg_loss)\n",
    "    history['recon'].append(avg_recon)\n",
    "    history['kld'].append(avg_kld)\n",
    "    history['resid'].append(avg_resid)\n",
    "\n",
    "    if epoch > STANDARD_BETA_EPOCH:\n",
    "        scheduler.step(avg_loss)\n",
    "\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    if new_lr < current_lr:\n",
    "        print(f\"--- When Epoch {epoch} is over, Learning Rate is Reduced: {current_lr:.6f} -> {new_lr:.6f} ---\")\n",
    "        if new_lr <= 0.00005:\n",
    "          print(f'Stop Learning. (Final Epoch = {epoch})')\n",
    "          print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] \"\n",
    "                f\"Total: {avg_loss:.4f} | \"\n",
    "                f\"Recon: {avg_recon:.4f} | \"\n",
    "                f\"KLD: {avg_kld:.4f} | \"\n",
    "                f\"ResidPenalty: {avg_resid:.4f}\")\n",
    "          break\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] \"\n",
    "              f\"Total: {avg_loss:.4f} | \"\n",
    "              f\"Recon: {avg_recon:.4f} | \"\n",
    "              f\"KLD: {avg_kld:.4f} | \"\n",
    "              f\"ResidPenalty: {avg_resid:.4f}\")\n",
    "\n",
    "print(f\"Training Finished in {time.time() - start_time:.2f} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7DurTD_pVpp"
   },
   "source": [
    "### Saving the Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zZOFGP9F48Vq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from google.colab import files # 코랩 브라우저로 바로 다운로드할 때 필요\n",
    "\n",
    "# 1. 모델의 가중치(State Dict)를 파일로 저장\n",
    "save_time_vae = 'time_vae_best_weights.pth'\n",
    "torch.save(model_vae.state_dict(), save_time_vae)\n",
    "print(f\"가중치가 {save_time_vae}에 저장되었습니다.\")\n",
    "\n",
    "# 2. 내 컴퓨터(로컬)로 파일 다운로드\n",
    "files.download(save_time_vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qlLZfC9w4_D1"
   },
   "outputs": [],
   "source": [
    "# 1. 수정된 클래스로 '새 빈 껍데기' 인스턴스 생성\n",
    "# (init 인자값들은 기존 학습 때와 100% 동일해야 함)\n",
    "model_vae = TimeVAE(\n",
    "    z_dim1=Z_DIM1,\n",
    "    z_dim2=Z_DIM2,\n",
    "    z_dim3=Z_DIM3,\n",
    "    latent_dim=LATENT_DIM,\n",
    "    seq_len=N,\n",
    "    output_dim=NUMBER_FEATURES\n",
    ").to(device)\n",
    "\n",
    "# 2. 저장해둔 가중치 파일 불러오기\n",
    "# 로컬에 다운받았던 파일을 다시 코랩 왼쪽 '파일' 탭에 드래그해서 업로드한 후 실행\n",
    "load_path = 'time_vae_best_weights.pth'\n",
    "model_vae.load_state_dict(torch.load(load_path, map_location=device))\n",
    "\n",
    "# 3. 모델을 GPU로 보내고 추론 모드로 설정\n",
    "model_vae.to(device)\n",
    "model_vae.eval()\n",
    "\n",
    "print(\"수정된 클래스에 기존 가중치 로드가 완료되었습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Q4zn__lsTA5"
   },
   "source": [
    "### Generating Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gYFVc7Z0gWDl"
   },
   "outputs": [],
   "source": [
    "# Checking the model's learning outcomes\n",
    "\n",
    "print(\"\\n[Visualizing Dual Features: Return & Volatility]\")\n",
    "# 학습 데이터 중 첫 번째 샘플 확인\n",
    "plot_decomposition_dual(model_vae, X_train_tensor[1320:1321], scaler)\n",
    "\n",
    "# 테스트 데이터 확인 (모델이 본 적 없는 데이터)\n",
    "print(\"\\n\"*10)\n",
    "print(\"[Visualizing Test Sample]\")\n",
    "plot_decomposition_dual(model_vae, X_test_tensor[0:1], scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSQTeoHLN2kC"
   },
   "outputs": [],
   "source": [
    "N_SAMPLES = 20000\n",
    "N_STEPS = 30\n",
    "N_WINDOW = 20\n",
    "COEF_RESID= 1.0\n",
    "NOISE_LEVEL = 0.0\n",
    "Z_COEF =1.0\n",
    "REVERSION_PROB = 0.7\n",
    "BATCH_SIZE = 20000\n",
    "S0 = df.iloc[-(N+1)].item()\n",
    "historical_data_np = np.log(df/df.shift(1)).dropna()[:-N].values.flatten()\n",
    "\n",
    "\n",
    "vol_of_vol=0.2  # 설정하신 값\n",
    "df_t=4.0\n",
    "coef_resid = 1\n",
    "ln_mu = X_train_tensor[:,:,0].mean(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BRonmRW-N5CH"
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Simulation Generation: 1. With ND/T-dist\n",
    "# ==========================================\n",
    "\n",
    "print(f\"\\n[Simulation] Generating {N_SAMPLES} synthetic scenarios...\")\n",
    "\n",
    "gen_data_org, gen_z_org = model_vae.generate_synthetic_data(\n",
    "    n_samples=N_SAMPLES,\n",
    "    device=device,\n",
    "    vol_of_vol=vol_of_vol,  # 설정하신 값\n",
    "    df_t=df_t,          # t-분포 자유도\n",
    "    coef_resid=coef_resid,\n",
    "    ln_mu = ln_mu\n",
    ")\n",
    "\n",
    "# CPU로 이동 및 Numpy 변환\n",
    "gen_data_np_org = gen_data_org.cpu().numpy()\n",
    "gen_returns_org = gen_data_np_org[:, :, 0]   # (20000, 60)\n",
    "gen_smooth_rv_org = gen_data_np_org[:, :, 1] # (20000, 60)\n",
    "\n",
    "# 함수 호출\n",
    "analyze_and_plot_simulation(\n",
    "    gen_returns=gen_returns_org,\n",
    "    gen_rv=gen_smooth_rv_org,\n",
    "    S0=S0.item() if hasattr(S0, 'item') else S0, # S0가 텐서나 Series일 경우 처리\n",
    "    title_prefix=\"Vanilla VAE\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WuAOufikm95x"
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Simulation_generation: 2. physically_consistent_paths_wo_clamping\n",
    "# ==========================================\n",
    "print(f\"\\n[Simulation] Generating {N_SAMPLES} Physically Consistent Scenarios...\")\n",
    "\n",
    "# 모델 호출\n",
    "\n",
    "gen_data_wo_clamping, gen_rv_wo_clamping = model_vae.generate_physically_consistent_paths(\n",
    "    historical_returns=historical_data_np,\n",
    "    n_samples=N_SAMPLES,\n",
    "    n_steps=N_STEPS,\n",
    "    N_window=N_WINDOW,\n",
    "    device=device,\n",
    "    coef_resid=COEF_RESID,\n",
    "    noise_level=NOISE_LEVEL,\n",
    "    z_coef=Z_COEF,\n",
    "    reversion_prob=REVERSION_PROB,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "gen_data_np_wo_clamping = gen_data_wo_clamping.cpu().numpy()\n",
    "gen_returns_wo_clamping = gen_data_np_wo_clamping[:, :, 0]\n",
    "gen_smooth_rv_wo_clamping = gen_data_np_wo_clamping[:, :, 1]\n",
    "\n",
    "# 함수 호출\n",
    "analyze_and_plot_simulation(\n",
    "    gen_returns=gen_returns_wo_clamping,\n",
    "    gen_rv=gen_smooth_rv_wo_clamping,\n",
    "    S0=S0.item() if hasattr(S0, 'item') else S0,\n",
    "    title_prefix=\"Physically Consistent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rvjLx0rNt2x"
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Simulation_generation: 3. physically_consistent_paths_with_clamping\n",
    "# ==========================================\n",
    "gen_data_with_clamping, gen_rv_with_clamping = model_vae.generate_physically_consistent_paths_with_clamping(\n",
    "    historical_returns=historical_data_np,\n",
    "    n_samples=N_SAMPLES,\n",
    "    n_steps=N_STEPS,\n",
    "    N_window=N_WINDOW,\n",
    "    device=device,\n",
    "    coef_resid=COEF_RESID,\n",
    "    noise_level=NOISE_LEVEL,\n",
    "    z_coef=Z_COEF,\n",
    "    reversion_prob=REVERSION_PROB,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "\n",
    "gen_data_np_with_clamping = gen_data_with_clamping.cpu().numpy()\n",
    "gen_returns_with_clamping = gen_data_np_with_clamping[:, :, 0]\n",
    "gen_smooth_rv_with_clamping = gen_data_np_with_clamping[:, :, 1]\n",
    "\n",
    "# 함수 호출\n",
    "analyze_and_plot_simulation(\n",
    "    gen_returns=gen_returns_with_clamping,\n",
    "    gen_rv=gen_smooth_rv_with_clamping,\n",
    "    S0=S0.item() if hasattr(S0, 'item') else S0,\n",
    "    title_prefix=\"Physically Consistent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vLYydHcO0veD"
   },
   "outputs": [],
   "source": [
    "plot_returns_and_rv(df, N=30, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36V3apE8Mu2J"
   },
   "outputs": [],
   "source": [
    "plot_random_rv_samples(gen_smooth_rv_org, n=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-IonOE0MvPD"
   },
   "outputs": [],
   "source": [
    "plot_random_rv_samples(gen_smooth_rv_wo_clamping, n=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzBmKfoWMveX"
   },
   "outputs": [],
   "source": [
    "plot_random_rv_samples(gen_smooth_rv_with_clamping, n=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r5iJJ5bPXXER"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9514kf7rZ90"
   },
   "source": [
    "## Agent Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PFT1p276iHW"
   },
   "source": [
    "### Viewing rv as daily vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uz05tBq76iHX"
   },
   "outputs": [],
   "source": [
    "params, v_t = garch_heston_analysis(df_train)\n",
    "print(f'\\nEstimated Hyperparameters of Heston: {params}\\n')\n",
    "# 디바이스 설정 (GPU 권장)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "mean = torch.tensor(params['mu_simple'])\n",
    "kappa = torch.tensor(params['kappa'])\n",
    "theta = torch.tensor(params['theta'])\n",
    "xi = torch.tensor(params['xi'])\n",
    "rho = torch.tensor(params['rho'])\n",
    "V_0 = torch.tensor(params['v0'])\n",
    "sig_0 = torch.sqrt(V_0)\n",
    "S_0 = torch.tensor(df_train[-1])\n",
    "K = torch.tensor(df_train[-1])   # ATM 옵션\n",
    "number_opt = NUMBER_OPT\n",
    "rv_window = RV_WINDOW\n",
    "initial_cf = bscall(S_0, K, T, mean, sig_0)\n",
    "\n",
    "\n",
    "# --- 모델 초기화 (Transformer) ---\n",
    "# input_dim=3 (LogMoneyness, VarSwapPrice, RollingRV)\n",
    "model_transformer_rv_is_daily = DeepHedgingModelTransformerViz(input_dim=3, d_model=64, nhead=4, output_dim=2, max_len=N+10).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model_transformer_rv_is_daily .parameters(), lr=0.005)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "# [3] Training Loop\n",
    "print(\"\\n\\nTraining Start with Transformer...\")\n",
    "\n",
    "COST_BPS_STOCK = 10.0\n",
    "COST_BPS_VAR   = 30.0\n",
    "\n",
    "epochs = 51\n",
    "attention_maps_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 1. 데이터 생성\n",
    "    gen_data_org, gen_rv_org = model_vae.generate_synthetic_data(\n",
    "    n_samples=N_SAMPLES,\n",
    "    device=device,\n",
    "    vol_of_vol=vol_of_vol,  # 설정하신 값\n",
    "    df_t=df_t,          # t-분포 자유도\n",
    "    coef_resid=coef_resid,\n",
    "    ln_mu = ln_mu\n",
    ")\n",
    "    gen_returns = gen_data_org[:,:,0:1]\n",
    "    prices = torch.exp(torch.cumsum(gen_returns, dim=1)) * S_0\n",
    "    prices = torch.cat((S_0.unsqueeze(0).expand(prices.size(0),1).to(device),prices.squeeze(-1)),dim=1).unsqueeze(2).to(device)\n",
    "    variances = gen_data_org[:,:,1:2]\n",
    "    variances = torch.cat((V_0.unsqueeze(0).expand(variances.size(0),1).to(device),variances.squeeze(-1)),dim=1).unsqueeze(2).to(device)\n",
    "\n",
    "    S_T = prices[:, -1, 0]\n",
    "\n",
    "    # Past Prices 처리\n",
    "    past_prices = (torch.tensor(df_train.iloc[-rv_window-1:-1].values).float() * torch.ones(M, rv_window)).to(device)\n",
    "    prices_expanded = torch.cat([past_prices, prices.squeeze(-1)], dim=1)\n",
    "    rolling_rvs = rolling_rv(prices_expanded, window=rv_window)\n",
    "\n",
    "    # 2. Variance Swap Inputs\n",
    "    K_var, var_swap_prices = generate_var_swap_prices_heston(T, dt, prices[:, :, 0], variances[:, :, 0], kappa, theta, r, device)\n",
    "\n",
    "    # 3. Inputs 구성 (Batch, Steps+1, 3)\n",
    "    log_moneyness = torch.log(prices / K)\n",
    "    inputs = torch.cat([log_moneyness, var_swap_prices, rolling_rvs], dim=2).float()\n",
    "    inputs = inputs[:, :-1, :] # (Batch, Steps, 3) Action은 T-1까지만 필요\n",
    "\n",
    "    # 배치 루프 변수 초기화\n",
    "    epoch_loss = 0.0\n",
    "    epoch_loss_mse = 0.0\n",
    "    epoch_loss_entropy = 0.0\n",
    "    epoch_final_pnl = 0.0\n",
    "    num_iters = 0\n",
    "\n",
    "    for i in range(0, M, BATCH_SIZE_HESTON):\n",
    "        if (i + 2 * BATCH_SIZE_HESTON) > M:\n",
    "            batch_inputs = inputs[i:, :, :]\n",
    "            batch_prices = prices[i:, :, :]\n",
    "            batch_var = variances[i:, :, 0]\n",
    "            batch_varswaps = var_swap_prices[i:, :, :]\n",
    "            batch_K_var = K_var[i:]\n",
    "            option_payoff = torch.relu(S_T - K)[i:]\n",
    "            is_last_batch = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            batch_inputs = inputs[i : i + BATCH_SIZE_HESTON, :, :]\n",
    "            batch_prices = prices[i : i + BATCH_SIZE_HESTON, :, :]\n",
    "            batch_varswaps = var_swap_prices[i : i + BATCH_SIZE_HESTON, :, :]\n",
    "            batch_K_var = K_var[i : i + BATCH_SIZE_HESTON]\n",
    "            option_payoff = torch.relu(S_T - K)[i : i + BATCH_SIZE_HESTON]\n",
    "            is_last_batch = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # --- [변경] 모델 호출 (Unpacking attention_maps) ---\n",
    "        deltas, var_swap_ns, attn_map_matrix = model_transformer_rv_is_daily(batch_inputs, T=T)\n",
    "\n",
    "        # 마지막 배치의 Attention Map 저장 (시각화용)\n",
    "        if is_last_batch:\n",
    "            revised_attention_mtx = torch.zeros((N,N), device=device)\n",
    "            for i in range(N):\n",
    "              revised_attention_mtx[i,:i+1] = attn_map_matrix[i][0]\n",
    "\n",
    "            attention_maps_history.append(revised_attention_mtx)\n",
    "\n",
    "        deltas = deltas.squeeze(-1)\n",
    "        var_swap_ns = var_swap_ns.squeeze(-1)\n",
    "\n",
    "        # ... (이하 비용 계산 로직은 기존과 100% 동일) ...\n",
    "        price_changes_stock = batch_prices[:, 1:, 0] - batch_prices[:, :-1, 0]\n",
    "        price_changes_var = batch_varswaps[:, 1:, 0] - batch_varswaps[:, :-1, 0]\n",
    "\n",
    "        prev_deltas = torch.cat([torch.zeros(deltas.size(0), 1).to(device), deltas[:, :-1]], dim=1)\n",
    "        delta_changes = torch.abs(deltas - prev_deltas)\n",
    "        cost_stock = torch.sum(delta_changes * batch_prices[:, :-1, 0] * (COST_BPS_STOCK / 10000), dim=1)\n",
    "\n",
    "        prev_ns = torch.cat([torch.zeros(var_swap_ns.size(0), 1).to(device), var_swap_ns[:, :-1]], dim=1)\n",
    "        n_changes = torch.abs(var_swap_ns - prev_ns)\n",
    "        k_var_expanded = batch_K_var.unsqueeze(1)\n",
    "        cost_var = torch.sum(n_changes * k_var_expanded * (COST_BPS_VAR / 10000), dim=1)\n",
    "\n",
    "        gain_stock = torch.sum(deltas * price_changes_stock, dim=1)\n",
    "        gain_var = torch.sum(var_swap_ns * price_changes_var, dim=1)\n",
    "        hedging_pnl = (gain_stock + gain_var) - (cost_stock + cost_var)\n",
    "\n",
    "        total_pnl = hedging_pnl - option_payoff\n",
    "        final_pnl = number_opt * (total_pnl + initial_cf)\n",
    "\n",
    "        loss = cvar_loss(total_pnl)\n",
    "        loss_mse = mean_loss(total_pnl)\n",
    "        loss_entropy = entropic_loss(total_pnl, risk_aversion = 0.7)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        torch.nn.utils.clip_grad_norm_(model_transformer_rv_is_daily.parameters(), max_norm=1.0)\n",
    "        loss_entropy.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_loss_mse += loss_mse.item()\n",
    "        epoch_loss_entropy += loss_entropy.item()\n",
    "        epoch_final_pnl += final_pnl.mean().item()\n",
    "        num_iters += 1\n",
    "\n",
    "        if is_last_batch: break\n",
    "\n",
    "    # 에포크 마지막 부분\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    avg_entropy = epoch_loss_entropy / num_iters\n",
    "\n",
    "    # 스케줄러 업데이트\n",
    "    scheduler.step(avg_entropy)\n",
    "\n",
    "\n",
    "    # 학습률이 변했는지 체크해서 알려주는 로직 (수동 verbose)\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    if new_lr < current_lr:\n",
    "        print(f\"--- When Epoch {epoch} is over, Learning Rate Reduced: {current_lr:.6f} -> {new_lr:.6f} ---\")\n",
    "        if new_lr <= 0.0001:\n",
    "          print(f'Stop Learning. (Final Epoch = {epoch})')\n",
    "          print(f\"Epoch {epoch} | CVaR: {avg_loss:.4f} | Entropic Loss: {avg_entropy:.4f} | PnL: {avg_pnl:.4f}\")\n",
    "          break\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "       avg_loss = epoch_loss / num_iters\n",
    "       avg_pnl = epoch_final_pnl / num_iters\n",
    "       avg_entropy = epoch_loss_entropy / num_iters\n",
    "\n",
    "\n",
    "       print(f\"Epoch {epoch} | CVaR: {avg_loss:.4f} | Entropic Loss: {avg_entropy:.4f} | PnL: {avg_pnl:.4f}\")\n",
    "\n",
    "print(f\"Training Finished.\")\n",
    "\n",
    "#[시각화 코드] - 이제 for문 돌면서 리스트를 깔 필요가 없어졌습니다!\n",
    "print(\"\\nVisualizing Attention Map...\")\n",
    "\n",
    "target_epochs = [5, 10, 25, 50]\n",
    "target_epochs = [e for e in target_epochs if e < len(attention_maps_history)]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(24, 6))\n",
    "\n",
    "for i, epoch_idx in enumerate(target_epochs):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # 모델이 이미 예쁘게 만들어준 (N, N) 행렬을 바로 사용\n",
    "    heatmap_data = attention_maps_history[epoch_idx].detach().cpu().numpy()\n",
    "\n",
    "    sns.heatmap(heatmap_data, ax=ax, cmap='viridis', square=True, cbar=True)\n",
    "    ax.set_title(f\"Epoch {epoch_idx}\")\n",
    "    ax.set_xlabel(\"Key (Past)\")\n",
    "    if i == 0: ax.set_ylabel(\"Query (Current)\")\n",
    "    else: ax.set_ylabel(\"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrfJKZyu6iHX"
   },
   "source": [
    "#### Saving the Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLM9VDwY6iHY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from google.colab import files\n",
    "\n",
    "# 1. 모델의 가중치(State Dict)를 파일로 저장\n",
    "save_transformer_rv_is_daily = 'tf_vae_rv_is_daily_best_weights.pth'\n",
    "torch.save(model_transformer_rv_is_daily.state_dict(), save_transformer_rv_is_daily)\n",
    "print(f\"가중치가 {save_transformer_rv_is_daily}에 저장되었습니다.\")\n",
    "\n",
    "# 2. 내 컴퓨터(로컬)로 파일 다운로드\n",
    "files.download(save_transformer_rv_is_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6JP71MG76iHY"
   },
   "outputs": [],
   "source": [
    "# 1. 수정된 클래스로 '새 빈 껍데기' 인스턴스 생성\n",
    "# (init 인자값들은 기존 학습 때와 100% 동일해야 함)\n",
    "model_transformer_rv_is_daily = DeepHedgingModelTransformerViz(input_dim=3, d_model=64, nhead=4, output_dim=2, max_len=N+10).to(device)\n",
    "\n",
    "# 2. 저장해둔 가중치 파일 불러오기\n",
    "# 로컬에 다운받았던 파일을 다시 코랩 왼쪽 '파일' 탭에 드래그해서 업로드한 후 실행\n",
    "load_path = 'tf_vae_rv_is_daily_best_weights.pth'\n",
    "model_transformer_rv_is_daily.load_state_dict(torch.load(load_path, map_location=device))\n",
    "\n",
    "# 3. 모델을 GPU로 보내고 추론 모드로 설정\n",
    "model_transformer_rv_is_daily.to(device)\n",
    "model_transformer_rv_is_daily.eval()\n",
    "\n",
    "print(\"수정된 클래스에 기존 가중치 로드가 완료되었습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaEaqwHIGYSd"
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2olzLX6EGYSd"
   },
   "outputs": [],
   "source": [
    "model_transformer_rv_is_daily.eval()  # 모델을 평가 모드로 전환 (Dropout, BatchNorm 비활성화)\n",
    "\n",
    "#generating test stock data\n",
    "\n",
    "gen_data_rv_is_daily_test, gen_rv_rv_is_daily_test = model_vae.generate_synthetic_data(\n",
    "    n_samples=N_SAMPLES,\n",
    "    device=device,\n",
    "    vol_of_vol=vol_of_vol,  # 설정하신 값\n",
    "    df_t=df_t,          # t-분포 자유도\n",
    "    coef_resid=coef_resid,\n",
    "    ln_mu = ln_mu\n",
    ")\n",
    "\n",
    "gen_returns_test = gen_data_rv_is_daily_test[:,:,0:1]\n",
    "prices_test = torch.exp(torch.cumsum(gen_returns_test, dim=1)) * S_0\n",
    "prices_test = torch.cat((S_0.unsqueeze(0).expand(prices_test.size(0),1).to(device),prices_test.squeeze(-1)),dim=1).unsqueeze(2).to(device)\n",
    "variances_test = gen_data_rv_is_daily_test[:,:,1:2]\n",
    "variances_test = torch.cat((V_0.unsqueeze(0).expand(variances_test.size(0),1).to(device),variances_test.squeeze(-1)),dim=1).unsqueeze(2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WV91xpAGYSe"
   },
   "outputs": [],
   "source": [
    "variances_test.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VbNTNXQcGYSe"
   },
   "outputs": [],
   "source": [
    "# --- Test 데이터 준비 (Test Loop 진입 전 실행) ---\n",
    "with torch.no_grad(): # 기울기 계산 끄기 (메모리 절약)\n",
    "\n",
    "    # 1. Test용 Variance Swap 데이터 생성\n",
    "    K_var_test, var_swap_prices_test = generate_var_swap_prices_heston(T, dt, prices_test.squeeze(-1), variances_test.squeeze(-1), kappa, theta, r, device)\n",
    "    prices_expanded_test = torch.cat([past_prices, prices_test.squeeze(-1)], dim=1)\n",
    "    rolling_rvs_test = rolling_rv(prices_expanded_test, window = window)\n",
    "\n",
    "    # 2. Input 구성\n",
    "    log_moneyness_test = torch.log(prices_test / K).to(device)\n",
    "\n",
    "    inputs_test = torch.cat([log_moneyness_test, var_swap_prices_test, rolling_rvs_test], dim=2).float()\n",
    "    inputs_test = inputs_test[:, :-1, :]# 마지막 시점 제외\n",
    "\n",
    "    # 3. 모델 예측 (Action)\n",
    "    # 결과: Stock 델타, VarSwap Notional\n",
    "    deltas_test, var_swap_ns_test,_ = model_transformer(inputs_test, T=T)\n",
    "\n",
    "    # 차원 축소 (Batch, Steps, 1) -> (Batch, Steps)\n",
    "    deltas_test = deltas_test.squeeze(-1)\n",
    "    var_swap_ns_test = var_swap_ns_test.squeeze(-1)\n",
    "\n",
    "    # 4. 자산 가격 변화량 계산 (t+1 - t)\n",
    "    price_changes_stock_test = prices_test[:, 1:, 0] - prices_test[:, :-1, 0]\n",
    "    price_changes_var_test = var_swap_prices_test[:, 1:, 0] - var_swap_prices_test[:, :-1, 0]\n",
    "\n",
    "    # 5. 거래 비용 (Transaction Cost) 계산\n",
    "\n",
    "    # (A) Stock Cost\n",
    "    prev_deltas_stock = torch.cat([torch.zeros(deltas_test.size(0), 1).to(device), deltas_test[:, :-1]], dim=1)\n",
    "    delta_changes_test = torch.abs(deltas_test - prev_deltas_stock)\n",
    "    cost_stock_test = torch.sum(delta_changes_test * prices_test[:, :-1, 0] * (COST_BPS_STOCK / 10000), dim=1)\n",
    "\n",
    "    # (B) VarSwap Cost\n",
    "    prev_ns_var = torch.cat([torch.zeros(var_swap_ns_test.size(0), 1).to(device), var_swap_ns_test[:, :-1]], dim=1)\n",
    "    n_changes_test = torch.abs(var_swap_ns_test - prev_ns_var)\n",
    "\n",
    "    # K_var_test 차원 확장 및 비용 계산\n",
    "    k_var_test_expanded = K_var_test.unsqueeze(1)\n",
    "    cost_var_test = torch.sum(n_changes_test * k_var_test_expanded * (COST_BPS_VAR / 10000), dim=1)\n",
    "\n",
    "    # 6. Hedging P&L 계산 (수익 - 비용)\n",
    "    gain_stock_test = torch.sum(deltas_test * price_changes_stock_test, dim=1)\n",
    "    gain_var_test = torch.sum(var_swap_ns_test * price_changes_var_test, dim=1)\n",
    "\n",
    "    hedging_pnl_test = (gain_stock_test + gain_var_test) - (cost_stock_test + cost_var_test)\n",
    "\n",
    "    # 7. 최종 P&L 및 Loss 계산\n",
    "    S_T_test = prices_test[:, -1, 0]\n",
    "    option_payoff_test = torch.relu(S_T_test - K)\n",
    "\n",
    "    total_pnl_test = hedging_pnl_test - option_payoff_test\n",
    "    # initial_cf는 옵션 프리미엄(초기 현금흐름)\n",
    "    final_pnl_test = (total_pnl_test + initial_cf) # * number_opt (필요시 곱하기)\n",
    "\n",
    "    # Loss Metric 계산\n",
    "    loss_test = cvar_loss(total_pnl_test)\n",
    "    loss_mse_test = mean_loss(total_pnl_test)\n",
    "    loss_entropy_test = entropic_loss(total_pnl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ig-1LiDlGYSe"
   },
   "outputs": [],
   "source": [
    "# 2. BS Hedging Simulation\n",
    "# ---------------------------------------------------------\n",
    "# prices_test shape: (Batch, Steps+1, 1)\n",
    "# 우리가 헷징 포지션을 잡아야 하는 건 t=0 부터 t=T-1 까지입니다.\n",
    "\n",
    "with torch.no_grad():\n",
    "    # (1) 입력 데이터 준비\n",
    "    # 시뮬레이션에 사용된 주가 (마지막 만기 시점 제외)\n",
    "    S_t = prices_test[:, :-1, 0] # shape: (Batch, Steps)\n",
    "\n",
    "    # (2) 잔여 만기(Time to Maturity) 텐서 생성\n",
    "    # t=0일 때 잔여만기 T, t=1일 때 T-dt, ...\n",
    "    # shape를 (Batch, Steps)로 맞춰줍니다.\n",
    "    batch_size, steps = S_t.shape\n",
    "    dt = T / steps\n",
    "\n",
    "    # [T, T-dt, T-2dt, ... , dt] 형태로 시간 생성\n",
    "    times = torch.linspace(T, dt, steps, device=device)\n",
    "    time_remaining_matrix = times.unsqueeze(0).expand(batch_size, steps) # (Batch, Steps)\n",
    "\n",
    "    # (3) BS Delta 계산\n",
    "    # r=0 (가정), sigma=sig\n",
    "    bs_deltas = calculate_bs_delta(S_t, time_remaining_matrix, K, 0.0, sig_0)\n",
    "\n",
    "    bs_prev_deltas = torch.cat([torch.zeros(bs_deltas.size(0), 1).to(device), bs_deltas[:, :-1]], dim=1)\n",
    "    bs_delta_changes = torch.abs(bs_deltas - bs_prev_deltas) # (Batch, Steps)\n",
    "\n",
    "    bs_transaction_costs = torch.sum(bs_delta_changes * prices_test[:, :-1, 0] * (COST_BPS_STOCK / 10000), dim=1)\n",
    "\n",
    "    # (4) BS P&L 계산 (Deep Hedging과 동일한 로직)\n",
    "    # 주가 변동분\n",
    "    price_changes_test = prices_test[:, 1:, 0] - prices_test[:, :-1, 0]\n",
    "\n",
    "    # 헷징 포트폴리오 수익\n",
    "    bs_hedging_pnl = torch.sum(bs_deltas * price_changes_test, dim=1) - bs_transaction_costs\n",
    "\n",
    "    # 옵션 Payoff (만기 시점)\n",
    "    S_T_test = prices_test[:, -1, 0]\n",
    "    option_payoff_test = torch.relu(S_T_test - K)\n",
    "\n",
    "    # 최종 P&L (Initial Premium + Hedging PnL - Payoff)\n",
    "    # initial_cf는 BS Call Price라고 하셨으므로, 이론상 이 값의 평균은 0에 수렴해야 함\n",
    "    bs_total_pnl = bs_hedging_pnl - option_payoff_test\n",
    "    bs_final_pnl = (initial_cf + bs_total_pnl) #* number_opt\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. 결과 비교 및 출력\n",
    "# ---------------------------------------------------------\n",
    "print(f\"--- Comparison (Test Paths: {M}) ---\")\n",
    "print(f\"[Deep Hedging] Mean PnL: {final_pnl_test.mean().item():.4f} | Std: {final_pnl_test.std().item():.4f} | CVaR(5%) w/o inital cf: {cvar_loss(final_pnl_test).item():.4f}\")\n",
    "print(f\"[BS Delta]     Mean PnL: {bs_final_pnl.mean().item():.4f} | Std: {bs_final_pnl.std().item():.4f} | CVaR(5%) w/o inital cf: {cvar_loss(bs_final_pnl).item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shDaOC50GYSe"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "# 딥러닝 PnL 분포\n",
    "plt.hist(final_pnl_test.cpu().numpy(), bins=75, alpha=0.5, label='Deep Hedging', density=True, color='blue')\n",
    "# BS PnL 분포\n",
    "plt.hist(bs_final_pnl.cpu().numpy(), bins=75, alpha=0.5, label='BS Hedging', density=True, color='red')\n",
    "\n",
    "plt.axvline(x=0, color='k', linestyle='--')\n",
    "plt.title('PnL Distribution Comparison with transaction cost')\n",
    "plt.xlabel('Profit & Loss')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Hzv7IIZGYSe"
   },
   "outputs": [],
   "source": [
    "# 한글 폰트 설정 (필요시 주석 해제)\n",
    "# plt.rcParams['font.family'] = 'Malgun Gothic' # Windows\n",
    "# plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "def visualize_deep_hedging_results(prices, variances, deltas, ns, pnls, T, dt, K):\n",
    "    \"\"\"\n",
    "    prices: (Batch, Steps+1)\n",
    "    variances: (Batch, Steps+1)\n",
    "    deltas: (Batch, Steps) -> Stock Hedge\n",
    "    ns: (Batch, Steps) -> VarSwap Hedge\n",
    "    pnls: (Batch) -> Final P&L\n",
    "    K: Strike Price (Scalar or Tensor)\n",
    "    \"\"\"\n",
    "\n",
    "    # 텐서를 넘파이로 변환 (CPU로 이동 후)\n",
    "    if torch.is_tensor(prices): prices = prices.cpu().numpy()\n",
    "    if torch.is_tensor(variances): variances = variances.cpu().numpy()\n",
    "    if torch.is_tensor(deltas): deltas = deltas.cpu().numpy()\n",
    "    if torch.is_tensor(ns): ns = ns.cpu().numpy()\n",
    "    if torch.is_tensor(pnls): pnls = pnls.cpu().numpy()\n",
    "\n",
    "    # K가 텐서면 변환, 아니면 그대로 사용\n",
    "    if torch.is_tensor(K):\n",
    "        K_val = K.detach().cpu().numpy()\n",
    "    else:\n",
    "        K_val = K\n",
    "\n",
    "    # 시간 축 생성\n",
    "    steps = deltas.shape[1]\n",
    "    time_axis = np.linspace(0, T, steps)\n",
    "\n",
    "    # ==========================================================\n",
    "    # 1. Sample Paths 시각화 (개별 샘플에서의 움직임)\n",
    "    # ==========================================================\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Sample Hedging Paths (Random 3 Samples)', fontsize=16)\n",
    "\n",
    "    sample_indices = np.random.choice(len(prices), 3, replace=False)\n",
    "    colors = ['r', 'g', 'b']\n",
    "\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        # 주가 & 변동성 흐름\n",
    "        ax1 = axes[0, 0]\n",
    "        ax1.plot(time_axis, prices[idx, :-1], color=colors[i], linestyle='-', label=f'Price {i}')\n",
    "        ax1.set_title('Underlying Price Process')\n",
    "        ax1.set_xlabel('Time')\n",
    "\n",
    "        ax2 = axes[0, 1]\n",
    "        ax2.plot(time_axis, np.sqrt(variances[idx, :-1]), color=colors[i], linestyle='--', label=f'Vol {i}')\n",
    "        ax2.set_title('Volatility Process (sqrt(v_t))')\n",
    "        ax2.set_xlabel('Time')\n",
    "\n",
    "        # 헷징 포지션 흐름\n",
    "        ax3 = axes[1, 0]\n",
    "        ax3.plot(time_axis, deltas[idx, :], color=colors[i], label=f'Delta {i}')\n",
    "        ax3.set_title('Stock Hedge Ratio (Delta)')\n",
    "        ax3.set_xlabel('Time')\n",
    "\n",
    "        ax4 = axes[1, 1]\n",
    "        ax4.plot(time_axis, ns[idx, :], color=colors[i], label=f'VarSwap N {i}')\n",
    "        ax4.set_title('VarSwap Notional (N)')\n",
    "        ax4.set_xlabel('Time')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    # ==========================================================\n",
    "    # 2. Scatter Plots + Trendline (Aggregate: 전체 기간 뭉뚱그림)\n",
    "    # ==========================================================\n",
    "    # 데이터를 1차원으로 펼치기 (Batch * Steps)\n",
    "    flat_prices = prices[:, :-1].flatten()\n",
    "    flat_vars = variances[:, :-1].flatten()\n",
    "    flat_vols = np.sqrt(flat_vars)\n",
    "    flat_deltas = deltas.flatten()\n",
    "    flat_ns = ns.flatten()\n",
    "\n",
    "    # K_val이 스칼라일 때와 배열일 때 처리\n",
    "    if np.ndim(K_val) == 0:\n",
    "        flat_moneyness = np.log(flat_prices / K_val)\n",
    "    else:\n",
    "        # K가 (Batch,) 형태라면 확장 필요\n",
    "        # 여기서는 간단히 처리 (사용자 환경에 맞게 조정)\n",
    "        pass\n",
    "        flat_moneyness = np.log(flat_prices / K_val) # K가 스칼라라고 가정\n",
    "\n",
    "    # 샘플링\n",
    "    sample_mask = np.random.choice(len(flat_prices), 5000, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    fig.suptitle('Aggregate Hedging Strategy (All Time Steps)', fontsize=16)\n",
    "\n",
    "    sns.regplot(x=flat_vols[sample_mask], y=flat_deltas[sample_mask], ax=axes[0],\n",
    "                scatter_kws={'alpha':0.1}, line_kws={'color':'red'}, order=2)\n",
    "    axes[0].set_title('Volatility vs Stock Delta')\n",
    "\n",
    "    sns.regplot(x=flat_vols[sample_mask], y=flat_ns[sample_mask], ax=axes[1],\n",
    "                scatter_kws={'alpha':0.1}, line_kws={'color':'red'}, order=2)\n",
    "    axes[1].set_title('Volatility vs VarSwap N')\n",
    "\n",
    "    sns.regplot(x=flat_moneyness[sample_mask], y=flat_deltas[sample_mask], ax=axes[2],\n",
    "                scatter_kws={'alpha':0.1}, line_kws={'color':'red'}, order=3)\n",
    "    axes[2].set_title('Log Moneyness vs Stock Delta')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ==========================================================\n",
    "    # [NEW] 2-1. Time-Sliced Analysis (at t = T/2)\n",
    "    # 특정 시점(중간 지점)을 잘라서 만기 효과(Tau)를 제거하고 봅니다.\n",
    "    # ==========================================================\n",
    "    mid_idx = steps // 2  # 중간 시점 인덱스\n",
    "\n",
    "    # 중간 시점의 데이터만 추출 (Batch Size만큼의 데이터)\n",
    "    slice_vol = np.sqrt(variances[:, mid_idx])\n",
    "    slice_n = ns[:, mid_idx]\n",
    "    slice_delta = deltas[:, mid_idx]\n",
    "    slice_moneyness = np.log(prices[:, mid_idx] / K_val)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    fig.suptitle(f'Time-Sliced Analysis (at Step {mid_idx}/{steps}, t={T/2:.2f})', fontsize=16, color='darkblue')\n",
    "\n",
    "    # (1) Sliced: Vol vs N (여기가 핵심)\n",
    "    # Lowess 추세선을 사용하여 비선형 관계를 더 부드럽게 봅니다.\n",
    "    sns.regplot(x=slice_vol, y=slice_n, ax=axes[1],\n",
    "                scatter_kws={'alpha':0.3, 'color': 'green'},\n",
    "                line_kws={'color':'darkgreen'}, lowess=True)\n",
    "    axes[1].set_title('Volatility vs VarSwap N (at T/2)')\n",
    "    axes[1].set_xlabel('Volatility (sigma)')\n",
    "    axes[1].set_ylabel('VarSwap Notional')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    # (2) Sliced: Vol vs Delta\n",
    "    sns.regplot(x=slice_vol, y=slice_delta, ax=axes[0],\n",
    "                scatter_kws={'alpha':0.3, 'color': 'purple'},\n",
    "                line_kws={'color':'indigo'}, order=2)\n",
    "    axes[0].set_title('Volatility vs Stock Delta (at T/2)')\n",
    "    axes[0].set_xlabel('Volatility (sigma)')\n",
    "    axes[0].set_ylabel('Hedge Ratio (Delta)')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # (3) Sliced: Moneyness vs Delta\n",
    "    sns.regplot(x=slice_moneyness, y=slice_delta, ax=axes[2],\n",
    "                scatter_kws={'alpha':0.3, 'color': 'orange'},\n",
    "                line_kws={'color':'brown'}, order=3)\n",
    "    axes[2].set_title('Moneyness vs Delta (at T/2)')\n",
    "    axes[2].set_xlabel('Log Moneyness')\n",
    "    axes[2].set_ylabel('Hedge Ratio (Delta)')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ==========================================================\n",
    "    # 3. [Alpha] P&L Distribution (성능 증명)\n",
    "    # ==========================================================\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(pnls, bins=50, kde=True, color='blue', stat='density', label='Deep Hedging P&L')\n",
    "\n",
    "    plt.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "    mean_val = np.mean(pnls)\n",
    "    std_val = np.std(pnls)\n",
    "    cvar_val = np.sort(pnls)[:int(len(pnls)*0.05)].mean()\n",
    "\n",
    "    plt.axvline(x=cvar_val, color='red', linestyle=':', label=f'CVaR (5%): {cvar_val:.4f}')\n",
    "    plt.title(f'Final P&L Distribution\\nMean: {mean_val:.4f} | Std: {std_val:.4f} | CVaR: {cvar_val:.4f}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # ==========================================================\n",
    "    # 4. [Alpha] Strategy Heatmap (Aggregate)\n",
    "    # ==========================================================\n",
    "    df_map = pd.DataFrame({\n",
    "        'Moneyness': flat_moneyness[sample_mask],\n",
    "        'Volatility': flat_vols[sample_mask],\n",
    "        'VarSwap_N': flat_ns[sample_mask]\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sc = plt.scatter(df_map['Moneyness'], df_map['Volatility'], c=df_map['VarSwap_N'],\n",
    "                     cmap='coolwarm', alpha=0.7, s=20)\n",
    "    plt.colorbar(sc, label='VarSwap Notional Position')\n",
    "    plt.title('Strategy Heatmap: When does the model buy/sell VarSwap?')\n",
    "    plt.xlabel('Log Moneyness (ln S/K)')\n",
    "    plt.ylabel('Volatility')\n",
    "    plt.axvline(0, color='black', linestyle='--', alpha=0.5)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# --- 실행 코드 ---\n",
    "# 데이터는 Test Loop를 돌리고 난 후의 변수들을 넣으시면 됩니다.\n",
    "# 텐서 상태여도 함수 내부에서 자동으로 numpy로 변환합니다.\n",
    "visualize_deep_hedging_results(\n",
    "    prices_test[:,:,0],\n",
    "    variances_test[:,:,0], # <- 이거 test loop 전에 저장해둔 변동성 path\n",
    "    deltas_test,\n",
    "    var_swap_ns_test,\n",
    "    final_pnl_test,\n",
    "    T, dt, K\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_-bPm01tA9G"
   },
   "source": [
    "### With Clamping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndqu40KMXdBV"
   },
   "outputs": [],
   "source": [
    "params, v_t = garch_heston_analysis(df_train)\n",
    "print(f'\\nEstimated Hyperparameters of Heston: {params}\\n')\n",
    "# 디바이스 설정 (GPU 권장)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "# --- 하이퍼파라미터 설정 ---\n",
    "mean = torch.tensor(params['mu_simple'])\n",
    "kappa = torch.tensor(params['kappa'])\n",
    "theta = torch.tensor(params['theta'])\n",
    "xi = torch.tensor(params['xi'])\n",
    "rho = torch.tensor(params['rho'])\n",
    "V_0 = torch.tensor(params['v0'])\n",
    "sig_0 = torch.sqrt(V_0)\n",
    "S_0 = torch.tensor(df_train[-1])\n",
    "K = torch.tensor(df_train[-1])   # ATM 옵션\n",
    "number_opt = NUMBER_OPT\n",
    "rv_window = RV_WINDOW\n",
    "initial_cf = bscall(S_0, K, T, mean, sig_0)\n",
    "\n",
    "\n",
    "# --- 모델 초기화 (Transformer) ---\n",
    "# input_dim=3 (LogMoneyness, VarSwapPrice, RollingRV)\n",
    "model_transformer_with_clamping = DeepHedgingModelTransformerViz(input_dim=3, d_model=64, nhead=4, output_dim=2, max_len=N+10).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model_transformer_with_clamping.parameters(), lr=0.005)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "# [3] Training Loop\n",
    "print(\"\\n\\nTraining Start with Transformer...\")\n",
    "\n",
    "COST_BPS_STOCK = 10.0\n",
    "COST_BPS_VAR   = 30.0\n",
    "\n",
    "epochs = 51\n",
    "attention_maps_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 1. 데이터 생성\n",
    "    gen_data_with_clamping, gen_rv_with_clamping = model_vae.generate_physically_consistent_paths_with_clamping(\n",
    "    historical_returns=historical_data_np,\n",
    "    n_samples=N_SAMPLES,\n",
    "    n_steps=N_STEPS,\n",
    "    N_window=N_WINDOW,\n",
    "    device=device,\n",
    "    coef_resid=COEF_RESID,\n",
    "    noise_level=NOISE_LEVEL,\n",
    "    z_coef=Z_COEF,\n",
    "    reversion_prob=REVERSION_PROB,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "    gen_returns = gen_data_with_clamping[:,:,0:1]\n",
    "    prices = torch.exp(torch.cumsum(gen_returns, dim=1)) * S_0\n",
    "    prices = torch.cat((S_0.unsqueeze(0).expand(prices.size(0),1).to(device),prices.squeeze(-1)),dim=1).unsqueeze(2).to(device)\n",
    "    variances = gen_data_with_clamping[:,:,1:2]\n",
    "    variances = torch.cat((V_0.unsqueeze(0).expand(variances.size(0),1).to(device),variances.squeeze(-1)),dim=1).unsqueeze(2).to(device)\n",
    "\n",
    "    S_T = prices[:, -1, 0]\n",
    "\n",
    "    # Past Prices 처리\n",
    "    past_prices = (torch.tensor(df_train.iloc[-rv_window-1:-1].values).float() * torch.ones(M, rv_window)).to(device)\n",
    "    prices_expanded = torch.cat([past_prices, prices.squeeze(-1)], dim=1)\n",
    "    rolling_rvs = rolling_rv(prices_expanded, window=rv_window)\n",
    "\n",
    "    # 2. Variance Swap Inputs\n",
    "    K_var, var_swap_prices = generate_var_swap_prices_heston(T, dt, prices[:, :, 0], variances[:, :, 0], kappa, theta, r, device)\n",
    "\n",
    "    # 3. Inputs 구성 (Batch, Steps+1, 3)\n",
    "    log_moneyness = torch.log(prices / K)\n",
    "    inputs = torch.cat([log_moneyness, var_swap_prices, rolling_rvs], dim=2).float()\n",
    "    inputs = inputs[:, :-1, :] # (Batch, Steps, 3) Action은 T-1까지만 필요\n",
    "\n",
    "    # 배치 루프 변수 초기화\n",
    "    epoch_loss = 0.0\n",
    "    epoch_loss_mse = 0.0\n",
    "    epoch_loss_entropy = 0.0\n",
    "    epoch_final_pnl = 0.0\n",
    "    num_iters = 0\n",
    "\n",
    "    for i in range(0, M, BATCH_SIZE_HESTON):\n",
    "        if (i + 2 * BATCH_SIZE_HESTON) > M:\n",
    "            batch_inputs = inputs[i:, :, :]\n",
    "            batch_prices = prices[i:, :, :]\n",
    "            batch_var = variances[i:, :, 0]\n",
    "            batch_varswaps = var_swap_prices[i:, :, :]\n",
    "            batch_K_var = K_var[i:]\n",
    "            option_payoff = torch.relu(S_T - K)[i:]\n",
    "            is_last_batch = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            batch_inputs = inputs[i : i + BATCH_SIZE_HESTON, :, :]\n",
    "            batch_prices = prices[i : i + BATCH_SIZE_HESTON, :, :]\n",
    "            batch_varswaps = var_swap_prices[i : i + BATCH_SIZE_HESTON, :, :]\n",
    "            batch_K_var = K_var[i : i + BATCH_SIZE_HESTON]\n",
    "            option_payoff = torch.relu(S_T - K)[i : i + BATCH_SIZE_HESTON]\n",
    "            is_last_batch = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # --- [변경] 모델 호출 (Unpacking attention_maps) ---\n",
    "        deltas, var_swap_ns, attn_map_matrix = model_transformer_with_clamping (batch_inputs, T=T)\n",
    "\n",
    "        # 마지막 배치의 Attention Map 저장 (시각화용)\n",
    "        if is_last_batch:\n",
    "            revised_attention_mtx = torch.zeros((N,N), device=device)\n",
    "            for i in range(N):\n",
    "              revised_attention_mtx[i,:i+1] = attn_map_matrix[i][0]\n",
    "\n",
    "            attention_maps_history.append(revised_attention_mtx)\n",
    "\n",
    "        deltas = deltas.squeeze(-1)\n",
    "        var_swap_ns = var_swap_ns.squeeze(-1)\n",
    "\n",
    "        # ... (이하 비용 계산 로직은 기존과 100% 동일) ...\n",
    "        price_changes_stock = batch_prices[:, 1:, 0] - batch_prices[:, :-1, 0]\n",
    "        price_changes_var = batch_varswaps[:, 1:, 0] - batch_varswaps[:, :-1, 0]\n",
    "\n",
    "        prev_deltas = torch.cat([torch.zeros(deltas.size(0), 1).to(device), deltas[:, :-1]], dim=1)\n",
    "        delta_changes = torch.abs(deltas - prev_deltas)\n",
    "        cost_stock = torch.sum(delta_changes * batch_prices[:, :-1, 0] * (COST_BPS_STOCK / 10000), dim=1)\n",
    "\n",
    "        prev_ns = torch.cat([torch.zeros(var_swap_ns.size(0), 1).to(device), var_swap_ns[:, :-1]], dim=1)\n",
    "        n_changes = torch.abs(var_swap_ns - prev_ns)\n",
    "        k_var_expanded = batch_K_var.unsqueeze(1)\n",
    "        cost_var = torch.sum(n_changes * k_var_expanded * (COST_BPS_VAR / 10000), dim=1)\n",
    "\n",
    "        gain_stock = torch.sum(deltas * price_changes_stock, dim=1)\n",
    "        gain_var = torch.sum(var_swap_ns * price_changes_var, dim=1)\n",
    "        hedging_pnl = (gain_stock + gain_var) - (cost_stock + cost_var)\n",
    "\n",
    "        total_pnl = hedging_pnl - option_payoff\n",
    "        final_pnl = number_opt * (total_pnl + initial_cf)\n",
    "\n",
    "        loss = cvar_loss(total_pnl)\n",
    "        loss_mse = mean_loss(total_pnl)\n",
    "        loss_entropy = entropic_loss(total_pnl, risk_aversion = 0.7)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        torch.nn.utils.clip_grad_norm_(model_transformer_with_clamping .parameters(), max_norm=1.0)\n",
    "        loss_entropy.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_loss_mse += loss_mse.item()\n",
    "        epoch_loss_entropy += loss_entropy.item()\n",
    "        epoch_final_pnl += final_pnl.mean().item()\n",
    "        num_iters += 1\n",
    "\n",
    "        if is_last_batch: break\n",
    "\n",
    "    # 에포크 마지막 부분\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    avg_entropy = epoch_loss_entropy / num_iters\n",
    "\n",
    "    # 스케줄러 업데이트\n",
    "    scheduler.step(avg_entropy)\n",
    "\n",
    "\n",
    "    # 학습률이 변했는지 체크해서 알려주는 로직 (수동 verbose)\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    if new_lr < current_lr:\n",
    "        print(f\"--- When Epoch {epoch} is over, Learning Rate Reduced: {current_lr:.6f} -> {new_lr:.6f} ---\")\n",
    "        if new_lr <= 0.0001:\n",
    "          print(f'Stop Learning. (Final Epoch = {epoch})')\n",
    "          print(f\"Epoch {epoch} | CVaR: {avg_loss:.4f} | Entropic Loss: {avg_entropy:.4f} | PnL: {avg_pnl:.4f}\")\n",
    "          break\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "       avg_loss = epoch_loss / num_iters\n",
    "       avg_pnl = epoch_final_pnl / num_iters\n",
    "       avg_entropy = epoch_loss_entropy / num_iters\n",
    "\n",
    "\n",
    "       print(f\"Epoch {epoch} | CVaR: {avg_loss:.4f} | Entropic Loss: {avg_entropy:.4f} | PnL: {avg_pnl:.4f}\")\n",
    "\n",
    "print(f\"Training Finished.\")\n",
    "\n",
    "#[시각화 코드] - 이제 for문 돌면서 리스트를 깔 필요가 없어졌습니다!\n",
    "print(\"\\nVisualizing Attention Map...\")\n",
    "\n",
    "target_epochs = [5, 10, 25, 50]\n",
    "target_epochs = [e for e in target_epochs if e < len(attention_maps_history)]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(24, 6))\n",
    "\n",
    "for i, epoch_idx in enumerate(target_epochs):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # 모델이 이미 예쁘게 만들어준 (N, N) 행렬을 바로 사용\n",
    "    heatmap_data = attention_maps_history[epoch_idx].detach().cpu().numpy()\n",
    "\n",
    "    sns.heatmap(heatmap_data, ax=ax, cmap='viridis', square=True, cbar=True)\n",
    "    ax.set_title(f\"Epoch {epoch_idx}\")\n",
    "    ax.set_xlabel(\"Key (Past)\")\n",
    "    if i == 0: ax.set_ylabel(\"Query (Current)\")\n",
    "    else: ax.set_ylabel(\"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkTGuNGGsoc5"
   },
   "source": [
    "#### Saving the Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zO1A7_lksoc6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from google.colab import files\n",
    "\n",
    "# 1. 모델의 가중치(State Dict)를 파일로 저장\n",
    "save_transformer_with_clamping = 'tf_vae_with_clamping_best_weights.pth'\n",
    "torch.save(model_transformer_with_clamping.state_dict(), save_transformer_with_clamping)\n",
    "print(f\"가중치가 {save_transformer_with_clamping}에 저장되었습니다.\")\n",
    "\n",
    "# 2. 내 컴퓨터(로컬)로 파일 다운로드\n",
    "files.download(save_transformer_with_clamping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PRhJDOVfsoc6"
   },
   "outputs": [],
   "source": [
    "# 1. 수정된 클래스로 '새 빈 껍데기' 인스턴스 생성\n",
    "# (init 인자값들은 기존 학습 때와 100% 동일해야 함)\n",
    "model_transformer_with_clamping = DeepHedgingModelTransformerViz(input_dim=3, d_model=64, nhead=4, output_dim=2, max_len=N+10).to(device)\n",
    "\n",
    "# 2. 저장해둔 가중치 파일 불러오기\n",
    "# 로컬에 다운받았던 파일을 다시 코랩 왼쪽 '파일' 탭에 드래그해서 업로드한 후 실행\n",
    "load_path = 'tf_vae_with_clamping_best_weights.pth'\n",
    "model_transformer_with_clamping.load_state_dict(torch.load(load_path, map_location=device))\n",
    "\n",
    "# 3. 모델을 GPU로 보내고 추론 모드로 설정\n",
    "model_transformer_with_clamping.to(device)\n",
    "model_transformer_with_clamping.eval()\n",
    "\n",
    "print(\"수정된 클래스에 기존 가중치 로드가 완료되었습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wby4HKxV8kng"
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FndO0x3w8knh"
   },
   "outputs": [],
   "source": [
    "model_transformer_with_clamping.eval()  # 모델을 평가 모드로 전환 (Dropout, BatchNorm 비활성화)\n",
    "\n",
    "#generating test stock data\n",
    "\n",
    "gen_data_with_clamping_test, gen_rv_with_clamping_test = model_vae.generate_physically_consistent_paths_with_clamping(\n",
    "    historical_returns=historical_data_np,\n",
    "    n_samples=N_SAMPLES,\n",
    "    n_steps=N_STEPS,\n",
    "    N_window=N_WINDOW,\n",
    "    device=device,\n",
    "    coef_resid=COEF_RESID,\n",
    "    noise_level=NOISE_LEVEL,\n",
    "    z_coef=Z_COEF,\n",
    "    reversion_prob=REVERSION_PROB,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "gen_returns_test = gen_data_with_clamping_test[:,:,0:1]\n",
    "prices_test = torch.exp(torch.cumsum(gen_returns_test, dim=1)) * S_0\n",
    "prices_test = torch.cat((S_0.unsqueeze(0).expand(prices_test.size(0),1).to(device),prices_test.squeeze(-1)),dim=1).unsqueeze(2).to(device)\n",
    "variances_test = gen_data_with_clamping_test[:,:,1:2]\n",
    "variances_test = torch.cat((V_0.unsqueeze(0).expand(variances_test.size(0),1).to(device),variances_test.squeeze(-1)),dim=1).unsqueeze(2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNO42ay_8knh"
   },
   "outputs": [],
   "source": [
    "# --- Test 데이터 준비 (Test Loop 진입 전 실행) ---\n",
    "with torch.no_grad(): # 기울기 계산 끄기 (메모리 절약)\n",
    "\n",
    "    # 1. Test용 Variance Swap 데이터 생성\n",
    "    K_var_test, var_swap_prices_test = generate_var_swap_prices_heston(T, dt, prices_test.squeeze(-1), variances_test.squeeze(-1), kappa, theta, r, device)\n",
    "    prices_expanded_test = torch.cat([past_prices, prices_test.squeeze(-1)], dim=1)\n",
    "    rolling_rvs_test = rolling_rv(prices_expanded_test, window = window)\n",
    "\n",
    "    # 2. Input 구성\n",
    "    log_moneyness_test = torch.log(prices_test / K).to(device)\n",
    "\n",
    "    inputs_test = torch.cat([log_moneyness_test, var_swap_prices_test, rolling_rvs_test], dim=2).float()\n",
    "    inputs_test = inputs_test[:, :-1, :]# 마지막 시점 제외\n",
    "\n",
    "    # 3. 모델 예측 (Action)\n",
    "    # 결과: Stock 델타, VarSwap Notional\n",
    "    deltas_test, var_swap_ns_test,_ = model_transformer(inputs_test, T=T)\n",
    "\n",
    "    # 차원 축소 (Batch, Steps, 1) -> (Batch, Steps)\n",
    "    deltas_test = deltas_test.squeeze(-1)\n",
    "    var_swap_ns_test = var_swap_ns_test.squeeze(-1)\n",
    "\n",
    "    # 4. 자산 가격 변화량 계산 (t+1 - t)\n",
    "    price_changes_stock_test = prices_test[:, 1:, 0] - prices_test[:, :-1, 0]\n",
    "    price_changes_var_test = var_swap_prices_test[:, 1:, 0] - var_swap_prices_test[:, :-1, 0]\n",
    "\n",
    "    # 5. 거래 비용 (Transaction Cost) 계산\n",
    "\n",
    "    # (A) Stock Cost\n",
    "    prev_deltas_stock = torch.cat([torch.zeros(deltas_test.size(0), 1).to(device), deltas_test[:, :-1]], dim=1)\n",
    "    delta_changes_test = torch.abs(deltas_test - prev_deltas_stock)\n",
    "    cost_stock_test = torch.sum(delta_changes_test * prices_test[:, :-1, 0] * (COST_BPS_STOCK / 10000), dim=1)\n",
    "\n",
    "    # (B) VarSwap Cost\n",
    "    prev_ns_var = torch.cat([torch.zeros(var_swap_ns_test.size(0), 1).to(device), var_swap_ns_test[:, :-1]], dim=1)\n",
    "    n_changes_test = torch.abs(var_swap_ns_test - prev_ns_var)\n",
    "\n",
    "    # K_var_test 차원 확장 및 비용 계산\n",
    "    k_var_test_expanded = K_var_test.unsqueeze(1)\n",
    "    cost_var_test = torch.sum(n_changes_test * k_var_test_expanded * (COST_BPS_VAR / 10000), dim=1)\n",
    "\n",
    "    # 6. Hedging P&L 계산 (수익 - 비용)\n",
    "    gain_stock_test = torch.sum(deltas_test * price_changes_stock_test, dim=1)\n",
    "    gain_var_test = torch.sum(var_swap_ns_test * price_changes_var_test, dim=1)\n",
    "\n",
    "    hedging_pnl_test = (gain_stock_test + gain_var_test) - (cost_stock_test + cost_var_test)\n",
    "\n",
    "    # 7. 최종 P&L 및 Loss 계산\n",
    "    S_T_test = prices_test[:, -1, 0]\n",
    "    option_payoff_test = torch.relu(S_T_test - K)\n",
    "\n",
    "    total_pnl_test = hedging_pnl_test - option_payoff_test\n",
    "    # initial_cf는 옵션 프리미엄(초기 현금흐름)\n",
    "    final_pnl_test = (total_pnl_test + initial_cf) # * number_opt (필요시 곱하기)\n",
    "\n",
    "    # Loss Metric 계산\n",
    "    loss_test = cvar_loss(total_pnl_test)\n",
    "    loss_mse_test = mean_loss(total_pnl_test)\n",
    "    loss_entropy_test = entropic_loss(total_pnl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XoGd1zyo8knh"
   },
   "outputs": [],
   "source": [
    "# 2. BS Hedging Simulation\n",
    "# ---------------------------------------------------------\n",
    "# prices_test shape: (Batch, Steps+1, 1)\n",
    "# 우리가 헷징 포지션을 잡아야 하는 건 t=0 부터 t=T-1 까지입니다.\n",
    "\n",
    "with torch.no_grad():\n",
    "    # (1) 입력 데이터 준비\n",
    "    # 시뮬레이션에 사용된 주가 (마지막 만기 시점 제외)\n",
    "    S_t = prices_test[:, :-1, 0] # shape: (Batch, Steps)\n",
    "\n",
    "    # (2) 잔여 만기(Time to Maturity) 텐서 생성\n",
    "    # t=0일 때 잔여만기 T, t=1일 때 T-dt, ...\n",
    "    # shape를 (Batch, Steps)로 맞춰줍니다.\n",
    "    batch_size, steps = S_t.shape\n",
    "    dt = T / steps\n",
    "\n",
    "    # [T, T-dt, T-2dt, ... , dt] 형태로 시간 생성\n",
    "    times = torch.linspace(T, dt, steps, device=device)\n",
    "    time_remaining_matrix = times.unsqueeze(0).expand(batch_size, steps) # (Batch, Steps)\n",
    "\n",
    "    # (3) BS Delta 계산\n",
    "    # r=0 (가정), sigma=sig\n",
    "    bs_deltas = calculate_bs_delta(S_t, time_remaining_matrix, K, 0.0, sig_0)\n",
    "\n",
    "    bs_prev_deltas = torch.cat([torch.zeros(bs_deltas.size(0), 1).to(device), bs_deltas[:, :-1]], dim=1)\n",
    "    bs_delta_changes = torch.abs(bs_deltas - bs_prev_deltas) # (Batch, Steps)\n",
    "\n",
    "    bs_transaction_costs = torch.sum(bs_delta_changes * prices_test[:, :-1, 0] * (COST_BPS_STOCK / 10000), dim=1)\n",
    "\n",
    "    # (4) BS P&L 계산 (Deep Hedging과 동일한 로직)\n",
    "    # 주가 변동분\n",
    "    price_changes_test = prices_test[:, 1:, 0] - prices_test[:, :-1, 0]\n",
    "\n",
    "    # 헷징 포트폴리오 수익\n",
    "    bs_hedging_pnl = torch.sum(bs_deltas * price_changes_test, dim=1) - bs_transaction_costs\n",
    "\n",
    "    # 옵션 Payoff (만기 시점)\n",
    "    S_T_test = prices_test[:, -1, 0]\n",
    "    option_payoff_test = torch.relu(S_T_test - K)\n",
    "\n",
    "    # 최종 P&L (Initial Premium + Hedging PnL - Payoff)\n",
    "    # initial_cf는 BS Call Price라고 하셨으므로, 이론상 이 값의 평균은 0에 수렴해야 함\n",
    "    bs_total_pnl = bs_hedging_pnl - option_payoff_test\n",
    "    bs_final_pnl = (initial_cf + bs_total_pnl) #* number_opt\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. 결과 비교 및 출력\n",
    "# ---------------------------------------------------------\n",
    "print(f\"--- Comparison (Test Paths: {M}) ---\")\n",
    "print(f\"[Deep Hedging] Mean PnL: {final_pnl_test.mean().item():.4f} | Std: {final_pnl_test.std().item():.4f} | CVaR(5%) w/o inital cf: {cvar_loss(final_pnl_test).item():.4f}\")\n",
    "print(f\"[BS Delta]     Mean PnL: {bs_final_pnl.mean().item():.4f} | Std: {bs_final_pnl.std().item():.4f} | CVaR(5%) w/o inital cf: {cvar_loss(bs_final_pnl).item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sWGywAM88knh"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "# 딥러닝 PnL 분포\n",
    "plt.hist(final_pnl_test.cpu().numpy(), bins=75, alpha=0.5, label='Deep Hedging', density=True, color='blue')\n",
    "# BS PnL 분포\n",
    "plt.hist(bs_final_pnl.cpu().numpy(), bins=75, alpha=0.5, label='BS Hedging', density=True, color='red')\n",
    "\n",
    "plt.axvline(x=0, color='k', linestyle='--')\n",
    "plt.title('PnL Distribution Comparison with transaction cost')\n",
    "plt.xlabel('Profit & Loss')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jji_lWbD8knh"
   },
   "outputs": [],
   "source": [
    "# 한글 폰트 설정 (필요시 주석 해제)\n",
    "# plt.rcParams['font.family'] = 'Malgun Gothic' # Windows\n",
    "# plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "def visualize_deep_hedging_results(prices, variances, deltas, ns, pnls, T, dt, K):\n",
    "    \"\"\"\n",
    "    prices: (Batch, Steps+1)\n",
    "    variances: (Batch, Steps+1)\n",
    "    deltas: (Batch, Steps) -> Stock Hedge\n",
    "    ns: (Batch, Steps) -> VarSwap Hedge\n",
    "    pnls: (Batch) -> Final P&L\n",
    "    K: Strike Price (Scalar or Tensor)\n",
    "    \"\"\"\n",
    "\n",
    "    # 텐서를 넘파이로 변환 (CPU로 이동 후)\n",
    "    if torch.is_tensor(prices): prices = prices.cpu().numpy()\n",
    "    if torch.is_tensor(variances): variances = variances.cpu().numpy()\n",
    "    if torch.is_tensor(deltas): deltas = deltas.cpu().numpy()\n",
    "    if torch.is_tensor(ns): ns = ns.cpu().numpy()\n",
    "    if torch.is_tensor(pnls): pnls = pnls.cpu().numpy()\n",
    "\n",
    "    # K가 텐서면 변환, 아니면 그대로 사용\n",
    "    if torch.is_tensor(K):\n",
    "        K_val = K.detach().cpu().numpy()\n",
    "    else:\n",
    "        K_val = K\n",
    "\n",
    "    # 시간 축 생성\n",
    "    steps = deltas.shape[1]\n",
    "    time_axis = np.linspace(0, T, steps)\n",
    "\n",
    "    # ==========================================================\n",
    "    # 1. Sample Paths 시각화 (개별 샘플에서의 움직임)\n",
    "    # ==========================================================\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Sample Hedging Paths (Random 3 Samples)', fontsize=16)\n",
    "\n",
    "    sample_indices = np.random.choice(len(prices), 3, replace=False)\n",
    "    colors = ['r', 'g', 'b']\n",
    "\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        # 주가 & 변동성 흐름\n",
    "        ax1 = axes[0, 0]\n",
    "        ax1.plot(time_axis, prices[idx, :-1], color=colors[i], linestyle='-', label=f'Price {i}')\n",
    "        ax1.set_title('Underlying Price Process')\n",
    "        ax1.set_xlabel('Time')\n",
    "\n",
    "        ax2 = axes[0, 1]\n",
    "        ax2.plot(time_axis, np.sqrt(variances[idx, :-1]), color=colors[i], linestyle='--', label=f'Vol {i}')\n",
    "        ax2.set_title('Volatility Process (sqrt(v_t))')\n",
    "        ax2.set_xlabel('Time')\n",
    "\n",
    "        # 헷징 포지션 흐름\n",
    "        ax3 = axes[1, 0]\n",
    "        ax3.plot(time_axis, deltas[idx, :], color=colors[i], label=f'Delta {i}')\n",
    "        ax3.set_title('Stock Hedge Ratio (Delta)')\n",
    "        ax3.set_xlabel('Time')\n",
    "\n",
    "        ax4 = axes[1, 1]\n",
    "        ax4.plot(time_axis, ns[idx, :], color=colors[i], label=f'VarSwap N {i}')\n",
    "        ax4.set_title('VarSwap Notional (N)')\n",
    "        ax4.set_xlabel('Time')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    # ==========================================================\n",
    "    # 2. Scatter Plots + Trendline (Aggregate: 전체 기간 뭉뚱그림)\n",
    "    # ==========================================================\n",
    "    # 데이터를 1차원으로 펼치기 (Batch * Steps)\n",
    "    flat_prices = prices[:, :-1].flatten()\n",
    "    flat_vars = variances[:, :-1].flatten()\n",
    "    flat_vols = np.sqrt(flat_vars)\n",
    "    flat_deltas = deltas.flatten()\n",
    "    flat_ns = ns.flatten()\n",
    "\n",
    "    # K_val이 스칼라일 때와 배열일 때 처리\n",
    "    if np.ndim(K_val) == 0:\n",
    "        flat_moneyness = np.log(flat_prices / K_val)\n",
    "    else:\n",
    "        # K가 (Batch,) 형태라면 확장 필요\n",
    "        # 여기서는 간단히 처리 (사용자 환경에 맞게 조정)\n",
    "        pass\n",
    "        flat_moneyness = np.log(flat_prices / K_val) # K가 스칼라라고 가정\n",
    "\n",
    "    # 샘플링\n",
    "    sample_mask = np.random.choice(len(flat_prices), 5000, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    fig.suptitle('Aggregate Hedging Strategy (All Time Steps)', fontsize=16)\n",
    "\n",
    "    sns.regplot(x=flat_vols[sample_mask], y=flat_deltas[sample_mask], ax=axes[0],\n",
    "                scatter_kws={'alpha':0.1}, line_kws={'color':'red'}, order=2)\n",
    "    axes[0].set_title('Volatility vs Stock Delta')\n",
    "\n",
    "    sns.regplot(x=flat_vols[sample_mask], y=flat_ns[sample_mask], ax=axes[1],\n",
    "                scatter_kws={'alpha':0.1}, line_kws={'color':'red'}, order=2)\n",
    "    axes[1].set_title('Volatility vs VarSwap N')\n",
    "\n",
    "    sns.regplot(x=flat_moneyness[sample_mask], y=flat_deltas[sample_mask], ax=axes[2],\n",
    "                scatter_kws={'alpha':0.1}, line_kws={'color':'red'}, order=3)\n",
    "    axes[2].set_title('Log Moneyness vs Stock Delta')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ==========================================================\n",
    "    # [NEW] 2-1. Time-Sliced Analysis (at t = T/2)\n",
    "    # 특정 시점(중간 지점)을 잘라서 만기 효과(Tau)를 제거하고 봅니다.\n",
    "    # ==========================================================\n",
    "    mid_idx = steps // 2  # 중간 시점 인덱스\n",
    "\n",
    "    # 중간 시점의 데이터만 추출 (Batch Size만큼의 데이터)\n",
    "    slice_vol = np.sqrt(variances[:, mid_idx])\n",
    "    slice_n = ns[:, mid_idx]\n",
    "    slice_delta = deltas[:, mid_idx]\n",
    "    slice_moneyness = np.log(prices[:, mid_idx] / K_val)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    fig.suptitle(f'Time-Sliced Analysis (at Step {mid_idx}/{steps}, t={T/2:.2f})', fontsize=16, color='darkblue')\n",
    "\n",
    "    # (1) Sliced: Vol vs N (여기가 핵심)\n",
    "    # Lowess 추세선을 사용하여 비선형 관계를 더 부드럽게 봅니다.\n",
    "    sns.regplot(x=slice_vol, y=slice_n, ax=axes[1],\n",
    "                scatter_kws={'alpha':0.3, 'color': 'green'},\n",
    "                line_kws={'color':'darkgreen'}, lowess=True)\n",
    "    axes[1].set_title('Volatility vs VarSwap N (at T/2)')\n",
    "    axes[1].set_xlabel('Volatility (sigma)')\n",
    "    axes[1].set_ylabel('VarSwap Notional')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    # (2) Sliced: Vol vs Delta\n",
    "    sns.regplot(x=slice_vol, y=slice_delta, ax=axes[0],\n",
    "                scatter_kws={'alpha':0.3, 'color': 'purple'},\n",
    "                line_kws={'color':'indigo'}, order=2)\n",
    "    axes[0].set_title('Volatility vs Stock Delta (at T/2)')\n",
    "    axes[0].set_xlabel('Volatility (sigma)')\n",
    "    axes[0].set_ylabel('Hedge Ratio (Delta)')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # (3) Sliced: Moneyness vs Delta\n",
    "    sns.regplot(x=slice_moneyness, y=slice_delta, ax=axes[2],\n",
    "                scatter_kws={'alpha':0.3, 'color': 'orange'},\n",
    "                line_kws={'color':'brown'}, order=3)\n",
    "    axes[2].set_title('Moneyness vs Delta (at T/2)')\n",
    "    axes[2].set_xlabel('Log Moneyness')\n",
    "    axes[2].set_ylabel('Hedge Ratio (Delta)')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ==========================================================\n",
    "    # 3. [Alpha] P&L Distribution (성능 증명)\n",
    "    # ==========================================================\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(pnls, bins=50, kde=True, color='blue', stat='density', label='Deep Hedging P&L')\n",
    "\n",
    "    plt.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "    mean_val = np.mean(pnls)\n",
    "    std_val = np.std(pnls)\n",
    "    cvar_val = np.sort(pnls)[:int(len(pnls)*0.05)].mean()\n",
    "\n",
    "    plt.axvline(x=cvar_val, color='red', linestyle=':', label=f'CVaR (5%): {cvar_val:.4f}')\n",
    "    plt.title(f'Final P&L Distribution\\nMean: {mean_val:.4f} | Std: {std_val:.4f} | CVaR: {cvar_val:.4f}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # ==========================================================\n",
    "    # 4. [Alpha] Strategy Heatmap (Aggregate)\n",
    "    # ==========================================================\n",
    "    df_map = pd.DataFrame({\n",
    "        'Moneyness': flat_moneyness[sample_mask],\n",
    "        'Volatility': flat_vols[sample_mask],\n",
    "        'VarSwap_N': flat_ns[sample_mask]\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sc = plt.scatter(df_map['Moneyness'], df_map['Volatility'], c=df_map['VarSwap_N'],\n",
    "                     cmap='coolwarm', alpha=0.7, s=20)\n",
    "    plt.colorbar(sc, label='VarSwap Notional Position')\n",
    "    plt.title('Strategy Heatmap: When does the model buy/sell VarSwap?')\n",
    "    plt.xlabel('Log Moneyness (ln S/K)')\n",
    "    plt.ylabel('Volatility')\n",
    "    plt.axvline(0, color='black', linestyle='--', alpha=0.5)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# --- 실행 코드 ---\n",
    "# 데이터는 Test Loop를 돌리고 난 후의 변수들을 넣으시면 됩니다.\n",
    "# 텐서 상태여도 함수 내부에서 자동으로 numpy로 변환합니다.\n",
    "visualize_deep_hedging_results(\n",
    "    prices_test[:,:,0],\n",
    "    variances_test[:,:,0], # <- 이거 test loop 전에 저장해둔 변동성 path\n",
    "    deltas_test,\n",
    "    var_swap_ns_test,\n",
    "    final_pnl_test,\n",
    "    T, dt, K\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9UF88nkwrVm"
   },
   "source": [
    "# '4) Time-GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otw72khOwvTi"
   },
   "source": [
    "## Time-GAN Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06Fd_I6IxdWo"
   },
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNiIU-WSDJoF"
   },
   "outputs": [],
   "source": [
    "#======================================================\n",
    "# Heston\n",
    "#======================================================\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class HestonDataset(Dataset):\n",
    "    def __init__(self, n_paths, n_steps, t_maturity,\n",
    "                 mu, kappa, theta, xi, rho, v_0, s_0, device='cpu'):\n",
    "\n",
    "        # 1. 작성자님의 함수로 Raw Data 생성\n",
    "        S_paths, v_paths = generate_heston(\n",
    "            n_paths, n_steps, t_maturity,\n",
    "            mu, kappa, theta, xi, rho, v_0, s_0, device\n",
    "        )\n",
    "        # S_paths shape: (N, Steps+1, 1)\n",
    "        # v_paths shape: (N, Steps+1, 1)\n",
    "\n",
    "        # 2. 두 데이터를 하나로 합치기 (Concatenate) -> Feature=2\n",
    "        # 결과 Shape: (N, Steps+1, 2)\n",
    "        # [:, :, 0]은 주가, [:, :, 1]은 변동성\n",
    "        self.data = torch.cat([S_paths, v_paths], dim=2)\n",
    "\n",
    "        # 3. MinMax Normalization (Robust Version)\n",
    "        # (Batch, Time, Feature) -> (Batch * Time, Feature)로 펼칩니다.\n",
    "        # 이렇게 하면 배치나 시간 차원을 신경 쓸 필요 없이 Feature별로 통계량을 낼 수 있습니다.\n",
    "        flat_data = self.data.reshape(-1, self.data.shape[-1])\n",
    "\n",
    "        # dim=0은 이제 (Batch * Time) 축이 됩니다.\n",
    "        self.min_val = flat_data.min(dim=0)[0] # 결과 Shape: (2,)\n",
    "        self.max_val = flat_data.max(dim=0)[0] # 결과 Shape: (2,)\n",
    "\n",
    "        # Broadcasting을 위해 차원 맞춰주기 (1, 1, 2)\n",
    "        # 이렇게 해두면 나중에 뺄셈할 때 에러 날 일이 없습니다.\n",
    "        self.min_val = self.min_val.view(1, 1, -1)\n",
    "        self.max_val = self.max_val.view(1, 1, -1)\n",
    "\n",
    "        # 0으로 나누기 방지\n",
    "        self.scale = self.max_val - self.min_val\n",
    "        self.scale[self.scale == 0] = 1.0\n",
    "\n",
    "        # 정규화 수행\n",
    "        self.normalized_data = (self.data - self.min_val) / self.scale\n",
    "\n",
    "        # NaN 체크 (Heston 모델의 고질병)\n",
    "        if torch.isnan(self.normalized_data).any():\n",
    "            print(\"🚨 WARNING: Data contains NaN! Check generation parameters (Negative Volatility?)\")\n",
    "\n",
    "        print(f\"Data Prepared! Shape: {self.normalized_data.shape}\")\n",
    "        # view로 차원을 (1,1,2)로 바꿨으니 출력할 때는 다시 flatten해서 보여줍니다\n",
    "        print(f\"Feature 0 (Price) Range: {self.min_val[0,0,0]:.2f} ~ {self.max_val[0,0,0]:.2f}\")\n",
    "        print(f\"Feature 1 (Vol) Range: {self.min_val[0,0,1]:.4f} ~ {self.max_val[0,0,1]:.4f}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.normalized_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.normalized_data[idx]\n",
    "\n",
    "    # 나중에 GAN이 만든 가짜 데이터(0~1)를 다시 원래 scale로 돌려놓을 때 사용\n",
    "    def inverse_transform(self, normalized_data):\n",
    "        return normalized_data * self.scale + self.min_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5J0PJ3y6_JF"
   },
   "source": [
    "### Phase Functions\n",
    "\n",
    "not included in the head class(Time-GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fHNROfUq6-Lx"
   },
   "outputs": [],
   "source": [
    "#======================================================\n",
    "# Phase 1: Optimizing the E & R\n",
    "#======================================================\n",
    "#import itertools\n",
    "\n",
    "def train_phase1_autoencoder(model, dataloader, config):\n",
    "    \"\"\"\n",
    "    Phase 1: Embedder & Recovery 학습 함수\n",
    "    \"\"\"\n",
    "    # 1. Optimizer 설정\n",
    "    # Embedder와 Recovery의 파라미터만 학습 대상입니다.\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "        list(model.embedder.parameters()) + list(model.recovery.parameters()),\n",
    "        #itertools.chain(model.embedder.parameters(),\n",
    "        #                 model.recovery.parameters())\n",
    "        #itertools.chain() : 리스트 새로 제작 안하고 그냥 torch가 읽을 때 둘이 함께 읽게 하는 도구\n",
    "        lr=0.001\n",
    "    )\n",
    "\n",
    "    criterion = nn.L1Loss() # 복원 오차 (Reconstruction Loss)\n",
    "\n",
    "    print(\"Start Embedding Network Training (Phase 1)\")\n",
    "\n",
    "    for epoch in range(config['n_epochs_phase1']):\n",
    "        for batch_idx, X in enumerate(dataloader):\n",
    "            # X shape: (Batch, Seq, Features)\n",
    "            X = X.to(config['device']).float()\n",
    "\n",
    "            # --- Forward Pass ---\n",
    "            # 1. 데이터를 잠재 공간으로 압축 (H)\n",
    "            H = model.embedder(X)\n",
    "\n",
    "            # 2. 잠재 공간에서 다시 데이터로 복원 (X_tilde)\n",
    "            X_tilde = model.recovery(H)\n",
    "\n",
    "            # 3. Loss 계산 (원본 vs 복원본)\n",
    "            loss = 100 * criterion(X, X_tilde)\n",
    "\n",
    "            # --- Backward Pass ---\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 로그 출력 (10 Epoch 마다)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"[Epoch {epoch+1}/{config['n_epochs_phase1']}] Phase 1 Loss: {loss.item():.6f}\")\n",
    "\n",
    "    print(\"Phase 1 Training Finished!\")\n",
    "    # 학습된 모델 반환\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yr5x1Q3mBxOa"
   },
   "outputs": [],
   "source": [
    "#======================================================\n",
    "# Phase 2: Optimizing the S\n",
    "#=====================================================\n",
    "\n",
    "def train_phase2_supervisor(model, dataloader, config):\n",
    "    \"\"\"\n",
    "    Phase 2: Supervisor 학습 함수\n",
    "    (잠재 공간 H 안에서의 시간적 인과관계 학습)\n",
    "    \"\"\"\n",
    "    # 1. Optimizer 설정\n",
    "    # 오직 Supervisor만 학습합니다. (Embedder는 이미 Phase 1에서 학습된 상태)\n",
    "    optimizer = optim.Adam(model.supervisor.parameters(), lr=0.001)\n",
    "\n",
    "    criterion = nn.L1Loss()\n",
    "\n",
    "    print(\"Start Supervisor Training (Phase 2)\")\n",
    "\n",
    "    # Embedder는 학습하지 않으므로 평가 모드로 전환 (선택사항이나 권장)\n",
    "    model.embedder.eval()\n",
    "    model.supervisor.train()\n",
    "\n",
    "    for epoch in range(config['n_epochs_phase2']):\n",
    "        for batch_idx, X in enumerate(dataloader):\n",
    "            # X shape: (Batch, Seq, Features)\n",
    "            X = X.to(config['device']).float()\n",
    "\n",
    "            # --- Forward Pass ---\n",
    "\n",
    "            # 1. Embedder를 통해 '정답 잠재 벡터(H)'를 얻습니다.\n",
    "            # 중요: Embedder의 웨이트는 업데이트하면 안 되므로 no_grad() 사용\n",
    "            with torch.no_grad():\n",
    "                H = model.embedder(X)\n",
    "\n",
    "            # 2. Supervisor가 H를 보고 흐름을 예측합니다.\n",
    "            # H_hat_super: Supervisor가 예측한 잠재 벡터 시퀀스\n",
    "            H_hat_super = model.supervisor(H)\n",
    "\n",
    "            # 3. Loss 계산 (Time-Shifted Prediction)\n",
    "            # Supervisor의 출력(t)이 실제 다음 스텝(t+1)과 같아져야 함\n",
    "            # 예측값: 0 ~ (마지막-1) 시점의 출력 -> (1 ~ 마지막)을 예측한 것\n",
    "            # 정답값: 1 ~ 마지막 시점의 실제 H\n",
    "            loss = 100 * criterion(H_hat_super[:, :-1, :], H[:, 1:, :])\n",
    "\n",
    "            # --- Backward Pass ---\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 로그 출력\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"[Epoch {epoch+1}/{config['n_epochs_phase2']}] Phase 2 Loss: {loss.item():.6f}\")\n",
    "\n",
    "    print(\"Phase 2 Training Finished!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XQraxdWE_PIy"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def train_phase3_joint(model, dataloader, config_GAN, config_phase3):\n",
    "    \"\"\"\n",
    "    Phase 3: Joint Training\n",
    "    목표: Generator가 Supervisor의 시간 흐름을 따르면서,\n",
    "          Discriminator를 속일 수 있는 데이터를 만들도록 학습.\n",
    "          (동시에 Embedder/Recovery는 흔들리지 않게 잡아줌)\n",
    "    \"\"\"\n",
    "    # --- 1. Optimizer 분리 (G팀: GS/ER vs D팀) ---\n",
    "\n",
    "    # G팀\n",
    "    # 이들은 'Total Loss'를 최소화하기 위해 한배를 탔습니다.\n",
    "    optimizer_G_GS = optim.Adam(\n",
    "        itertools.chain(\n",
    "            model.generator.parameters(),\n",
    "            model.supervisor.parameters()\n",
    "        ),\n",
    "        lr=config_phase3['lr_G']\n",
    "    )\n",
    "\n",
    "    optimizer_G_ER = optim.Adam(\n",
    "        itertools.chain(\n",
    "            model.embedder.parameters(),\n",
    "            model.recovery.parameters(),\n",
    "        ),\n",
    "        lr=config_phase3['lr_G']\n",
    "    )\n",
    "\n",
    "\n",
    "    # [Lambda Weights: 작성자님 설계 반영]\n",
    "    # lambda_sup: Anchor 역할 (Real Data의 물리 법칙 고수) -> 높게 설정\n",
    "    # lambda_adv: G와 D의 균형을 맞추며 S, E를 미세 조정 -> 기본 1\n",
    "    lambda_recon = config_phase3['lambda_recon']\n",
    "    lambda_sup   = config_phase3['lambda_sup']\n",
    "    lambda_adv   = config_phase3['lambda_adv']\n",
    "\n",
    "    # D팀: Discriminator (독고다이)\n",
    "    optimizer_D = optim.Adam(model.discriminator.parameters(), lr=config_phase3['lr_D'])\n",
    "\n",
    "    # Loss 함수들\n",
    "    mse_loss = nn.MSELoss() # Reconstruction, Supervised 용\n",
    "    bce_loss = nn.BCELoss() # Adversarial (Binary Cross Entropy) 용\n",
    "\n",
    "    print(\"Start Joint Training (Phase 3)\")\n",
    "\n",
    "    scheduler_G_GS = torch.optim.lr_scheduler.StepLR(optimizer_G_GS, step_size=400, gamma=0.5)\n",
    "    scheduler_G_ER = torch.optim.lr_scheduler.StepLR(optimizer_G_ER, step_size=400, gamma=0.5)\n",
    "    scheduler_D = torch.optim.lr_scheduler.StepLR(optimizer_D, step_size=400, gamma=0.5)\n",
    "\n",
    "    for epoch in range(config_GAN['n_epochs_phase3']):\n",
    "        for batch_idx, X in enumerate(dataloader):\n",
    "\n",
    "            # =======================================================\n",
    "            # [Step 3] Generator 팀 학습 (G의 턴)\n",
    "            # =======================================================\n",
    "            # G팀의 목표: D를 속이고(Adv), 원본 복구하고(Recon), 흐름 맞추기(Supervised)\n",
    "\n",
    "            model.zero_grad()\n",
    "            for _ in range(config_phase3['epochs_G']):\n",
    "                # X shape: (Batch, Seq, Feature=2)\n",
    "                X = X.to(config_GAN['device']).float()\n",
    "\n",
    "                #--------------------------------------------\n",
    "                # G_GS: Generator & Supervisor\n",
    "                #--------------------------------------------\n",
    "\n",
    "                # 1. loss_G_adversarial: Adversarial Loss (D를 속여라: 가짜 -> 1)\n",
    "                # 이번엔 detach 없이! 그래야 G까지 미분이 전달됨.\n",
    "                # [수정 후 - 작성자님 제안]\n",
    "                # X와 동일한 크기, 장치, 타입으로 노이즈 생성 (훨씬 안전함)\n",
    "                Z = torch.randn_like(X)\n",
    "                E_hat = model.generator(Z)\n",
    "                H_hat_fake = model.supervisor(E_hat)\n",
    "\n",
    "                Y_fake = model.discriminator(H_hat_fake)\n",
    "                Y_fake_e = model.discriminator(E_hat)\n",
    "\n",
    "                loss_G_adversarial_fake = bce_loss(Y_fake, torch.ones_like(Y_fake))\n",
    "                loss_G_adversarial_fake_e = bce_loss(Y_fake_e, torch.ones_like(Y_fake_e))\n",
    "\n",
    "                loss_G_adversarial = loss_G_adversarial_fake + config_phase3['gamma_G'] * loss_G_adversarial_fake_e\n",
    "\n",
    "                # 2. loss_S_real: Supervised Loss (시간 흐름을 지켜라)\n",
    "                # H_hat의 t 시점으로 t+1 시점 예측이 잘 되는지 (Slicing 사용)\n",
    "                H = model.embedder(X)\n",
    "                H_hat_real = model.supervisor(H)\n",
    "\n",
    "                loss_S_real =  torch.sqrt(mse_loss(H_hat_real[:, :-1, :], H[:, 1:, :]) + 1e-6)\n",
    "                loss_S = config_phase3['coef_GS_S'] * loss_S_real\n",
    "\n",
    "                # 3. loss_moment: 배치(Batch)를 압축해서 '평균 흐름'과 '변동성 흐름' 뽑기\n",
    "                # dim=0은 배치 차원(128개)을 퉁친다는 뜻입니다.\n",
    "\n",
    "                # (1) 진짜(Real)의 통계\n",
    "                mu_real = X.mean(dim=0)   # 평균 (Mean) -> V2용\n",
    "                std_real = X.std(dim=0)   # 표준편차 (Std) -> V1용\n",
    "\n",
    "                # (2) 가짜(Fake)의 통계\n",
    "                X_hat = model.recovery(H_hat_fake)\n",
    "\n",
    "                mu_fake = X_hat.mean(dim=0)\n",
    "                std_fake = X_hat.std(dim=0)\n",
    "\n",
    "                # Loss 계산 (L1 Distance: 차이의 절대값의 평균)\n",
    "                # V1: 표준편차(Volatility)가 얼마나 다른가?\n",
    "                loss_V1 = torch.mean(torch.abs(std_real - std_fake))\n",
    "\n",
    "                # V2: 평균(Trend/Drift)이 얼마나 다른가?\n",
    "                loss_V2 = torch.mean(torch.abs(mu_real - mu_fake))\n",
    "\n",
    "                # 최종 합산\n",
    "                loss_V = loss_V1 + loss_V2\n",
    "                loss_Moment = config_phase3['coef_moment'] * loss_V\n",
    "\n",
    "                # Total G_GS Loss\n",
    "\n",
    "                loss_G_GS_total = loss_G_adversarial + loss_S + loss_Moment\n",
    "\n",
    "                optimizer_G_GS.zero_grad()\n",
    "                loss_G_GS_total.backward()\n",
    "                optimizer_G_GS.step()\n",
    "\n",
    "                #--------------------------------------------\n",
    "                # G_ER: Embedder & Recover\n",
    "                #--------------------------------------------\n",
    "                # 1. loss_R: Reconstruction Error\n",
    "                # G_GS.STEP()하면 앞 계산 결과 증발되어서 다시 해야됨.\n",
    "                H = model.embedder(X)\n",
    "                X_tilde = model.recovery(H)\n",
    "\n",
    "                loss_R = 10 * torch.sqrt(mse_loss(X, X_tilde) + 1e-6)\n",
    "\n",
    "                # 2. loss_S: Supervised Feedback for E\n",
    "                # Embedder가 S가 예측하기 좋은 H를 만들도록 유도\n",
    "                H_hat_real_new = model.supervisor(H)\n",
    "                loss_S_real_new = torch.sqrt(mse_loss(H_hat_real_new[:, :-1, :], H[:, 1:, :]) + 1e-6)\n",
    "                loss_S_for_ER = 0.1 * loss_S_real_new\n",
    "\n",
    "                # Total G_GS Loss\n",
    "\n",
    "                loss_G_ER_total = loss_R + loss_S_for_ER\n",
    "\n",
    "                optimizer_G_ER.zero_grad()\n",
    "                loss_G_ER_total.backward()\n",
    "                optimizer_G_ER.step()\n",
    "\n",
    "\n",
    "            # =======================================================\n",
    "            # [Step 3] Discriminator 학습 (D의 턴)\n",
    "            # =======================================================\n",
    "            # D의 목표: 진짜(H)는 1, 가짜(H_hat)는 0으로 구분하기\n",
    "            for _ in range(config_phase3['epochs_D']):\n",
    "                # X shape: (Batch, Seq, Feature=2)\n",
    "                X = X.to(config_GAN['device']).float()\n",
    "                Z = torch.randn_like(X)\n",
    "\n",
    "                # Real Path (Anchor용)\n",
    "                H = model.embedder(X)\n",
    "                H_hat_real = model.supervisor(H)\n",
    "\n",
    "                E_hat = model.generator(Z)\n",
    "                H_hat_fake = model.supervisor(E_hat)\n",
    "\n",
    "                # 중요: G팀으로 그라디언트가 역류하지 않게 .detach() 필수!\n",
    "                Y_real = model.discriminator(H.detach())\n",
    "                Y_fake = model.discriminator(H_hat_fake.detach())\n",
    "                Y_fake_e = model.discriminator(E_hat.detach())\n",
    "\n",
    "                loss_D_real = bce_loss(Y_real, torch.ones_like(Y_real))\n",
    "                loss_D_fake = bce_loss(Y_fake, torch.zeros_like(Y_fake))\n",
    "                loss_D_fake_e = bce_loss(Y_fake_e, torch.zeros_like(Y_fake_e))\n",
    "\n",
    "                loss_D = loss_D_fake + loss_D_real + config_phase3['gamma_D'] * loss_D_fake_e\n",
    "\n",
    "                optimizer_D.zero_grad()\n",
    "                loss_D.backward()\n",
    "                optimizer_D.step()\n",
    "\n",
    "        scheduler_G_GS.step()\n",
    "        scheduler_G_ER.step()\n",
    "        scheduler_D.step()\n",
    "\n",
    "        # 로그 출력\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"-\"*50)\n",
    "            print(f\"[Epoch {epoch+1}/{config_GAN['n_epochs_phase3']}]\\n\")\n",
    "            print(f\"\\n\")\n",
    "            print(f\"G_GS_Total: {loss_G_GS_total.item():.4f}\\n\"\n",
    "                  f\"Decomposed G_GS : (G_Adv: {loss_G_adversarial.item():.7f}, Sup: {loss_S.item():.7f}, Moment: {loss_Moment.item():.7f})\\n\")\n",
    "\n",
    "            print(f\"G_ER_Total: {loss_G_ER_total.item():.4f}\\n\"\n",
    "                  f\"Decomposed G_ER : (Recon : {loss_R.item():.7f}, Sup(descaled): {loss_S_for_ER.item():.7f})\\n\")\n",
    "\n",
    "            print(f\"D_Loss: {loss_D.item():.4f}\\n\"\n",
    "                  f\"Decomposed D : (D_real: {loss_D_real.item():.7f}, D_fake: {loss_D_fake:.7f}, D_fake_e(with gamma): {config_phase3['gamma_D'] * loss_D_fake_e.item():.7f})\\n\")\n",
    "            print(f\"-\"*50,\"\\n\")\n",
    "\n",
    "\n",
    "    print(\"Joint Training Finished!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUoEzf8jMi0I"
   },
   "source": [
    "### Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJB-yqX1MqzV"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn.init as init\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. Embedder: 원본 데이터(Feature) -> 잠재 공간(Latent)\n",
    "# ==============================================================================\n",
    "class Embedder(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Embedder, self).__init__()\n",
    "        self.feature_dim = args.feature_dim\n",
    "        self.hidden_dim = args.hidden_dim\n",
    "        self.num_layers = args.num_layers\n",
    "\n",
    "        # 입력(2개) -> 은닉층(24개)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=self.feature_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.sigmoid = nn.Sigmoid() # 0~1 사이 값으로 정규화 (Latent Space)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        # 1. Linear Layer: Xavier (Glorot) Initialization\n",
    "        if isinstance(m, nn.Linear):\n",
    "            init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                init.constant_(m.bias, 0)\n",
    "\n",
    "        # 2. GRU Layer: Orthogonal Initialization (시계열 필수!)\n",
    "        elif isinstance(m, nn.GRU):\n",
    "            for name, param in m.named_parameters():\n",
    "                if 'weight_ih' in name:\n",
    "                    init.xavier_uniform_(param.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    init.orthogonal_(param.data) # 여기가 핵심\n",
    "                elif 'bias' in name:\n",
    "                    init.constant_(param.data, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, seq, feature]\n",
    "        output, _ = self.gru(x)\n",
    "        output = self.fc(output)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. Recovery: 잠재 공간(Latent) -> 원본 데이터 복원(Feature)\n",
    "# ==============================================================================\n",
    "class Recovery(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Recovery, self).__init__()\n",
    "        self.feature_dim = args.feature_dim\n",
    "        self.hidden_dim = args.hidden_dim\n",
    "        self.num_layers = args.num_layers\n",
    "\n",
    "        # 은닉층(24개) -> 원본(2개)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=self.hidden_dim,\n",
    "            hidden_size=self.feature_dim, # GRU 출력을 바로 Feature 크기로\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(self.feature_dim, self.feature_dim) # 한번 더 정제\n",
    "        self.sigmoid = nn.Sigmoid() # 원본 데이터가 MinMax(0~1)이므로 Sigmoid 사용\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        # E/R에서 썼던 그 함수 그대로 복사\n",
    "        if isinstance(m, nn.Linear):\n",
    "            init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.GRU):\n",
    "            for name, param in m.named_parameters():\n",
    "                if 'weight_ih' in name:\n",
    "                    init.xavier_uniform_(param.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    init.orthogonal_(param.data)\n",
    "                elif 'bias' in name:\n",
    "                    init.constant_(param.data, 0)\n",
    "\n",
    "    def forward(self, h):\n",
    "        output, _ = self.gru(h)\n",
    "        output = self.fc(output)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. Generator: 노이즈(Noise) -> 가짜 잠재 벡터(Fake Latent)\n",
    "# ==============================================================================\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Generator, self).__init__()\n",
    "        self.feature_dim = args.feature_dim\n",
    "        self.hidden_dim = args.hidden_dim\n",
    "        self.num_layers = args.num_layers\n",
    "\n",
    "        # 노이즈(2개) -> 은닉층(24개)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=self.feature_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        # E/R에서 썼던 그 함수 그대로 복사\n",
    "        if isinstance(m, nn.Linear):\n",
    "            init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.GRU):\n",
    "            for name, param in m.named_parameters():\n",
    "                if 'weight_ih' in name:\n",
    "                    init.xavier_uniform_(param.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    init.orthogonal_(param.data)\n",
    "                elif 'bias' in name:\n",
    "                    init.constant_(param.data, 0)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # z: [batch, seq, feature_dim] (노이즈)\n",
    "        output, _ = self.gru(z)\n",
    "        output = self.fc(output)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. Supervisor: 잠재 벡터(t) -> 다음 시점 잠재 벡터(t+1) (시간 흐름 교정)\n",
    "# ==============================================================================\n",
    "class Supervisor(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Supervisor, self).__init__()\n",
    "        self.hidden_dim = args.hidden_dim\n",
    "        self.num_layers = args.num_layers # Supervisor는 보통 레이어를 조금 적게 쓰기도 함 (여기선 동일하게)\n",
    "\n",
    "        # Latent(24개) -> Latent(24개)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=self.hidden_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.num_layers - 1, # 통상적으로 G보다 한 겹 얇게 만듦 (선택사항)\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        # E/R에서 썼던 그 함수 그대로 복사\n",
    "        if isinstance(m, nn.Linear):\n",
    "            init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.GRU):\n",
    "            for name, param in m.named_parameters():\n",
    "                if 'weight_ih' in name:\n",
    "                    init.xavier_uniform_(param.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    init.orthogonal_(param.data)\n",
    "                elif 'bias' in name:\n",
    "                    init.constant_(param.data, 0)\n",
    "\n",
    "    def forward(self, h):\n",
    "        output, _ = self.gru(h)\n",
    "        output = self.fc(output)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. Discriminator: 잠재 벡터 -> 진짜/가짜 판별\n",
    "# ==============================================================================\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.hidden_dim = args.hidden_dim\n",
    "        self.num_layers = args.num_layers\n",
    "\n",
    "        # Latent(24개) -> Scalar(1개, Real/Fake)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=self.hidden_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        # 시퀀스의 각 시점마다 진위 여부를 판단함 (Seq2Seq Discriminator)\n",
    "        self.fc = nn.Linear(self.hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid() # BCELoss를 쓰기 위해 확률값(0~1) 배출\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        # E/R에서 썼던 그 함수 그대로 복사\n",
    "        if isinstance(m, nn.Linear):\n",
    "            init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.GRU):\n",
    "            for name, param in m.named_parameters():\n",
    "                if 'weight_ih' in name:\n",
    "                    init.xavier_uniform_(param.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    init.orthogonal_(param.data)\n",
    "                elif 'bias' in name:\n",
    "                    init.constant_(param.data, 0)\n",
    "\n",
    "    def forward(self, h):\n",
    "        output, _ = self.gru(h)\n",
    "        output = self.fc(output)\n",
    "        output = self.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ST8k6-kLOZ1g"
   },
   "source": [
    "### Head Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7R_CRTDOZJv"
   },
   "outputs": [],
   "source": [
    "class TimeGAN(nn.Module):\n",
    "    \"\"\"\n",
    "    TimeGAN 전체 모델 조립\n",
    "    \"\"\"\n",
    "    def __init__(self, args):\n",
    "        super(TimeGAN, self).__init__()\n",
    "        self.args = args\n",
    "        self.device = args.device\n",
    "        self.feature_dim = args.feature_dim\n",
    "        self.hidden_dim = args.hidden_dim\n",
    "\n",
    "        # 1. 부품 조립 (Instantiation)\n",
    "        self.embedder = Embedder(args).to(self.device)\n",
    "        self.recovery = Recovery(args).to(self.device)\n",
    "        self.generator = Generator(args).to(self.device)\n",
    "        self.supervisor = Supervisor(args).to(self.device)\n",
    "        self.discriminator = Discriminator(args).to(self.device)\n",
    "\n",
    "    def forward(self, z, max_seq_len):\n",
    "        \"\"\"\n",
    "        Inference(생성)용 함수:\n",
    "        Noise -> Generator -> Supervisor -> Recovery -> Fake Data\n",
    "        \"\"\"\n",
    "        # 1. Generator: Noise(Z) -> Rough Latent(E_hat)\n",
    "        e_hat = self.generator(z)\n",
    "\n",
    "        # 2. Supervisor: Rough Latent -> Refined Latent(H_hat)\n",
    "        h_hat = self.supervisor(e_hat)\n",
    "\n",
    "        # 3. Recovery: Refined Latent -> Fake Data(X_hat)\n",
    "        x_hat = self.recovery(h_hat)\n",
    "\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJeZWxUvwy79"
   },
   "source": [
    "## Time-GAN Learnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUPIm3_JwltD"
   },
   "outputs": [],
   "source": [
    "# --- 하이퍼 파라미터 설정 ---\n",
    "\n",
    "params, v_t = garch_heston_analysis(df_train)\n",
    "print(f'\\nEstimated Hyperparameters of Heston: {params}\\n')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Heston 파라미터 (일반적인 시장 상황 가정)\n",
    "config_heston = {\n",
    "    'n_paths': 5000,      # 데이터 개수 (많을수록 좋음)\n",
    "    'n_steps': N,        # 시퀀스 길이 (Seq_Len)\n",
    "    't_maturity': 30/252,    # 1년\n",
    "    'mu': torch.tensor(params['mu_simple']),           # Drift\n",
    "    'kappa': torch.tensor(params['kappa']),         # Mean reversion speed\n",
    "    'theta': torch.tensor(params['theta']),        # Long-term variance\n",
    "    'xi': torch.tensor(params['xi']),            # Vol of Vol\n",
    "    'rho': torch.tensor(params['rho']),          # Correlation (주가와 변동성은 보통 음의 상관관계)\n",
    "    'v_0': torch.tensor(params['v0']),          # 초기 분산\n",
    "    's_0': torch.tensor(S_0).float(),         # 초기 주가\n",
    "    'device': device\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OVdFSo5YVwBT"
   },
   "outputs": [],
   "source": [
    "\n",
    "config_GAN = {\n",
    "    'device': device,\n",
    "    'feature_dim': 2,      # Price, Vol\n",
    "    'hidden_dim': 64,      # Latent Dimension (논문 추천: Feature x 4 이상)\n",
    "    'num_layers': 4,       # GRU Layer 개수\n",
    "    'padding_value': 0,\n",
    "    'n_epochs_phase1': 1000, # Autoencoder (충분히 학습 필요)\n",
    "    'n_epochs_phase2': 1000, # Supervisor (물리 법칙 각인)\n",
    "    'n_epochs_phase3': 1000  # Joint Training (본 게임)\n",
    "}\n",
    "\n",
    "config_for_phase3 = {\n",
    "    'lambda_recon': 1,\n",
    "    'lambda_sup': 1,\n",
    "    'lambda_adv': 1,\n",
    "    'epochs_D': 1,\n",
    "    'epochs_G': 2,\n",
    "    'gamma_D': 1.0,\n",
    "    'gamma_G': 1.0,\n",
    "    'lr_D' : 0.001,\n",
    "    'lr_G' : 0.001,\n",
    "    'coef_GS_S' : 200,\n",
    "    'coef_moment' : 100\n",
    "}\n",
    "\n",
    "\n",
    "args = type('Args', (), {\n",
    "    'device': config_GAN['device'],\n",
    "    'feature_dim': config_GAN['feature_dim'],\n",
    "    'hidden_dim': config_GAN['hidden_dim'],\n",
    "    'num_layers': config_GAN['num_layers'],\n",
    "    'padding_value': config_GAN['padding_value']\n",
    "})()\n",
    "\n",
    "model = TimeGAN(args).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qtRrTEPPw9je"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 생성\n",
    "dataset = HestonDataset(**config_heston)\n",
    "\n",
    "# DataLoader 생성 (Batch 단위로 쪼개기)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# 확인 사살\n",
    "sample_batch = next(iter(dataloader)) #iter은 Dataloader로 묶여있는 애들을 잡겠다 선언, next는 그 중 첫번째 배치를 잡으란 뜻\n",
    "print(f\"Sample Batch Shape: {sample_batch.shape}\")\n",
    "# 예상 출력: torch.Size([128, 31, 2]) -> (Batch, Seq_Len+1, Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w1aE_WPp0BPD"
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. Training Pipeline (Phase 1 -> 2 -> 3)\n",
    "# ==========================================\n",
    "\n",
    "# ==========================================\n",
    "# [Phase 1] Embedder & Recovery\n",
    "# ==========================================\n",
    "model.train()\n",
    "model = train_phase1_autoencoder(model, dataloader, config_GAN)\n",
    "\n",
    "# 1. 파일명 설정 (요청하신 대로 변경)\n",
    "save_time_gan_phase1 = 'time_gan_phase1_best_weights.pth'\n",
    "\n",
    "# 2. 여러 상태(State)를 딕셔너리로 묶기\n",
    "# 리스트보다 이렇게 이름을 붙여 저장하는 게 훨씬 안전합니다.\n",
    "checkpoint_phase1 = {\n",
    "    'embedder_state_dict': model.embedder.state_dict(),\n",
    "    'recovery_state_dict': model.recovery.state_dict(),\n",
    "    'config': config_GAN\n",
    "}\n",
    "\n",
    "# 3. 파일 저장\n",
    "torch.save(checkpoint_phase1, save_time_gan_phase1)\n",
    "print(f\"가중치가 {save_time_gan_phase1}에 통합 저장되었습니다.\")\n",
    "\n",
    "# 4. 파일 다운로드\n",
    "files.download(save_time_gan_phase1)\n",
    "\n",
    "# ==========================================\n",
    "# [Phase 2] Supervisor\n",
    "# ==========================================\n",
    "\n",
    "model = train_phase2_supervisor(model, dataloader, config_GAN)\n",
    "\n",
    "save_time_gan_phase2 = 'time_gan_phase2_best_weights.pth'\n",
    "checkpoint_phase2 = {\n",
    "    'supervisor_state_dict': model.supervisor.state_dict(),\n",
    "    'config': config_GAN\n",
    "}\n",
    "torch.save(checkpoint_phase2, save_time_gan_phase2)\n",
    "print(f\"가중치가 {save_time_gan_phase2}에 저장되었습니다.\")\n",
    "\n",
    "files.download(save_time_gan_phase2)\n",
    "\n",
    "# ==========================================\n",
    "# [Phase 3] Joint Training\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "model.train()\n",
    "model = train_phase3_joint(model, dataloader, config_GAN, config_for_phase3)\n",
    "\n",
    "# 1. 파일명 설정 (Phase 3 전용)\n",
    "save_time_gan_phase3 = 'time_gan_phase3_best_weights.pth'\n",
    "\n",
    "checkpoint_phase3 = {\n",
    "    'embedder_state_dict': model.embedder.state_dict(),\n",
    "    'recovery_state_dict': model.recovery.state_dict(),\n",
    "    'supervisor_state_dict': model.supervisor.state_dict(),\n",
    "    'generator_state_dict': model.generator.state_dict(),\n",
    "    'discriminator_state_dict': model.discriminator.state_dict(),\n",
    "    'config_gan': config_GAN,\n",
    "    'config_for_phase3': config_for_phase3\n",
    "}\n",
    "\n",
    "\n",
    "torch.save(checkpoint_phase3, save_time_gan_phase3)\n",
    "print(f\"최종 통합 가중치가 {save_time_gan_phase3}에 저장되었습니다.\")\n",
    "\n",
    "files.download(save_time_gan_phase3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Oi5JOA9-ub4"
   },
   "source": [
    "### Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cnGyH42AC5w"
   },
   "outputs": [],
   "source": [
    "model.embedder.load_state_dict(checkpoint_phase1['embedder_state_dict'])\n",
    "model.recovery.load_state_dict(checkpoint_phase1['recovery_state_dict'])\n",
    "model.supervisor.load_state_dict(checkpoint_phase2['supervisor_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQEvcvpx8N67"
   },
   "outputs": [],
   "source": [
    "# From save file\n",
    "\n",
    "load_path = 'time_gan_phase1_best_weights.pth'\n",
    "checkpoint_phase1 = torch.load(load_path, map_location=device)\n",
    "model.embedder.load_state_dict(checkpoint_phase1['embedder_state_dict'])\n",
    "model.recovery.load_state_dict(checkpoint_phase1['recovery_state_dict'])\n",
    "\n",
    "load_path = 'time_gan_phase2_best_weights.pth'\n",
    "checkpoint_phase2 = torch.load(load_path, map_location=device)\n",
    "model.supervisor.load_state_dict(checkpoint_phase2['supervisor_state_dict'])\n",
    "\n",
    "\n",
    "# 3. 모델을 GPU로 보내고 추론 모드로 설정\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"✅ Supervisor 가중치가 성공적으로 로드되었습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z1EO0GeBWnum"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_results(model, dataset, device, n_samples=5):\n",
    "\n",
    "\n",
    "    # 1. 가짜 데이터 생성\n",
    "    # 노이즈 생성 (Z) - 학습 때와 동일한 분포\n",
    "    # 원본 데이터 셋에서 샘플 하나 가져와서 shape 참고\n",
    "    sample_real = dataset[0].unsqueeze(0) # (1, seq_len, 2)\n",
    "    z = torch.randn(n_samples, sample_real.shape[1], sample_real.shape[2]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Generator -> Supervisor -> Recovery 순서로 통과\n",
    "        fake_data_norm = model(z, sample_real.shape[1])\n",
    "        fake_data = dataset.inverse_transform(fake_data_norm).cpu().numpy()\n",
    "\n",
    "    # 2. 진짜 데이터 샘플 추출\n",
    "    real_data_norm = next(iter(DataLoader(dataset, batch_size=n_samples, shuffle=True)))\n",
    "    real_data = dataset.inverse_transform(real_data_norm).cpu().numpy()\n",
    "\n",
    "    # 3. 시각화 (Price & Volatility)\n",
    "    fig, axes = plt.subplots(2, n_samples, figsize=(20, 8))\n",
    "    fig.suptitle('TimeGAN Generation: Real vs Fake (Heston Model)', fontsize=16)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Upper Row: Price (Feature 0)\n",
    "        axes[0, i].plot(real_data[i, :, 0], label='Real Price', color='blue', alpha=0.6)\n",
    "        axes[0, i].plot(fake_data[i, :, 0], label='Fake Price', color='red', linestyle='--')\n",
    "        axes[0, i].set_title(f'Sample {i+1} - Price')\n",
    "        if i == 0: axes[0, i].legend()\n",
    "\n",
    "        # Lower Row: Volatility (Feature 1)\n",
    "        axes[1, i].plot(real_data[i, :, 1], label='Real Vol', color='cyan', alpha=0.6)\n",
    "        axes[1, i].plot(fake_data[i, :, 1], label='Fake Vol', color='magenta', linestyle='--')\n",
    "        axes[1, i].set_title(f'Sample {i+1} - Volatility')\n",
    "        if i == 0: axes[1, i].legend()\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# 실행\n",
    "visualize_results(model, dataset, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sA3nARCBWoBR"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def visualize_phase1_reconstruction(model, dataset, device, n_samples=4):\n",
    "    \"\"\"\n",
    "    X (Original) vs R(E(X)) (Reconstructed) 비교 시각화\n",
    "    \"\"\"\n",
    "    '''\n",
    "    model.embedder.load_state_dict(checkpoint_phase3['embedder_state_dict'])\n",
    "    model.recovery.load_state_dict(checkpoint_phase3['recovery_state_dict'])\n",
    "    '''\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    # 1. 실제 데이터 배치를 하나 가져옴\n",
    "    dataloader = DataLoader(dataset, batch_size=n_samples, shuffle=True)\n",
    "    real_data_norm = next(iter(dataloader)).to(device).float()\n",
    "\n",
    "    # 2. 모델 통과 (Encode -> Decode)\n",
    "    with torch.no_grad():\n",
    "        H = model.embedder(real_data_norm)\n",
    "        recon_data_norm = model.recovery(H)\n",
    "\n",
    "    # 3. 역정규화 (0~1 -> 원래 주가/변동성 스케일)\n",
    "    real_data = dataset.inverse_transform(real_data_norm).cpu().numpy()\n",
    "    recon_data = dataset.inverse_transform(recon_data_norm).cpu().numpy()\n",
    "\n",
    "    # 4. 그리기\n",
    "    fig, axes = plt.subplots(2, n_samples, figsize=(20, 8))\n",
    "    fig.suptitle(f'Phase 1 Check: Autoencoder Reconstruction (Sigmoid Structure)', fontsize=16)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # --- Feature 0: Price ---\n",
    "        ax = axes[0, i]\n",
    "        ax.plot(real_data[i, :, 0], label='Original', color='blue', alpha=0.7)\n",
    "        ax.plot(recon_data[i, :, 0], label='Reconstructed', color='red', linestyle='--')\n",
    "        ax.set_title(f'Sample {i+1}: Price')\n",
    "        if i==0: ax.legend()\n",
    "\n",
    "        # --- Feature 1: Volatility ---\n",
    "        ax = axes[1, i]\n",
    "        ax.plot(real_data[i, :, 1], label='Original', color='cyan', alpha=0.7)\n",
    "        ax.plot(recon_data[i, :, 1], label='Reconstructed', color='magenta', linestyle='--')\n",
    "        ax.set_title(f'Sample {i+1}: Volatility')\n",
    "        if i==0: ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 실행\n",
    "visualize_phase1_reconstruction(model, dataset, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K_LzQK7RAwsP"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def visualize_phase2_supervisor(model, dataset, device, n_samples=4):\n",
    "    \"\"\"\n",
    "    X (Original) vs R(S(E(X))) (Supervised Prediction) 비교 시각화\n",
    "    Supervisor는 t시점의 정보로 t+1시점을 예측하려 하므로,\n",
    "    빨간 선(Supervised)이 파란 선(Original)의 흐름을 한 박자 앞서거나 비슷하게 따라가야 합니다.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.supervisor.eval()\n",
    "\n",
    "\n",
    "    # 1. 실제 데이터 배치를 하나 가져옴\n",
    "    dataloader = DataLoader(dataset, batch_size=n_samples, shuffle=True)\n",
    "    real_data_norm = next(iter(dataloader)).to(device).float()\n",
    "\n",
    "    # 2. 모델 통과 (Encode -> Supervisor -> Decode)\n",
    "    with torch.no_grad():\n",
    "        # A. 원본을 잠재 공간으로 보냄\n",
    "        H = model.embedder(real_data_norm)\n",
    "\n",
    "        # B. Supervisor를 통해 '다음 스텝의 잠재 표현'을 예측\n",
    "        #    (이 과정에서 시간적 역학/Dynamics가 적용됨)\n",
    "        H_hat_supervise = model.supervisor(H)\n",
    "\n",
    "        # C. 예측된 잠재 표현을 다시 원래 차원으로 복원\n",
    "        recon_supervised_norm = model.recovery(H_hat_supervise)\n",
    "\n",
    "    # 3. 역정규화 (0~1 -> 원래 스케일)\n",
    "    real_data = dataset.inverse_transform(real_data_norm).cpu().numpy()\n",
    "    recon_supervised = dataset.inverse_transform(recon_supervised_norm).cpu().numpy()\n",
    "\n",
    "    # 4. 그리기\n",
    "    fig, axes = plt.subplots(2, n_samples, figsize=(20, 8))\n",
    "    fig.suptitle(f'Phase 2 Check: Supervisor Dynamics (X vs Supervisor(X))', fontsize=16)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # --- Feature 0: Price ---\n",
    "        ax = axes[0, i]\n",
    "        ax.plot(real_data[i, :, 0], label='Original (t)', color='blue', alpha=0.7)\n",
    "        # Supervisor 결과는 엄밀히 말하면 t+1 예측이므로 살짝 어긋날 수 있지만,\n",
    "        # 전체적인 Heston Path의 모양(굴곡)을 유지하는지 보는 것이 핵심입니다.\n",
    "        ax.plot(recon_supervised[i, :, 0], label='Supervised (Prediction)', color='red', linestyle='--')\n",
    "        ax.set_title(f'Sample {i+1}: Price Dynamics')\n",
    "        if i==0: ax.legend()\n",
    "\n",
    "        # --- Feature 1: Volatility ---\n",
    "        ax = axes[1, i]\n",
    "        ax.plot(real_data[i, :, 1], label='Original (t)', color='cyan', alpha=0.7)\n",
    "        ax.plot(recon_supervised[i, :, 1], label='Supervised (Prediction)', color='magenta', linestyle='--')\n",
    "        ax.set_title(f'Sample {i+1}: Volatility Dynamics')\n",
    "        if i==0: ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 실행\n",
    "visualize_phase2_supervisor(model, dataset, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IZDzJiJBccQV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN3htOdJLGEwkJSvi8Wq6+5",
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
