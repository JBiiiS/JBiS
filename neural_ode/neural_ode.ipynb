{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0219f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U  finance-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd # pandas 명시적 import 필요\n",
    "import FinanceDataReader as fdr\n",
    "import random\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "from base.base_config import BaseConfig\n",
    "from base.data_process import *\n",
    "from base.loss_functions import MSE_Loss, KLD_Loss\n",
    "\n",
    "from neural_ode_config import NeuralODEConfig\n",
    "from neural_ode_ffn import NeuralODEEncoder, LatentSampler\n",
    "from neural_ode_back import ODEFunc, NeuralODEDecoder\n",
    "from neural_ode_model import NeuralODE\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. 설정 및 장치 초기화\n",
    "# ---------------------------------------------------------\n",
    "config =  NeuralODEConfig(batch_size=64, num_assets=1, steps = 30, num_epochs=1000)\n",
    "\n",
    "# [안전장치] Config에 device가 없으면 여기서 직접 설정\n",
    "if hasattr(config, 'device'):\n",
    "    device = config.device\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Device set to: {device}\")\n",
    "\n",
    "\n",
    "config_dict = config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8654d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df = fdr_data_with_ticker('2010-01-01', '2025-12-31', 'AAPL')\n",
    "\n",
    "price_df = clean_price_data(price_df)\n",
    "\n",
    "ln_price, ln_price_diff = log_data(price_df)\n",
    "\n",
    "ln_price = clean_price_data(ln_price)\n",
    "ln_price_diff = clean_price_data(ln_price_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = To_TensorSet(config)\n",
    "tensor_set = processor.process(ln_price_diff)\n",
    "\n",
    "# [2] 텐서 추출 (BTD 포맷 사용)\n",
    "# NeuralODE 모델은 [Batch, Time, Dim] 입력을 기대하므로 'BTD'를 가져옵니다.\n",
    "train_tensor = processed_data['train']['BTD']  # Shape: [N_train, 30, 500]\n",
    "test_tensor  = processed_data['test']['BTD']   # Shape: [1, 30, 500]\n",
    "\n",
    "# [3] TensorDataset 생성\n",
    "# 입력(x)과 타겟(y)이 같은 Autoencoder 구조이므로, 데이터셋에 (x, x)를 넣거나\n",
    "# 단순히 (x,)만 넣어서 꺼낼 때 활용할 수 있습니다. \n",
    "# 여기서는 가장 일반적인 (x,) 형태로 만듭니다.\n",
    "train_dataset = TensorDataset(train_tensor)\n",
    "test_dataset  = TensorDataset(test_tensor)\n",
    "\n",
    "# [4] DataLoader 생성\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size, # Config에 설정된 배치 크기 (예: 64)\n",
    "    shuffle=True,              # 학습 시 순서를 섞음 (필수)\n",
    "    drop_last=True             # 마지막 배치가 사이즈보다 작으면 버림 (차원 오류 방지)\n",
    ")\n",
    "\n",
    "# 테스트 로더는 보통 셔플하지 않고, 배치 전체를 한 번에 넣거나 1개씩 넣습니다.\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,              # 테스트는 하나씩 혹은 통째로\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# [검증] 잘 만들어졌는지 확인\n",
    "# -------------------------------------------------------\n",
    "print(f\"Train Data Shape: {train_tensor.shape}\")\n",
    "print(f\"Train Loader Batches: {len(train_loader)}\")\n",
    "\n",
    "# 배치가 모델에 잘 들어가는지 테스트\n",
    "for batch in train_loader:\n",
    "    x_batch = batch[0] # TensorDataset은 튜플로 반환하므로 [0]으로 꺼냄\n",
    "    print(f\"Input Batch Shape: {x_batch.shape}\") # [64, 30, 500] 이어야 함\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e05e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# [1] Model Initialization\n",
    "# We pass the CLASSES, not instances, because NeuralODE.__init__ instantiates them.\n",
    "model = NeuralODE(\n",
    "    config=config, \n",
    "    encoder=NeuralODEEncoder, \n",
    "    sampler=LatentSampler, \n",
    "    ode_function=ODEFunc, \n",
    "    decoder=NeuralODEDecoder\n",
    ").to(config.device)\n",
    "\n",
    "# [2] Optimizer\n",
    "# Adam is the standard choice for VAE/ODE architectures.\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=config.learning_rate, \n",
    "    weight_decay=config.weight_decay\n",
    ")\n",
    "\n",
    "#\n",
    "# [2] The Training Loop\n",
    "# ------------------------------------------------------------------------------\n",
    "print(f\"Starting Training on {config.device}...\")\n",
    "print(f\"Dimension Mismatch Strategy: Slicing output {config.number_of_times} -> {config.steps}\")\n",
    "\n",
    "loss_recon = MSE_Loss()\n",
    "history_loss = {'loss': [], 'recon': [], 'kld': []}\n",
    "\n",
    "for epoch in range(config.num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_recon = 0\n",
    "    epoch_kld = 0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        # 1. Prepare Data\n",
    "        # TensorDataset wraps the tensor in a tuple, so we access [0]\n",
    "        x_batch = batch[0].to(config.device) \n",
    "        \n",
    "        # 2. Forward Pass\n",
    "        # We pass time_steps=None to let the model generate the full high-res \n",
    "        # trajectory (120 points) defined in config.times\n",
    "        optimizer.zero_grad()\n",
    "        x_pred, mu, logvar = model(x_batch, time_steps=None)\n",
    "        \n",
    "        # 3. Compute Loss\n",
    "        recon_loss = loss_recon(x_pred, x_batch)\n",
    "        kld_loss = KLD_Loss(mu, logvar)\n",
    "        total_loss = recon_loss + (config.kld_coeff) * kld_loss\n",
    "\n",
    "        # 4. Backward & Optimize\n",
    "        total_loss.backward()\n",
    "        \n",
    "        # Gradient Clipping (Optional but recommended for ODEs/RNNs)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # 5. Accumulate Metrics\n",
    "        epoch_loss += total_loss.item()\n",
    "        epoch_recon += recon_loss.item()\n",
    "        epoch_kld += kld_loss.item()\n",
    "    \n",
    "    # Average over batches\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    avg_recon = epoch_recon / len(train_loader)\n",
    "    avg_kld = epoch_kld / len(train_loader)\n",
    "    \n",
    "    history_loss['loss'].append(avg_loss)\n",
    "    history_loss['recon'].append(avg_recon)\n",
    "    history_loss['kld'].append(avg_kld)\n",
    "    \n",
    "    # Logging (Every 10 epochs)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{config.num_epochs}] \"\n",
    "              f\"Loss: {avg_loss:.6f} | Recon: {avg_recon:.6f} | KLD: {avg_kld:.6f}\")\n",
    "\n",
    "print(\"Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37337471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
